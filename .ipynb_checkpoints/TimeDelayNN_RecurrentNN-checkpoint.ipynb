{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Time Delay Neural Netork and Recurrent Neural Network\n",
    "### Hoda Akl\n",
    "EEL6814 - HW 4 <br>\n",
    "The goal is to utilize a TDNN and a RNN to distinguish strings of characters belonging to a grammar and compare their performance. A grammar is a rule that establishes the possible sequence of symbols in a string, i.e. the language. In our case the grammar is {0*,1}, where * means any number of zeros. This means that strings like \n",
    "0,1,0,0,0,1,0,0,1,…. \n",
    "belong to the grammar and strings like \n",
    "0,0,1,1,0,1,….\n",
    "do not belong to the grammar. This is a simple case of language processing when the dictionary has only 2 symbols (0 and 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Most general notebook \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "# Form our test and train data\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Form our test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random \n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import models \n",
    "from keras import layers \n",
    "from keras import initializers\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "def create_string(grammar = True):\n",
    "    \"\"\" Returns one array of length 60 that either belongs to the grammar or doesn't \"\"\"\n",
    "    n = 60 \n",
    "    string_arr = np.ones(n)*n\n",
    "    if grammar ==True: \n",
    "\n",
    "        s = 0\n",
    "        while s<n:\n",
    "            n_zero = random.randint(1,11)\n",
    "            if s+n_zero < (n-1):\n",
    "                string_arr[s:s+n_zero] = np.zeros(n_zero)\n",
    "                string_arr[s+n_zero] = 1\n",
    "                s = s+n_zero+1\n",
    "            else:\n",
    "                string_arr[s:] = np.zeros(n-s)\n",
    "                s = n\n",
    "        \n",
    "    \n",
    "    if grammar == False: \n",
    "        curr_idx = 0\n",
    "        while curr_idx<n:\n",
    "        #     curr_idx  = s\n",
    "            last_zero_idx = random.randint(curr_idx+1,curr_idx+11)\n",
    "            if (last_zero_idx <= n):\n",
    "                string_arr[curr_idx:last_zero_idx] = np.zeros(last_zero_idx -curr_idx)\n",
    "                curr_idx = last_zero_idx\n",
    "            else:\n",
    "                string_arr[curr_idx:] = np.zeros(n -curr_idx)\n",
    "                curr_idx = n\n",
    "            ####\n",
    "        #     for the ones string\n",
    "            last_ones_idx = random.randint(curr_idx+1,curr_idx+11)\n",
    "            if (last_ones_idx <= n):\n",
    "                string_arr[curr_idx:last_ones_idx] = np.ones(last_ones_idx -curr_idx)\n",
    "                curr_idx = last_ones_idx\n",
    "            else:\n",
    "                string_arr[curr_idx:] = np.ones(n -curr_idx)\n",
    "                curr_idx = n\n",
    "                \n",
    "    return string_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating data : \n",
    "# Last column is the labels \n",
    "# first 500 samples are grammar \n",
    "# last / second 500 samples are grammar \n",
    "DataBase = np.ones((1000,61))*200\n",
    "for i in range(500):\n",
    "    DataBase[i,:-1] = create_string(grammar = True)\n",
    "    DataBase[i,-1] = 1\n",
    "    DataBase[i+500,:-1] = create_string(grammar = False)\n",
    "    DataBase[i+500,-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape  (800, 80)\n",
      "X_Val shape  (200, 80)\n",
      "Y_Train_oneHot shape  (800, 2)\n",
      "Y_Val_oneHot shape  (200, 2)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing the data \n",
    "## data preprocessing \n",
    "# seperate label from sequence\n",
    "Data = DataBase[:,:-1]\n",
    "Label = DataBase[:,-1]\n",
    "\n",
    "PaddedData = np.zeros((Data.shape[0], 81))\n",
    "\n",
    "PaddedData[:,:60] = Data\n",
    "PaddedData[:,-1] = Label\n",
    "np.random.shuffle(PaddedData)\n",
    "Data_Shuffled_WLabel = PaddedData\n",
    "Labels = Data_Shuffled_WLabel[:,-1]\n",
    "Data_processed = Data_Shuffled_WLabel[:,:-1]\n",
    "scl = MinMaxScaler()\n",
    "scl.fit(Data_processed)\n",
    "Data_processed = scl.transform(Data_processed)\n",
    "from keras.utils import to_categorical\n",
    "YTrain_oneHot = to_categorical(Labels)\n",
    "XTrain = Data_processed\n",
    "# \n",
    "X_Train,X_Val,Y_Train_oneHot,Y_Val_oneHot = train_test_split(XTrain,YTrain_oneHot, test_size=0.2, random_state=42)\n",
    "print('X_Train shape ', X_Train.shape)\n",
    "print('X_Val shape ', X_Val.shape)\n",
    "print('Y_Train_oneHot shape ', Y_Train_oneHot.shape)\n",
    "print('Y_Val_oneHot shape ', Y_Val_oneHot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Test shape  (500, 80)\n",
      "Y_Test_OneHot shape  (500, 2)\n"
     ]
    }
   ],
   "source": [
    "### preprocessing the testing data \n",
    "path = 'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\hmw4test.csv'\n",
    "TestData=pd.read_csv(path,header=None)\n",
    "TestData = shuffle(TestData,random_state=42)    # by setting the random state we will get reproducible results\n",
    "# Split the data into training and testing \n",
    "# Scale the input \n",
    "#\n",
    "XTest = TestData.iloc[:,:-1].values\n",
    "# scl = MinMaxScaler() # for scaling the data\n",
    "# XDataSc = scl.fit_transfo.rm(XData)\n",
    "X_Test = scl.transform(XTest)\n",
    "# XTest = XTest.reshape((XTest.shape[0], XTest.shape[1],1))\n",
    "YLabels = TestData.iloc[:,-1].values\n",
    "Y_Test_OneHot = to_categorical(YLabels)\n",
    "# X_Test = XTest.reshape(XTest.shape[0], XTest.shape[1],1)\n",
    "print('X_Test shape ', X_Test.shape)\n",
    "print('Y_Test_OneHot shape ', Y_Test_OneHot.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape inputs \n",
    "X_Test  = X_Test.reshape(X_Test.shape[0], X_Test.shape[1],1)\n",
    "X_Val   = X_Val.reshape(X_Val.shape[0], X_Val.shape[1],1)\n",
    "X_Train = X_Train.reshape(X_Train.shape[0], X_Train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "## I want to define a model that has input of delay size \n",
    "def create_network(delay_size = 7, filters = 30, train_size = 800, batchsize = 10, nh_layers = 1, internal_memory = False):\n",
    "    net =models.Sequential()\n",
    "    filters = filters \n",
    "    delay_size = delay_size\n",
    "    input_shape = (train_size,80)\n",
    "    net.add(layers.Conv1D(filters ,  delay_size,activation='relu', input_shape = (80,1) ,padding=\"same\"))\n",
    "    \n",
    "    if nh_layers > 1:\n",
    "        for i in range(nh_layers - 1):\n",
    "            if internal_memory == True:\n",
    "                net.add(layers.Conv1D(filters ,  delay_size ,activation='relu',padding=\"same\"))\n",
    "            else:\n",
    "                net.add(layers.Flatten())\n",
    "                net.add(layers.Dense(50, activation = 'relu'))\n",
    "    net.add(layers.Flatten())\n",
    "    net.add(layers.Dense(2,activation='softmax'))\n",
    "    \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path( nhidden = 1, delay = 20, internal_memory = 'wo'):\n",
    "    path1 = 'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\SavedModel\\TDNN' + '_layers_' + str(nhidden) + '_delay_' + str(delay)+ '_'+ internal_memory  +'_memory.h5'\n",
    "    return path1\n",
    "    \n",
    "    \n",
    "def train_TDNN(network , SavePath, delaysize, nhlayers = 1, verbose = 1, batchsize = 10, epochs = 1000):\n",
    "    StopCriteria = 'val_loss'\n",
    "    callbacks = [EarlyStopping(monitor=StopCriteria, patience=20),\n",
    "             ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n",
    "    network = network\n",
    "    network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history = network.fit(X_Train,Y_Train_oneHot,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batchsize, # Early stopping,\n",
    "                         verbose = verbose,\n",
    "                     validation_data=(X_Val,Y_Val_oneHot),\n",
    "                     callbacks = callbacks)\n",
    "    return history\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\SavedModel\\TDNN_layers_1_delay_20_wo_memory.h5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 80, 30)            240       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 4802      \n",
      "=================================================================\n",
      "Total params: 5,042\n",
      "Trainable params: 5,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path = create_path()\n",
    "print(path)\n",
    "nett = create_network()\n",
    "nett.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.2782 - accuracy: 0.8963 - val_loss: 0.0396 - val_accuracy: 0.9950\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 0.0196 - accuracy: 0.9987 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 9.6984e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 7.7663e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 6.4486e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 5.4653e-04 - accuracy: 1.0000 - val_loss: 9.4159e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 4.6153e-04 - accuracy: 1.0000 - val_loss: 8.2985e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 3.9773e-04 - accuracy: 1.0000 - val_loss: 7.4028e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.5122e-04 - accuracy: 1.0000 - val_loss: 6.4283e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 3.0668e-04 - accuracy: 1.0000 - val_loss: 6.2264e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.7256e-04 - accuracy: 1.0000 - val_loss: 5.7627e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3994e-04 - accuracy: 1.0000 - val_loss: 4.7545e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.1486e-04 - accuracy: 1.0000 - val_loss: 5.1442e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.9430e-04 - accuracy: 1.0000 - val_loss: 4.1730e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6843e-04 - accuracy: 1.0000 - val_loss: 4.0965e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.5741e-04 - accuracy: 1.0000 - val_loss: 3.5004e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.3948e-04 - accuracy: 1.0000 - val_loss: 3.4760e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.2870e-04 - accuracy: 1.0000 - val_loss: 3.2900e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.1860e-04 - accuracy: 1.0000 - val_loss: 3.2976e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.0622e-04 - accuracy: 1.0000 - val_loss: 2.8263e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 9.8971e-05 - accuracy: 1.0000 - val_loss: 2.7508e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 9.0142e-05 - accuracy: 1.0000 - val_loss: 2.4500e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 8.3288e-05 - accuracy: 1.0000 - val_loss: 2.3085e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.7623e-05 - accuracy: 1.0000 - val_loss: 2.1010e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.1751e-05 - accuracy: 1.0000 - val_loss: 1.9946e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 6.6201e-05 - accuracy: 1.0000 - val_loss: 1.8667e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 6.1707e-05 - accuracy: 1.0000 - val_loss: 1.7585e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 5.6898e-05 - accuracy: 1.0000 - val_loss: 1.7723e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 5.3475e-05 - accuracy: 1.0000 - val_loss: 1.7120e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4.9815e-05 - accuracy: 1.0000 - val_loss: 1.6936e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 4.6652e-05 - accuracy: 1.0000 - val_loss: 1.5086e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 4.3562e-05 - accuracy: 1.0000 - val_loss: 1.4497e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 4.0701e-05 - accuracy: 1.0000 - val_loss: 1.4221e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 3.8477e-05 - accuracy: 1.0000 - val_loss: 1.2928e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 3.5757e-05 - accuracy: 1.0000 - val_loss: 1.2444e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 3.3569e-05 - accuracy: 1.0000 - val_loss: 1.2003e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.2318e-05 - accuracy: 1.0000 - val_loss: 1.1180e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 3.0185e-05 - accuracy: 1.0000 - val_loss: 1.0892e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.8044e-05 - accuracy: 1.0000 - val_loss: 1.0431e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.6589e-05 - accuracy: 1.0000 - val_loss: 9.8574e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.4944e-05 - accuracy: 1.0000 - val_loss: 9.4907e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.4517e-05 - accuracy: 1.0000 - val_loss: 9.0365e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.2258e-05 - accuracy: 1.0000 - val_loss: 8.6562e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.1274e-05 - accuracy: 1.0000 - val_loss: 8.0130e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.9910e-05 - accuracy: 1.0000 - val_loss: 8.1704e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 1.8929e-05 - accuracy: 1.0000 - val_loss: 7.4959e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 1.7672e-05 - accuracy: 1.0000 - val_loss: 7.4315e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.6803e-05 - accuracy: 1.0000 - val_loss: 7.3211e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.5899e-05 - accuracy: 1.0000 - val_loss: 6.6510e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 1.5117e-05 - accuracy: 1.0000 - val_loss: 6.3037e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 1.4294e-05 - accuracy: 1.0000 - val_loss: 6.0925e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.3603e-05 - accuracy: 1.0000 - val_loss: 5.9870e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 1.2836e-05 - accuracy: 1.0000 - val_loss: 5.9463e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 1.2227e-05 - accuracy: 1.0000 - val_loss: 5.7006e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.1545e-05 - accuracy: 1.0000 - val_loss: 5.3743e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.0997e-05 - accuracy: 1.0000 - val_loss: 5.2738e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.0390e-05 - accuracy: 1.0000 - val_loss: 5.1233e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 9.9123e-06 - accuracy: 1.0000 - val_loss: 4.9926e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 9.4813e-06 - accuracy: 1.0000 - val_loss: 4.4087e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 9.0658e-06 - accuracy: 1.0000 - val_loss: 4.4298e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 8.5596e-06 - accuracy: 1.0000 - val_loss: 3.9919e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 8.0770e-06 - accuracy: 1.0000 - val_loss: 4.0130e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 7.6878e-06 - accuracy: 1.0000 - val_loss: 4.2647e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 7.3941e-06 - accuracy: 1.0000 - val_loss: 3.7333e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 7.0231e-06 - accuracy: 1.0000 - val_loss: 3.6383e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 6.6332e-06 - accuracy: 1.0000 - val_loss: 3.7173e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 6.3321e-06 - accuracy: 1.0000 - val_loss: 3.6323e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 6.0865e-06 - accuracy: 1.0000 - val_loss: 3.4854e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 5.7579e-06 - accuracy: 1.0000 - val_loss: 3.1889e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 5.4294e-06 - accuracy: 1.0000 - val_loss: 3.2211e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 5.2675e-06 - accuracy: 1.0000 - val_loss: 2.9972e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 4.9392e-06 - accuracy: 1.0000 - val_loss: 2.8338e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 4.7708e-06 - accuracy: 1.0000 - val_loss: 2.7646e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 4.5344e-06 - accuracy: 1.0000 - val_loss: 2.9225e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 4.2729e-06 - accuracy: 1.0000 - val_loss: 2.7640e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 4.0736e-06 - accuracy: 1.0000 - val_loss: 2.5028e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 3.9267e-06 - accuracy: 1.0000 - val_loss: 2.4541e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 3.7616e-06 - accuracy: 1.0000 - val_loss: 2.3108e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 3.5655e-06 - accuracy: 1.0000 - val_loss: 2.2602e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 3.4001e-06 - accuracy: 1.0000 - val_loss: 2.1323e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 3.2185e-06 - accuracy: 1.0000 - val_loss: 2.0734e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 3.0923e-06 - accuracy: 1.0000 - val_loss: 2.0238e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.9634e-06 - accuracy: 1.0000 - val_loss: 2.1820e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.7986e-06 - accuracy: 1.0000 - val_loss: 1.8689e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.6598e-06 - accuracy: 1.0000 - val_loss: 1.9098e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.5501e-06 - accuracy: 1.0000 - val_loss: 1.9177e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 2.4602e-06 - accuracy: 1.0000 - val_loss: 1.7998e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.3389e-06 - accuracy: 1.0000 - val_loss: 1.7183e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 2.2445e-06 - accuracy: 1.0000 - val_loss: 1.7254e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 2.1378e-06 - accuracy: 1.0000 - val_loss: 1.5713e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.0363e-06 - accuracy: 1.0000 - val_loss: 1.5268e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 1.9572e-06 - accuracy: 1.0000 - val_loss: 1.5240e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.8757e-06 - accuracy: 1.0000 - val_loss: 1.5226e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 1.7765e-06 - accuracy: 1.0000 - val_loss: 1.4548e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 1.6841e-06 - accuracy: 1.0000 - val_loss: 1.3361e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 1.6178e-06 - accuracy: 1.0000 - val_loss: 1.2997e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 1.5370e-06 - accuracy: 1.0000 - val_loss: 1.2326e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 1.4704e-06 - accuracy: 1.0000 - val_loss: 1.1728e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.4066e-06 - accuracy: 1.0000 - val_loss: 1.1886e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.3472e-06 - accuracy: 1.0000 - val_loss: 1.1511e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.2763e-06 - accuracy: 1.0000 - val_loss: 1.1212e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.2222e-06 - accuracy: 1.0000 - val_loss: 1.0720e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.1703e-06 - accuracy: 1.0000 - val_loss: 1.0107e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.1205e-06 - accuracy: 1.0000 - val_loss: 1.0048e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.0729e-06 - accuracy: 1.0000 - val_loss: 1.0359e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 1.0289e-06 - accuracy: 1.0000 - val_loss: 9.8261e-06 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 9.7526e-07 - accuracy: 1.0000 - val_loss: 9.1504e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 9.3935e-07 - accuracy: 1.0000 - val_loss: 8.8461e-06 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 8.9361e-07 - accuracy: 1.0000 - val_loss: 8.5579e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 8.5278e-07 - accuracy: 1.0000 - val_loss: 8.0220e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 8.1493e-07 - accuracy: 1.0000 - val_loss: 8.1982e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 7.7962e-07 - accuracy: 1.0000 - val_loss: 7.7659e-06 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 7.4490e-07 - accuracy: 1.0000 - val_loss: 7.9433e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 7.2717e-07 - accuracy: 1.0000 - val_loss: 7.0674e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 6.8232e-07 - accuracy: 1.0000 - val_loss: 7.6152e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 6.5445e-07 - accuracy: 1.0000 - val_loss: 6.5594e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 6.2391e-07 - accuracy: 1.0000 - val_loss: 6.4325e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 5.9902e-07 - accuracy: 1.0000 - val_loss: 6.1829e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 5.8844e-07 - accuracy: 1.0000 - val_loss: 5.8071e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 5.4419e-07 - accuracy: 1.0000 - val_loss: 6.0662e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 5.2347e-07 - accuracy: 1.0000 - val_loss: 5.8112e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5.0067e-07 - accuracy: 1.0000 - val_loss: 5.7165e-06 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 4.7609e-07 - accuracy: 1.0000 - val_loss: 5.4086e-06 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 4.5776e-07 - accuracy: 1.0000 - val_loss: 5.2561e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 4.3600e-07 - accuracy: 1.0000 - val_loss: 5.1953e-06 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 4.1797e-07 - accuracy: 1.0000 - val_loss: 5.0273e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 3.9652e-07 - accuracy: 1.0000 - val_loss: 4.8582e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 3.8042e-07 - accuracy: 1.0000 - val_loss: 4.7348e-06 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 3.6582e-07 - accuracy: 1.0000 - val_loss: 4.8688e-06 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 3.5003e-07 - accuracy: 1.0000 - val_loss: 4.3071e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 3.3244e-07 - accuracy: 1.0000 - val_loss: 4.3697e-06 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 3.1918e-07 - accuracy: 1.0000 - val_loss: 4.0486e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 3.0577e-07 - accuracy: 1.0000 - val_loss: 3.9896e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.9206e-07 - accuracy: 1.0000 - val_loss: 3.8359e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 2.7761e-07 - accuracy: 1.0000 - val_loss: 3.7203e-06 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 2.6703e-07 - accuracy: 1.0000 - val_loss: 3.5743e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.5526e-07 - accuracy: 1.0000 - val_loss: 3.3986e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.4229e-07 - accuracy: 1.0000 - val_loss: 3.3533e-06 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 2.3201e-07 - accuracy: 1.0000 - val_loss: 3.2168e-06 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2262e-07 - accuracy: 1.0000 - val_loss: 3.1650e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.1338e-07 - accuracy: 1.0000 - val_loss: 3.0387e-06 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.0474e-07 - accuracy: 1.0000 - val_loss: 2.9773e-06 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.9640e-07 - accuracy: 1.0000 - val_loss: 2.8063e-06 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.8701e-07 - accuracy: 1.0000 - val_loss: 2.7163e-06 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.7911e-07 - accuracy: 1.0000 - val_loss: 2.6276e-06 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.7002e-07 - accuracy: 1.0000 - val_loss: 2.5763e-06 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.6332e-07 - accuracy: 1.0000 - val_loss: 2.6383e-06 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 1.5810e-07 - accuracy: 1.0000 - val_loss: 2.5018e-06 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.4976e-07 - accuracy: 1.0000 - val_loss: 2.3940e-06 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 1.4290e-07 - accuracy: 1.0000 - val_loss: 2.2933e-06 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.3605e-07 - accuracy: 1.0000 - val_loss: 2.1955e-06 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.3143e-07 - accuracy: 1.0000 - val_loss: 2.1366e-06 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.2621e-07 - accuracy: 1.0000 - val_loss: 2.1556e-06 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.2055e-07 - accuracy: 1.0000 - val_loss: 2.0352e-06 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 1.1578e-07 - accuracy: 1.0000 - val_loss: 2.0746e-06 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.0982e-07 - accuracy: 1.0000 - val_loss: 1.7981e-06 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.0595e-07 - accuracy: 1.0000 - val_loss: 1.7319e-06 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.0058e-07 - accuracy: 1.0000 - val_loss: 1.7474e-06 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 9.6559e-08 - accuracy: 1.0000 - val_loss: 1.7385e-06 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 9.3132e-08 - accuracy: 1.0000 - val_loss: 1.6551e-06 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 8.8215e-08 - accuracy: 1.0000 - val_loss: 1.6741e-06 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 8.5085e-08 - accuracy: 1.0000 - val_loss: 1.6551e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.9572e-08 - accuracy: 1.0000 - val_loss: 1.5424e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 7.7635e-08 - accuracy: 1.0000 - val_loss: 1.5114e-06 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 7.4357e-08 - accuracy: 1.0000 - val_loss: 1.4405e-06 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 7.2122e-08 - accuracy: 1.0000 - val_loss: 1.3720e-06 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 6.8694e-08 - accuracy: 1.0000 - val_loss: 1.3714e-06 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 6.4224e-08 - accuracy: 1.0000 - val_loss: 1.2653e-06 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 6.1244e-08 - accuracy: 1.0000 - val_loss: 1.2999e-06 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 1.2355e-06 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 5.6475e-08 - accuracy: 1.0000 - val_loss: 1.1616e-06 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 5.3048e-08 - accuracy: 1.0000 - val_loss: 1.1527e-06 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 5.2452e-08 - accuracy: 1.0000 - val_loss: 1.0502e-06 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4.9323e-08 - accuracy: 1.0000 - val_loss: 1.0633e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 4.6790e-08 - accuracy: 1.0000 - val_loss: 1.0388e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 4.5299e-08 - accuracy: 1.0000 - val_loss: 9.9891e-07 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 4.5939e-08 - accuracy: 1.00 - 0s 141us/step - loss: 4.3660e-08 - accuracy: 1.0000 - val_loss: 9.6256e-07 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 4.1872e-08 - accuracy: 1.0000 - val_loss: 9.5302e-07 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 3.9339e-08 - accuracy: 1.0000 - val_loss: 9.2680e-07 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 3.7998e-08 - accuracy: 1.0000 - val_loss: 8.7495e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3.7253e-08 - accuracy: 1.0000 - val_loss: 8.5528e-07 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 3.4720e-08 - accuracy: 1.0000 - val_loss: 8.3144e-07 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.2634e-08 - accuracy: 1.0000 - val_loss: 7.9747e-07 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3.1441e-08 - accuracy: 1.0000 - val_loss: 8.0760e-07 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.0100e-08 - accuracy: 1.0000 - val_loss: 8.0462e-07 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.8312e-08 - accuracy: 1.0000 - val_loss: 7.6171e-07 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.7567e-08 - accuracy: 1.0000 - val_loss: 7.0092e-07 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.6375e-08 - accuracy: 1.0000 - val_loss: 6.9198e-07 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 6.6993e-07 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.4289e-08 - accuracy: 1.0000 - val_loss: 6.8185e-07 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3544e-08 - accuracy: 1.0000 - val_loss: 6.5801e-07 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2203e-08 - accuracy: 1.0000 - val_loss: 6.3655e-07 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.1756e-08 - accuracy: 1.0000 - val_loss: 5.7934e-07 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 2.0266e-08 - accuracy: 1.0000 - val_loss: 5.5371e-07 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.9670e-08 - accuracy: 1.0000 - val_loss: 5.5013e-07 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.8477e-08 - accuracy: 1.0000 - val_loss: 5.1795e-07 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 1.7732e-08 - accuracy: 1.0000 - val_loss: 5.1258e-07 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.7285e-08 - accuracy: 1.0000 - val_loss: 5.4596e-07 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.6242e-08 - accuracy: 1.0000 - val_loss: 4.6669e-07 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.6093e-08 - accuracy: 1.0000 - val_loss: 4.6014e-07 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.5348e-08 - accuracy: 1.0000 - val_loss: 4.9053e-07 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.4603e-08 - accuracy: 1.0000 - val_loss: 4.7504e-07 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 1.3411e-08 - accuracy: 1.0000 - val_loss: 4.4583e-07 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.3113e-08 - accuracy: 1.0000 - val_loss: 4.0709e-07 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.2666e-08 - accuracy: 1.0000 - val_loss: 4.2139e-07 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.2219e-08 - accuracy: 1.0000 - val_loss: 4.0709e-07 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 3.7669e-07 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 1.1325e-08 - accuracy: 1.0000 - val_loss: 3.8921e-07 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 1.1325e-08 - accuracy: 1.0000 - val_loss: 3.6835e-07 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.0431e-08 - accuracy: 1.0000 - val_loss: 3.6835e-07 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 3.6596e-07 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 9.9838e-09 - accuracy: 1.0000 - val_loss: 3.4630e-07 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 3.3676e-07 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 8.7917e-09 - accuracy: 1.0000 - val_loss: 3.3616e-07 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 3.2961e-07 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 8.3446e-09 - accuracy: 1.0000 - val_loss: 3.2663e-07 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 8.9407e-09 - accuracy: 1.0000 - val_loss: 2.9087e-07 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 2.8848e-07 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 7.7486e-09 - accuracy: 1.0000 - val_loss: 2.8908e-07 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 7.5996e-09 - accuracy: 1.0000 - val_loss: 2.8610e-07 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 2.7656e-07 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 2.7477e-07 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 6.8545e-09 - accuracy: 1.0000 - val_loss: 2.8431e-07 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 6.2585e-09 - accuracy: 1.0000 - val_loss: 2.5570e-07 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 5.8115e-09 - accuracy: 1.0000 - val_loss: 2.4140e-07 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 2.4020e-07 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 2.3067e-07 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 2.3245e-07 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 2.2113e-07 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 2.0742e-07 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 2.2828e-07 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 1.8060e-07 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 1.8000e-07 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 1.8716e-07 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 1.6689e-07 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 1.6391e-07 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 1.6510e-07 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 1.5914e-07 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 1.5497e-07 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 1.4424e-07 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 1.5139e-07 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 1.4424e-07 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.3471e-07 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.3173e-07 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.2278e-07 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.1325e-07 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.1682e-07 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.8082e-08 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.8082e-08 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.0929e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.8545e-08 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.7949e-08 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.0929e-08 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.5565e-08 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.5565e-08 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.1989e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.0797e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.1393e-08 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.7816e-08 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.6028e-08 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.8412e-08 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 6.2585e-08 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 6.4969e-08 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.7816e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.5432e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.7220e-08 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.7816e-08 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.3048e-08 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.4836e-08 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 4.8280e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.1260e-08 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.9472e-08 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5283e-10 - accuracy: 1.00 - 0s 153us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.9472e-08 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 5.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.2319e-08 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.3511e-08 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.3511e-08 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 152us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.00 - 0s 152us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.4107e-08 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 147us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "network = create_network(delay_size=7)\n",
    "\n",
    "StopCriteria = 'val_loss'\n",
    "Path1 = 'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\SavedModel' \n",
    "\n",
    "Path2 = '\\TDNN_1layer_Delay7.h5'\n",
    "SavePath = Path1 + Path2\n",
    "callbacks = [EarlyStopping(monitor=StopCriteria, patience=20),\n",
    "             ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n",
    "network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = network.fit(X_Train,Y_Train_oneHot,\n",
    "                      epochs=1000,\n",
    "                      batch_size=10, # Early stopping,\n",
    "                         verbose = 1,\n",
    "                     validation_data=(X_Val,Y_Val_oneHot),\n",
    "                     callbacks = callbacks)\n",
    "\n",
    "#                       , \n",
    "#                      callbacks = callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 46us/step\n",
      "0.9520000219345093\n"
     ]
    }
   ],
   "source": [
    "loss, acc = network.evaluate(X_Test, Y_Test_OneHot)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 80, 30)            240       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 4802      \n",
      "=================================================================\n",
      "Total params: 5,042\n",
      "Trainable params: 5,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delay7_1layer_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.2693 - accuracy: 0.8500 - val_loss: 0.0346 - val_accuracy: 0.9950\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 0.0161 - accuracy: 0.9987 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9950\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 8.6904e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 7.4745e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 6.3121e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 4.8732e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 4.5126e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 4.3841e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 3.5575e-04 - accuracy: 1.0000 - val_loss: 9.6272e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 3.0556e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 2.5753e-04 - accuracy: 1.0000 - val_loss: 9.1509e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 2.4438e-04 - accuracy: 1.0000 - val_loss: 9.7455e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 2.0588e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.8403e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 1.6689e-04 - accuracy: 1.0000 - val_loss: 8.2624e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.6001e-04 - accuracy: 1.0000 - val_loss: 8.6264e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.4036e-04 - accuracy: 1.0000 - val_loss: 8.6785e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.3955e-04 - accuracy: 1.0000 - val_loss: 6.8718e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.1689e-04 - accuracy: 1.0000 - val_loss: 7.0573e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 1.0573e-04 - accuracy: 1.0000 - val_loss: 8.0918e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.0072e-04 - accuracy: 1.0000 - val_loss: 8.1957e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 9.3516e-05 - accuracy: 1.0000 - val_loss: 5.8776e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 8.4044e-05 - accuracy: 1.0000 - val_loss: 7.7034e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 8.1891e-05 - accuracy: 1.0000 - val_loss: 6.2549e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 7.3229e-05 - accuracy: 1.0000 - val_loss: 7.4817e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 7.2414e-05 - accuracy: 1.0000 - val_loss: 6.2053e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 6.9194e-05 - accuracy: 1.0000 - val_loss: 5.8021e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 6.0497e-05 - accuracy: 1.0000 - val_loss: 4.8527e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 5.6587e-05 - accuracy: 1.0000 - val_loss: 5.1993e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 5.2838e-05 - accuracy: 1.0000 - val_loss: 4.7642e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 4.8937e-05 - accuracy: 1.0000 - val_loss: 6.0316e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 4.6579e-05 - accuracy: 1.0000 - val_loss: 5.4545e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 4.3822e-05 - accuracy: 1.0000 - val_loss: 4.2576e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 4.2753e-05 - accuracy: 1.0000 - val_loss: 3.7355e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 3.9560e-05 - accuracy: 1.0000 - val_loss: 4.6270e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 3.5948e-05 - accuracy: 1.0000 - val_loss: 4.7804e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 3.5357e-05 - accuracy: 1.0000 - val_loss: 3.9899e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 3.2293e-05 - accuracy: 1.0000 - val_loss: 5.1902e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 3.0505e-05 - accuracy: 1.0000 - val_loss: 3.5910e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.8382e-05 - accuracy: 1.0000 - val_loss: 3.7396e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.7447e-05 - accuracy: 1.0000 - val_loss: 4.2665e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 2.5432e-05 - accuracy: 1.0000 - val_loss: 3.7136e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 2.5003e-05 - accuracy: 1.0000 - val_loss: 3.0922e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 2.2959e-05 - accuracy: 1.0000 - val_loss: 3.0010e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 2.1924e-05 - accuracy: 1.0000 - val_loss: 3.3231e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.1290e-05 - accuracy: 1.0000 - val_loss: 2.2630e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 2.0201e-05 - accuracy: 1.0000 - val_loss: 2.6932e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 1.8506e-05 - accuracy: 1.0000 - val_loss: 3.1445e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 1.7133e-05 - accuracy: 1.0000 - val_loss: 3.1801e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.6790e-05 - accuracy: 1.0000 - val_loss: 2.8416e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 1.5564e-05 - accuracy: 1.0000 - val_loss: 2.9587e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 1.4943e-05 - accuracy: 1.0000 - val_loss: 2.3684e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.3884e-05 - accuracy: 1.0000 - val_loss: 2.7353e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.3677e-05 - accuracy: 1.0000 - val_loss: 2.3803e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 1.3081e-05 - accuracy: 1.0000 - val_loss: 2.1155e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.2213e-05 - accuracy: 1.00 - 0s 175us/step - loss: 1.2116e-05 - accuracy: 1.0000 - val_loss: 2.2232e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.1600e-05 - accuracy: 1.0000 - val_loss: 2.3132e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.0881e-05 - accuracy: 1.0000 - val_loss: 2.3743e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.0335e-05 - accuracy: 1.0000 - val_loss: 2.1658e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.0036e-05 - accuracy: 1.0000 - val_loss: 1.9882e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.0510e-05 - accuracy: 1.00 - 0s 175us/step - loss: 9.8024e-06 - accuracy: 1.0000 - val_loss: 2.0812e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 8.9834e-06 - accuracy: 1.0000 - val_loss: 1.8511e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 8.8255e-06 - accuracy: 1.0000 - val_loss: 1.9157e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 8.2702e-06 - accuracy: 1.0000 - val_loss: 2.2047e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 8.1178e-06 - accuracy: 1.0000 - val_loss: 1.5827e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 7.3248e-06 - accuracy: 1.0000 - val_loss: 1.9303e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 7.1298e-06 - accuracy: 1.0000 - val_loss: 1.7599e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 6.7774e-06 - accuracy: 1.0000 - val_loss: 1.6229e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 6.4677e-06 - accuracy: 1.0000 - val_loss: 1.8485e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 6.2177e-06 - accuracy: 1.0000 - val_loss: 1.7155e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 5.7297e-06 - accuracy: 1.0000 - val_loss: 1.7441e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 5.5734e-06 - accuracy: 1.0000 - val_loss: 1.4830e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 5.4016e-06 - accuracy: 1.0000 - val_loss: 1.6093e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 5.0336e-06 - accuracy: 1.0000 - val_loss: 1.6565e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 4.7709e-06 - accuracy: 1.0000 - val_loss: 1.3578e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 4.6365e-06 - accuracy: 1.0000 - val_loss: 1.3805e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 4.3125e-06 - accuracy: 1.0000 - val_loss: 1.4253e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.1541e-06 - accuracy: 1.0000 - val_loss: 1.2419e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.0194e-06 - accuracy: 1.0000 - val_loss: 1.2743e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 3.8442e-06 - accuracy: 1.0000 - val_loss: 1.2959e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 3.6779e-06 - accuracy: 1.0000 - val_loss: 1.4196e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 3.5242e-06 - accuracy: 1.0000 - val_loss: 1.4486e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 3.2887e-06 - accuracy: 1.0000 - val_loss: 1.1669e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 3.1381e-06 - accuracy: 1.0000 - val_loss: 1.2342e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 3.1281e-06 - accuracy: 1.0000 - val_loss: 1.0966e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.8263e-06 - accuracy: 1.0000 - val_loss: 1.4391e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 2.8439e-06 - accuracy: 1.0000 - val_loss: 1.3064e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 2.6409e-06 - accuracy: 1.0000 - val_loss: 1.2049e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 2.4921e-06 - accuracy: 1.0000 - val_loss: 1.1728e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.5147e-06 - accuracy: 1.0000 - val_loss: 1.0425e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.3040e-06 - accuracy: 1.0000 - val_loss: 1.0266e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.1595e-06 - accuracy: 1.0000 - val_loss: 1.0286e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 2.1412e-06 - accuracy: 1.0000 - val_loss: 1.1439e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 1.9941e-06 - accuracy: 1.0000 - val_loss: 8.9587e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.9211e-06 - accuracy: 1.0000 - val_loss: 8.4181e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.8429e-06 - accuracy: 1.0000 - val_loss: 1.1039e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.7407e-06 - accuracy: 1.0000 - val_loss: 9.6950e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.6614e-06 - accuracy: 1.0000 - val_loss: 9.0763e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.5991e-06 - accuracy: 1.0000 - val_loss: 9.2739e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.5571e-06 - accuracy: 1.0000 - val_loss: 1.0529e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 1.4276e-06 - accuracy: 1.0000 - val_loss: 7.9052e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.3825e-06 - accuracy: 1.0000 - val_loss: 1.0070e-04 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 1.3317e-06 - accuracy: 1.0000 - val_loss: 7.0056e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.2721e-06 - accuracy: 1.0000 - val_loss: 7.9672e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.1956e-06 - accuracy: 1.0000 - val_loss: 8.2665e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.1515e-06 - accuracy: 1.0000 - val_loss: 8.7820e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.1564e-06 - accuracy: 1.0000 - val_loss: 6.7087e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 1.0711e-06 - accuracy: 1.0000 - val_loss: 7.8728e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.0280e-06 - accuracy: 1.0000 - val_loss: 5.9640e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 9.7437e-07 - accuracy: 1.0000 - val_loss: 6.8626e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 9.2803e-07 - accuracy: 1.0000 - val_loss: 6.8083e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 8.9733e-07 - accuracy: 1.0000 - val_loss: 6.9884e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 8.5457e-07 - accuracy: 1.0000 - val_loss: 7.0115e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 8.1701e-07 - accuracy: 1.0000 - val_loss: 6.5038e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 7.7843e-07 - accuracy: 1.0000 - val_loss: 6.0769e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 7.3834e-07 - accuracy: 1.0000 - val_loss: 6.4869e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 7.3148e-07 - accuracy: 1.0000 - val_loss: 5.6323e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 6.9126e-07 - accuracy: 1.0000 - val_loss: 5.5734e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 6.4864e-07 - accuracy: 1.0000 - val_loss: 5.2246e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 6.4566e-07 - accuracy: 1.0000 - val_loss: 5.0276e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 5.8442e-07 - accuracy: 1.0000 - val_loss: 6.1733e-05 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 5.7026e-07 - accuracy: 1.0000 - val_loss: 6.2518e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 5.5923e-07 - accuracy: 1.0000 - val_loss: 4.6775e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 5.0961e-07 - accuracy: 1.0000 - val_loss: 6.1331e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 5.1006e-07 - accuracy: 1.0000 - val_loss: 5.4072e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 4.7966e-07 - accuracy: 1.0000 - val_loss: 5.5357e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 4.7489e-07 - accuracy: 1.0000 - val_loss: 4.6227e-05 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 4.4047e-07 - accuracy: 1.0000 - val_loss: 4.7469e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 4.1857e-07 - accuracy: 1.0000 - val_loss: 3.9330e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 4.0769e-07 - accuracy: 1.0000 - val_loss: 5.3506e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 3.7804e-07 - accuracy: 1.0000 - val_loss: 3.9358e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 3.7297e-07 - accuracy: 1.0000 - val_loss: 5.4326e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 3.5077e-07 - accuracy: 1.0000 - val_loss: 3.9878e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 3.4168e-07 - accuracy: 1.0000 - val_loss: 3.8718e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.2827e-07 - accuracy: 1.0000 - val_loss: 3.7422e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 3.1173e-07 - accuracy: 1.0000 - val_loss: 3.8818e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 2.9892e-07 - accuracy: 1.0000 - val_loss: 4.4937e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 2.7969e-07 - accuracy: 1.0000 - val_loss: 4.1609e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 2.7746e-07 - accuracy: 1.0000 - val_loss: 4.1237e-05 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 2.5973e-07 - accuracy: 1.0000 - val_loss: 3.5796e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.4512e-07 - accuracy: 1.0000 - val_loss: 3.3853e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 2.3499e-07 - accuracy: 1.0000 - val_loss: 3.2977e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.3022e-07 - accuracy: 1.0000 - val_loss: 2.9985e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.1770e-07 - accuracy: 1.0000 - val_loss: 3.0475e-05 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 2.0817e-07 - accuracy: 1.0000 - val_loss: 3.0804e-05 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.0012e-07 - accuracy: 1.0000 - val_loss: 3.0751e-05 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.9193e-07 - accuracy: 1.0000 - val_loss: 3.1265e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.8522e-07 - accuracy: 1.0000 - val_loss: 3.6256e-05 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.8179e-07 - accuracy: 1.0000 - val_loss: 3.4105e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 1.7375e-07 - accuracy: 1.0000 - val_loss: 2.7313e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8984e-07 - accuracy: 1.00 - 0s 174us/step - loss: 1.6972e-07 - accuracy: 1.0000 - val_loss: 2.4005e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.4946e-07 - accuracy: 1.0000 - val_loss: 3.3125e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.5289e-07 - accuracy: 1.0000 - val_loss: 3.3566e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.3754e-07 - accuracy: 1.0000 - val_loss: 2.6708e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 1.3486e-07 - accuracy: 1.0000 - val_loss: 2.2509e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.3441e-07 - accuracy: 1.0000 - val_loss: 2.1871e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 3.0953e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 1.2398e-07 - accuracy: 1.0000 - val_loss: 2.6983e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 1.1399e-07 - accuracy: 1.0000 - val_loss: 2.7407e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 1.0833e-07 - accuracy: 1.0000 - val_loss: 2.1591e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 1.0341e-07 - accuracy: 1.0000 - val_loss: 2.1368e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 9.8198e-08 - accuracy: 1.0000 - val_loss: 2.1748e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 9.5218e-08 - accuracy: 1.0000 - val_loss: 2.0447e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 9.0599e-08 - accuracy: 1.0000 - val_loss: 1.9156e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 8.4340e-08 - accuracy: 1.0000 - val_loss: 2.5253e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 8.7768e-08 - accuracy: 1.0000 - val_loss: 2.7257e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 7.9125e-08 - accuracy: 1.0000 - val_loss: 1.7181e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 8.0466e-08 - accuracy: 1.0000 - val_loss: 1.6846e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 7.2867e-08 - accuracy: 1.0000 - val_loss: 1.8851e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 6.9737e-08 - accuracy: 1.0000 - val_loss: 2.0801e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 6.5714e-08 - accuracy: 1.0000 - val_loss: 1.6156e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 6.4820e-08 - accuracy: 1.0000 - val_loss: 1.6615e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 6.1542e-08 - accuracy: 1.0000 - val_loss: 1.6615e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 5.8412e-08 - accuracy: 1.0000 - val_loss: 1.7868e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.5879e-08 - accuracy: 1.0000 - val_loss: 1.8617e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 5.4985e-08 - accuracy: 1.0000 - val_loss: 2.1386e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 5.2601e-08 - accuracy: 1.0000 - val_loss: 1.6882e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 5.1260e-08 - accuracy: 1.0000 - val_loss: 1.6237e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 4.7088e-08 - accuracy: 1.0000 - val_loss: 1.5990e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 4.5299e-08 - accuracy: 1.0000 - val_loss: 1.6083e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 4.3809e-08 - accuracy: 1.0000 - val_loss: 1.5352e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 4.3660e-08 - accuracy: 1.0000 - val_loss: 1.5776e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 3.9190e-08 - accuracy: 1.0000 - val_loss: 1.4259e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 3.8743e-08 - accuracy: 1.0000 - val_loss: 1.5577e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 3.7104e-08 - accuracy: 1.0000 - val_loss: 1.3132e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 3.6210e-08 - accuracy: 1.0000 - val_loss: 1.1830e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 3.3677e-08 - accuracy: 1.0000 - val_loss: 1.4271e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 3.3379e-08 - accuracy: 1.0000 - val_loss: 1.3941e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.4720e-08 - accuracy: 1.0000 - val_loss: 8.8445e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 3.1143e-08 - accuracy: 1.0000 - val_loss: 1.2083e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 2.8908e-08 - accuracy: 1.0000 - val_loss: 1.4047e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 2.8312e-08 - accuracy: 1.0000 - val_loss: 1.1329e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.6524e-08 - accuracy: 1.0000 - val_loss: 1.0009e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.5183e-08 - accuracy: 1.0000 - val_loss: 1.2132e-05 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 2.3693e-08 - accuracy: 1.0000 - val_loss: 1.0403e-05 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.6433e-08 - accuracy: 1.00 - 0s 170us/step - loss: 2.2799e-08 - accuracy: 1.0000 - val_loss: 1.0456e-05 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 2.1756e-08 - accuracy: 1.0000 - val_loss: 1.0788e-05 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 2.1011e-08 - accuracy: 1.0000 - val_loss: 1.1521e-05 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 2.0713e-08 - accuracy: 1.0000 - val_loss: 9.0551e-06 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 1.9819e-08 - accuracy: 1.0000 - val_loss: 9.0122e-06 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.8924e-08 - accuracy: 1.0000 - val_loss: 1.0262e-05 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 1.7583e-08 - accuracy: 1.0000 - val_loss: 1.0201e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 1.7285e-08 - accuracy: 1.0000 - val_loss: 9.8178e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.6391e-08 - accuracy: 1.0000 - val_loss: 9.4632e-06 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.6093e-08 - accuracy: 1.0000 - val_loss: 8.8741e-06 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.4305e-08 - accuracy: 1.0000 - val_loss: 9.5715e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.5199e-08 - accuracy: 1.0000 - val_loss: 9.0586e-06 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 1.4305e-08 - accuracy: 1.0000 - val_loss: 9.5364e-06 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 1.3411e-08 - accuracy: 1.0000 - val_loss: 7.3042e-06 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.3262e-08 - accuracy: 1.0000 - val_loss: 8.2166e-06 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 1.2517e-08 - accuracy: 1.0000 - val_loss: 8.4980e-06 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.2666e-08 - accuracy: 1.0000 - val_loss: 8.7063e-06 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.1921e-08 - accuracy: 1.0000 - val_loss: 8.1898e-06 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 7.3179e-06 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.1027e-08 - accuracy: 1.0000 - val_loss: 8.1541e-06 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.0580e-08 - accuracy: 1.0000 - val_loss: 6.3649e-06 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.0133e-08 - accuracy: 1.0000 - val_loss: 6.5435e-06 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 9.6858e-09 - accuracy: 1.0000 - val_loss: 7.0328e-06 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 7.0738e-06 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 7.0595e-06 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 7.0548e-06 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 8.3446e-09 - accuracy: 1.0000 - val_loss: 5.5159e-06 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 6.1166e-06 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 8.0466e-09 - accuracy: 1.0000 - val_loss: 6.5506e-06 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 7.1526e-09 - accuracy: 1.0000 - val_loss: 6.2797e-06 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 7.1526e-09 - accuracy: 1.0000 - val_loss: 6.1249e-06 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 6.5565e-09 - accuracy: 1.0000 - val_loss: 5.0234e-06 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 6.8696e-06 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 6.5565e-09 - accuracy: 1.0000 - val_loss: 4.9764e-06 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 4.5607e-06 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 5.8115e-09 - accuracy: 1.0000 - val_loss: 4.7900e-06 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 5.4974e-06 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 5.0664e-09 - accuracy: 1.0000 - val_loss: 5.6284e-06 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 5.3444e-06 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.0664e-09 - accuracy: 1.0000 - val_loss: 5.0169e-06 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 4.6000e-06 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 4.4214e-06 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 4.4703e-09 - accuracy: 1.0000 - val_loss: 4.6608e-06 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 4.8555e-06 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 3.7639e-06 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 3.7758e-06 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 3.8139e-06 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 4.3445e-06 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 3.6191e-06 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.8699e-09 - accuracy: 1.00 - 0s 206us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 4.1849e-06 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 3.6066e-06 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 3.9425e-06 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 3.8091e-06 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 3.4833e-06 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 4.1105e-06 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 3.9664e-06 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 3.6233e-06 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 3.6781e-06 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 3.9205e-06 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 3.5208e-06 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 3.2349e-06 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 2.8418e-06 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 3.4380e-06 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 3.5530e-06 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 3.2772e-06 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.5516e-06 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 3.2570e-06 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 157us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.9192e-06 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 3.0127e-06 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.3205e-06 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.1622e-06 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 2.6696e-06 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 2.4325e-06 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.7756e-06 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.5504e-06 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.8948e-06 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.0640e-06 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.5093e-06 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.7083e-06 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.4629e-06 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.3157e-06 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.3407e-06 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.4379e-06 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.5219e-06 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 162us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.4188e-06 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.2877e-06 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.3675e-06 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.1477e-06 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.1382e-06 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.9439e-06 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.5564e-06 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.1161e-06 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.9481e-06 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.9463e-06 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.1459e-06 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 161us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.2806e-06 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.9517e-06 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.0154e-06 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7414e-06 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.6305e-06 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.6418e-06 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7032e-06 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6603e-06 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.9046e-06 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.6895e-06 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6865e-06 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.8480e-06 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7992e-06 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.8003e-06 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.5513e-06 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5608e-06 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5805e-06 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6925e-06 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5918e-06 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5054e-06 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5280e-06 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5364e-06 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5352e-06 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3826e-06 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6746e-06 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6365e-06 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 172us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.4339e-06 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6961e-06 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.5680e-06 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3534e-06 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5531e-06 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.4208e-06 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3689e-06 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4649e-06 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3236e-06 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4679e-06 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5894e-06 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3207e-06 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3922e-06 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5239e-06 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6210e-06 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3088e-06 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 165us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3403e-06 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 171us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5161e-06 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.00 - 0s 189us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5114e-06 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6693e-06 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4053e-06 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4708e-06 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4768e-06 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6007e-06 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5644e-06 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5829e-06 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5912e-06 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5501e-06 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4321e-06 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 167us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4845e-06 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4387e-06 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5078e-06 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4637e-06 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4452e-06 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3856e-06 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4988e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "DS = 20\n",
    "Network20 = create_network(delay_size = 20)\n",
    "results_20delays = train_TDNN(Network20 , delaysize=DS, nhlayers = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 39us/step\n",
      "0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "loss, acc = Network20.evaluate(X_Test, Y_Test_OneHot)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Plot \n",
    "ResultsList = [Delay7_1layer_dict,results_20delays.history ]\n",
    "for i in range(len(Results_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_acc_7delay  = Delay7_1layer_dict['accuracy']\n",
    "# training_vals_loss = Delay7_1layer_dict['loss']\n",
    "Val_acc_7delay = Delay7_1layer_dict['val_accuracy']\n",
    "# valid_vals_loss = Delay7_1layer_dict['val_loss']\n",
    "# \n",
    "Train_acc_20delay = results_20delays.history['accuracy']\n",
    "# training_vals_loss = Delay7_1layer_dict['loss']\n",
    "Val_acc_20delay = results_20delays.history['val_accuracy']\n",
    "# valid_vals_loss = Delay7_1layer_dict['val_loss']\n",
    "# x = list(range(len(training_vals_acc)));\n",
    "plt.plot(Train_acc_7delay, label = 'Delay =  7 - Train Acc')\n",
    "plt.plot( Val_acc_7delay,label = 'Delay =  7 - Val Acc')\n",
    "plt.plot( Train_acc_20delay, label = 'Delay =  20 - Train Acc')\n",
    "plt.plot( Val_acc_20delay, label = 'Delay =  20 - Val Acc')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Training Curves - Accuracy for 1 hidden layer different delay ')\n",
    "# plt.xlim([.98, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_acc_7delay  = Delay7_1layer_dict['loss']\n",
    "# training_vals_loss = Delay7_1layer_dict['loss']\n",
    "Val_acc_7delay = Delay7_1layer_dict['val_loss']\n",
    "# valid_vals_loss = Delay7_1layer_dict['val_loss']\n",
    "# \n",
    "Train_acc_20delay = results_20delays.history['loss']\n",
    "# training_vals_loss = Delay7_1layer_dict['loss']\n",
    "Val_acc_20delay = results_20delays.history['val_loss']\n",
    "# valid_vals_loss = Delay7_1layer_dict['val_loss']\n",
    "# x = list(range(len(training_vals_acc)));\n",
    "plt.plot(Train_acc_7delay, label = 'Delay =  7 - Train Loss')\n",
    "plt.plot( Val_acc_7delay,label = 'Delay =  7 - Val Loss')\n",
    "plt.plot( Train_acc_20delay, label = 'Delay =  20 - Train Loss')\n",
    "plt.plot( Val_acc_20delay, label = 'Delay =  20 - Val Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Training Curves - Loss for 1 hidden layer different delay ')\n",
    "# plt.xlim([.98, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 40us/step\n",
      "500/500 [==============================] - 0s 30us/step\n",
      "Delay 7 : \n",
      "test accuracy =  0.44996309563631076  , test loss =  0.9520000219345093\n",
      "\n",
      "Delay 20 : \n",
      "test accuracy =  0.1612121923789382  , test loss =  0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "acc7, loss7    = network.evaluate(X_Test, Y_Test_OneHot)\n",
    "acc20, loss20  = Network20.evaluate(X_Test, Y_Test_OneHot)\n",
    "print('Delay 7 : ')\n",
    "print('test accuracy = ' , acc7, ' , test loss = ', loss7)\n",
    "print()\n",
    "print('Delay 20 : ')\n",
    "print('test accuracy = ' , acc20, ' , test loss = ', loss20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of them got trained in 358 epochs for 20 and 359 epochs for 7\n",
    "\n",
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = Network20.predict(X_Test)\n",
    "#\n",
    "# Get the max probabilites for each rows\n",
    "probs = np.max(predictions, axis = 1)\n",
    "#\n",
    "# Get the predicted classes for each row  - I have plus 1 because this \n",
    "Y_Predicted_classes = np.argmax(predictions, axis = 1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ConfMat = confusion_matrix(YLabels, Y_Predicted_classes)\n",
    "import seaborn as sn\n",
    "confMat = np.transpose(ConfMat)\n",
    "df_cm = pd.DataFrame(ConfMat, index = [\"Predicted 0\", \"Predicted 1\"],\n",
    "                  columns = [\"True 0\", \"True 1\"])\n",
    "plt.figure(figsize = (7,5))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.title('confusion matrix for 1 hidden layer 20 dalay line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = network.predict(X_Test)\n",
    "#\n",
    "# Get the max probabilites for each rows\n",
    "probs = np.max(predictions, axis = 1)\n",
    "#\n",
    "# Get the predicted classes for each row  - I have plus 1 because this \n",
    "Y_Predicted_classes = np.argmax(predictions, axis = 1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ConfMat = confusion_matrix(YLabels, Y_Predicted_classes)\n",
    "import seaborn as sn\n",
    "confMat = np.transpose(ConfMat)\n",
    "df_cm = pd.DataFrame(ConfMat, index = [\"Predicted 0\", \"Predicted 1\"],\n",
    "                  columns = [\"True 0\", \"True 1\"])\n",
    "plt.figure(figsize = (7,5))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.title('confusion matrix for 1 hidden layer 7 dalay line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying a two hidden layer with delay 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 486us/step - loss: 0.1049 - accuracy: 0.9588 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 6.3377e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 4.0504e-04 - accuracy: 1.0000 - val_loss: 8.8936e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 2.3781e-04 - accuracy: 1.0000 - val_loss: 6.1464e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.6899e-04 - accuracy: 1.0000 - val_loss: 6.8498e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 1.2849e-04 - accuracy: 1.0000 - val_loss: 6.0324e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 9.5862e-05 - accuracy: 1.0000 - val_loss: 4.5477e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 7.7278e-05 - accuracy: 1.0000 - val_loss: 4.5781e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 6.3528e-05 - accuracy: 1.0000 - val_loss: 3.6884e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 4.9690e-05 - accuracy: 1.0000 - val_loss: 3.7233e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 4.2728e-05 - accuracy: 1.0000 - val_loss: 3.1712e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 3.6156e-05 - accuracy: 1.0000 - val_loss: 3.3862e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 3.1209e-05 - accuracy: 1.0000 - val_loss: 2.8574e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 2.6830e-05 - accuracy: 1.0000 - val_loss: 2.7074e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 2.3735e-05 - accuracy: 1.0000 - val_loss: 2.7029e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 2.1013e-05 - accuracy: 1.0000 - val_loss: 2.1876e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 1.8290e-05 - accuracy: 1.0000 - val_loss: 2.1725e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 1.6347e-05 - accuracy: 1.0000 - val_loss: 2.2608e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.4659e-05 - accuracy: 1.0000 - val_loss: 1.8597e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.3128e-05 - accuracy: 1.0000 - val_loss: 2.0394e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 1.1843e-05 - accuracy: 1.0000 - val_loss: 1.8000e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 1.0747e-05 - accuracy: 1.0000 - val_loss: 1.5503e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.0181e-05 - accuracy: 1.0000 - val_loss: 1.7044e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 8.8842e-06 - accuracy: 1.0000 - val_loss: 1.5385e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 8.2245e-06 - accuracy: 1.0000 - val_loss: 1.4885e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 7.5892e-06 - accuracy: 1.0000 - val_loss: 1.4647e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 7.0311e-06 - accuracy: 1.0000 - val_loss: 1.3198e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 6.3675e-06 - accuracy: 1.0000 - val_loss: 1.2487e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 5.8618e-06 - accuracy: 1.0000 - val_loss: 1.1701e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 5.4194e-06 - accuracy: 1.0000 - val_loss: 1.2112e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 5.0408e-06 - accuracy: 1.0000 - val_loss: 1.1381e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 4.6686e-06 - accuracy: 1.0000 - val_loss: 1.1093e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 4.3099e-06 - accuracy: 1.0000 - val_loss: 1.1013e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 4.0460e-06 - accuracy: 1.0000 - val_loss: 9.4443e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 3.7580e-06 - accuracy: 1.0000 - val_loss: 9.6658e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 3.5020e-06 - accuracy: 1.0000 - val_loss: 9.2341e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 3.2750e-06 - accuracy: 1.0000 - val_loss: 9.2357e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 3.0625e-06 - accuracy: 1.0000 - val_loss: 9.0696e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 2.8835e-06 - accuracy: 1.0000 - val_loss: 8.5786e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 2.6921e-06 - accuracy: 1.0000 - val_loss: 8.0967e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 2.5134e-06 - accuracy: 1.0000 - val_loss: 8.2733e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 2.3689e-06 - accuracy: 1.0000 - val_loss: 8.6179e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 2.2582e-06 - accuracy: 1.0000 - val_loss: 7.7027e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 2.0995e-06 - accuracy: 1.0000 - val_loss: 7.6242e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 1.9712e-06 - accuracy: 1.0000 - val_loss: 7.0658e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.8607e-06 - accuracy: 1.0000 - val_loss: 7.1279e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.7799e-06 - accuracy: 1.0000 - val_loss: 6.6288e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 1.6686e-06 - accuracy: 1.0000 - val_loss: 6.3093e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 1.5750e-06 - accuracy: 1.0000 - val_loss: 6.5510e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.4712e-06 - accuracy: 1.0000 - val_loss: 6.3863e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 1.3913e-06 - accuracy: 1.0000 - val_loss: 5.9739e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 1.3153e-06 - accuracy: 1.0000 - val_loss: 6.1350e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 1.2399e-06 - accuracy: 1.0000 - val_loss: 6.1733e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 1.1793e-06 - accuracy: 1.0000 - val_loss: 5.6709e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 1.1137e-06 - accuracy: 1.0000 - val_loss: 5.7412e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 1.0541e-06 - accuracy: 1.0000 - val_loss: 5.0896e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.0076e-06 - accuracy: 1.0000 - val_loss: 5.2256e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 9.4412e-07 - accuracy: 1.0000 - val_loss: 5.0123e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 9.0449e-07 - accuracy: 1.0000 - val_loss: 4.9419e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 8.4921e-07 - accuracy: 1.0000 - val_loss: 4.5978e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 8.0972e-07 - accuracy: 1.0000 - val_loss: 4.5020e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 7.7679e-07 - accuracy: 1.0000 - val_loss: 4.2115e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 7.2613e-07 - accuracy: 1.0000 - val_loss: 4.4475e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 6.9111e-07 - accuracy: 1.0000 - val_loss: 4.2518e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 6.5505e-07 - accuracy: 1.0000 - val_loss: 4.2144e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 6.2942e-07 - accuracy: 1.0000 - val_loss: 4.2622e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 5.9455e-07 - accuracy: 1.0000 - val_loss: 4.0095e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 5.7011e-07 - accuracy: 1.0000 - val_loss: 3.6245e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 5.3078e-07 - accuracy: 1.0000 - val_loss: 3.8789e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 5.0485e-07 - accuracy: 1.0000 - val_loss: 3.8980e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 4.8086e-07 - accuracy: 1.0000 - val_loss: 3.5677e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 4.6059e-07 - accuracy: 1.0000 - val_loss: 3.3439e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 4.3526e-07 - accuracy: 1.0000 - val_loss: 3.5865e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 4.1738e-07 - accuracy: 1.0000 - val_loss: 3.6621e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 3.9562e-07 - accuracy: 1.0000 - val_loss: 3.2434e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 3.7402e-07 - accuracy: 1.0000 - val_loss: 3.2296e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 3.5688e-07 - accuracy: 1.0000 - val_loss: 3.3850e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 3.4272e-07 - accuracy: 1.0000 - val_loss: 3.2382e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 3.2201e-07 - accuracy: 1.0000 - val_loss: 3.1274e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 3.1054e-07 - accuracy: 1.0000 - val_loss: 3.0707e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 3.0034e-07 - accuracy: 1.00 - 0s 229us/step - loss: 2.9325e-07 - accuracy: 1.0000 - val_loss: 3.0296e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 2.7895e-07 - accuracy: 1.0000 - val_loss: 2.8351e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 2.6628e-07 - accuracy: 1.0000 - val_loss: 2.8416e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 2.5526e-07 - accuracy: 1.0000 - val_loss: 2.8040e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 2.4140e-07 - accuracy: 1.0000 - val_loss: 2.6566e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 2.3067e-07 - accuracy: 1.0000 - val_loss: 2.5235e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 2.1979e-07 - accuracy: 1.0000 - val_loss: 2.5298e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 2.0876e-07 - accuracy: 1.0000 - val_loss: 2.4274e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 2.0146e-07 - accuracy: 1.0000 - val_loss: 2.4846e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 1.9088e-07 - accuracy: 1.0000 - val_loss: 2.3532e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 1.8284e-07 - accuracy: 1.0000 - val_loss: 2.3278e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.7494e-07 - accuracy: 1.0000 - val_loss: 2.2941e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 1.6764e-07 - accuracy: 1.0000 - val_loss: 2.2053e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.6034e-07 - accuracy: 1.0000 - val_loss: 2.0149e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.5184e-07 - accuracy: 1.0000 - val_loss: 2.0001e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.4618e-07 - accuracy: 1.0000 - val_loss: 2.0448e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 1.3962e-07 - accuracy: 1.0000 - val_loss: 1.9112e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.3128e-07 - accuracy: 1.0000 - val_loss: 2.0059e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 1.2651e-07 - accuracy: 1.0000 - val_loss: 1.8694e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 1.2040e-07 - accuracy: 1.0000 - val_loss: 1.9607e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.1414e-07 - accuracy: 1.0000 - val_loss: 1.7971e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.1027e-07 - accuracy: 1.0000 - val_loss: 1.6073e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 1.0520e-07 - accuracy: 1.0000 - val_loss: 1.7000e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 9.9689e-08 - accuracy: 1.0000 - val_loss: 1.6662e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 9.5814e-08 - accuracy: 1.0000 - val_loss: 1.6600e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 7.5340e-08 - accuracy: 1.00 - ETA: 0s - loss: 9.5124e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.3446e-08 - accuracy: 1.00 - 0s 244us/step - loss: 8.9705e-08 - accuracy: 1.0000 - val_loss: 1.6216e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 8.6129e-08 - accuracy: 1.0000 - val_loss: 1.5691e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 8.3148e-08 - accuracy: 1.0000 - val_loss: 1.5664e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 7.8827e-08 - accuracy: 1.0000 - val_loss: 1.4255e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 7.5549e-08 - accuracy: 1.0000 - val_loss: 1.4800e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 7.1674e-08 - accuracy: 1.0000 - val_loss: 1.4743e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 6.8545e-08 - accuracy: 1.0000 - val_loss: 1.4466e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 6.7502e-08 - accuracy: 1.0000 - val_loss: 1.3115e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 6.3777e-08 - accuracy: 1.0000 - val_loss: 1.3463e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 6.0797e-08 - accuracy: 1.0000 - val_loss: 1.2998e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 5.8951e-08 - accuracy: 1.00 - 0s 240us/step - loss: 5.8562e-08 - accuracy: 1.0000 - val_loss: 1.3088e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 5.5581e-08 - accuracy: 1.0000 - val_loss: 1.2907e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 5.3793e-08 - accuracy: 1.0000 - val_loss: 1.1496e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 5.1111e-08 - accuracy: 1.0000 - val_loss: 1.1948e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 4.8876e-08 - accuracy: 1.0000 - val_loss: 1.1467e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 4.7386e-08 - accuracy: 1.0000 - val_loss: 1.1004e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 4.5001e-08 - accuracy: 1.0000 - val_loss: 1.1500e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 4.2915e-08 - accuracy: 1.0000 - val_loss: 1.1343e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 4.1276e-08 - accuracy: 1.0000 - val_loss: 1.0470e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 3.9190e-08 - accuracy: 1.0000 - val_loss: 9.8949e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 3.6955e-08 - accuracy: 1.0000 - val_loss: 9.8651e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 3.5912e-08 - accuracy: 1.0000 - val_loss: 1.0189e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 3.4571e-08 - accuracy: 1.0000 - val_loss: 9.5849e-06 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 3.3379e-08 - accuracy: 1.0000 - val_loss: 9.8889e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 3.0994e-08 - accuracy: 1.0000 - val_loss: 8.7996e-06 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 3.0398e-08 - accuracy: 1.0000 - val_loss: 9.6789e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 260us/step - loss: 2.9504e-08 - accuracy: 1.0000 - val_loss: 8.7044e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 2.7865e-08 - accuracy: 1.0000 - val_loss: 8.7781e-06 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 2.7120e-08 - accuracy: 1.0000 - val_loss: 7.9397e-06 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 8.5770e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 2.4736e-08 - accuracy: 1.0000 - val_loss: 8.1301e-06 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 2.3246e-08 - accuracy: 1.0000 - val_loss: 7.7897e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 2.2054e-08 - accuracy: 1.0000 - val_loss: 7.8082e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 2.0713e-08 - accuracy: 1.0000 - val_loss: 7.9171e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 2.0117e-08 - accuracy: 1.0000 - val_loss: 7.3124e-06 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 1.9670e-08 - accuracy: 1.0000 - val_loss: 6.8356e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 1.8477e-08 - accuracy: 1.0000 - val_loss: 7.0059e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 1.7881e-08 - accuracy: 1.0000 - val_loss: 6.6910e-06 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 1.6838e-08 - accuracy: 1.0000 - val_loss: 7.1642e-06 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.6689e-08 - accuracy: 1.0000 - val_loss: 6.1737e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.5944e-08 - accuracy: 1.0000 - val_loss: 6.4743e-06 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.5199e-08 - accuracy: 1.0000 - val_loss: 6.3398e-06 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.4454e-08 - accuracy: 1.0000 - val_loss: 6.1915e-06 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 1.3858e-08 - accuracy: 1.0000 - val_loss: 6.0558e-06 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 1.3113e-08 - accuracy: 1.0000 - val_loss: 5.7266e-06 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.2964e-08 - accuracy: 1.0000 - val_loss: 6.0546e-06 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 1.2219e-08 - accuracy: 1.0000 - val_loss: 5.6605e-06 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.1772e-08 - accuracy: 1.0000 - val_loss: 5.6438e-06 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 1.1027e-08 - accuracy: 1.0000 - val_loss: 5.2211e-06 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 5.1353e-06 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 4.6577e-06 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 4.7780e-06 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 4.9168e-06 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 8.6427e-09 - accuracy: 1.0000 - val_loss: 4.6953e-06 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 8.6427e-09 - accuracy: 1.0000 - val_loss: 4.6238e-06 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 8.1956e-09 - accuracy: 1.0000 - val_loss: 4.7858e-06 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 4.5309e-06 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 7.7486e-09 - accuracy: 1.0000 - val_loss: 4.3630e-06 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 4.4047e-06 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 4.3939e-06 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 6.8545e-09 - accuracy: 1.0000 - val_loss: 4.2177e-06 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 4.3844e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 6.1095e-09 - accuracy: 1.0000 - val_loss: 4.0217e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 6.1095e-09 - accuracy: 1.0000 - val_loss: 3.6935e-06 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 3.6453e-06 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 3.5560e-06 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 3.7489e-06 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 3.6048e-06 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 3.4255e-06 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 3.1551e-06 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 4.4703e-09 - accuracy: 1.0000 - val_loss: 3.4178e-06 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 3.0508e-06 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 3.1718e-06 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 3.0264e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.9025e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 2.8644e-06 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 2.8346e-06 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 2.7315e-06 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 2.6452e-06 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 2.7178e-06 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 2.5903e-06 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 2.5433e-06 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 2.3812e-06 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9868e-09 - accuracy: 1.00 - 0s 241us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 2.2448e-06 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.3592e-06 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 2.3229e-06 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 2.4337e-06 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.1805e-06 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.1924e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 2.0863e-06 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5327e-09 - accuracy: 1.0000 ETA: 0s - loss: 1.0145e-09 - accuracy: 1. - 0s 249us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.9249e-06 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 2.0172e-06 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.0601e-06 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.9576e-06 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.7259e-06 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.7771e-06 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.7747e-06 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 1.7759e-06 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.7533e-06 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 1.7950e-06 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.6692e-06 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.7211e-06 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.4655e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.5525e-06 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.5096e-06 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.4643e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.5310e-06 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.4905e-06 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.4661e-06 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.4965e-06 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.3242e-06 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.2641e-06 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.3201e-06 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.2635e-06 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.2962e-06 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.2563e-06 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.1741e-06 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.1991e-06 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0614e-06 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0364e-06 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0305e-06 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 260us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0370e-06 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 9.7504e-07 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.6550e-07 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0400e-06 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 9.6550e-07 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.2855e-07 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.4882e-07 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.1187e-07 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0239e-06 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.9935e-07 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.4334e-07 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.4036e-07 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9280e-07 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.6658e-07 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9161e-07 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9399e-07 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4286e-07 - val_accuracy: 1.0000 - loss: 0.0000e+00 - accuracy: 1.00\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5180e-07 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2021e-07 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3630e-07 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2200e-07 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1783e-07 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8922e-07 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1783e-07 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5943e-07 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1604e-07 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3678e-07 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0400e-07 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2605e-07 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0698e-07 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9268e-07 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7420e-07 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9089e-07 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5096e-07 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7957e-07 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3606e-07 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4798e-07 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6765e-07 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1044e-07 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.7706e-07 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.8302e-07 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2593e-07 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.9256e-07 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.8600e-07 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5918e-07 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.4905e-07 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1806e-07 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1031e-07 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1151e-07 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9601e-07 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.2939e-07 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0137e-07 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.3475e-07 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9541e-07 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7873e-07 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7038e-07 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6442e-07 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7575e-07 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5548e-07 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5846e-07 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6323e-07 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5370e-07 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3999e-07 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 373us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3582e-07 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4714e-07 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 378us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.0840e-07 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.8993e-07 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.8516e-07 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.9291e-07 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.1377e-07 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7681e-07 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.9410e-07 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.6787e-07 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5893e-07 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 368us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.6847e-07 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.0661e-07 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.4999e-07 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5357e-07 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5834e-07 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5774e-07 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5059e-07 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5417e-07 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.3152e-07 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.3390e-07 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1900e-07 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1304e-07 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.0232e-07 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9814e-07 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.0589e-07 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9099e-07 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1960e-07 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1006e-07 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 374us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9040e-07 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.8861e-07 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9934e-07 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9099e-07 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9218e-07 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.7013e-07 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.7788e-07 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.6715e-07 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.7252e-07 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.6775e-07 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.6596e-07 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.4808e-07 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.4927e-07 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.4868e-07 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5881e-07 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5046e-07 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 373us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.3258e-07 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5046e-07 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.3377e-07 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5821e-07 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5106e-07 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2543e-07 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2603e-07 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2483e-07 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1470e-07 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 368us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1649e-07 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1291e-07 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1113e-07 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2007e-07 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.4450e-07 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.9921e-07 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0934e-07 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0993e-07 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 364us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0517e-07 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0159e-07 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2483e-07 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.9205e-07 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0695e-07 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.9325e-07 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8252e-07 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.9742e-07 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8252e-07 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8133e-07 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0338e-07 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7894e-07 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7477e-07 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7417e-07 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8133e-07 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "800/800 [==============================] - 0s 435us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0397e-07 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8133e-07 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7477e-07 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7537e-07 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "800/800 [==============================] - 0s 378us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6821e-07 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7954e-07 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6821e-07 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7358e-07 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7715e-07 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5510e-07 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5570e-07 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6106e-07 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "800/800 [==============================] - 0s 374us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5272e-07 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5987e-07 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5212e-07 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6523e-07 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "800/800 [==============================] - 0s 397us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5153e-07 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5510e-07 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "800/800 [==============================] - 0s 443us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5510e-07 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5629e-07 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "800/800 [==============================] - 0s 446us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5391e-07 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "800/800 [==============================] - 0s 469us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6225e-07 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5570e-07 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "800/800 [==============================] - 0s 478us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4855e-07 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5391e-07 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4914e-07 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4557e-07 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4139e-07 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3543e-07 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4199e-07 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3841e-07 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4080e-07 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5331e-07 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4557e-07 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3364e-07 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3186e-07 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2947e-07 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3305e-07 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2709e-07 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2828e-07 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2470e-07 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3543e-07 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3364e-07 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2411e-07 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2292e-07 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2113e-07 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3543e-07 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2232e-07 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2590e-07 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2113e-07 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2411e-07 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2411e-07 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2053e-07 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1994e-07 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1696e-07 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2590e-07 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1815e-07 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1874e-07 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1457e-07 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1338e-07 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1159e-07 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1040e-07 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1159e-07 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1874e-07 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0861e-07 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0980e-07 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0802e-07 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0861e-07 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0861e-07 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0921e-07 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0921e-07 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0861e-07 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0563e-07 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0444e-07 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0563e-07 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0206e-07 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0325e-07 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0504e-07 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9908e-07 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0921e-07 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9729e-07 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0265e-07 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0206e-07 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9908e-07 - val_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9848e-07 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9431e-07 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0802e-07 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9192e-07 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9312e-07 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9431e-07 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9967e-07 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9371e-07 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9490e-07 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9550e-07 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9133e-07 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8954e-07 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "800/800 [==============================] - 0s 351us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9490e-07 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8894e-07 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8477e-07 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9192e-07 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8298e-07 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8835e-07 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8537e-07 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8835e-07 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8835e-07 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8596e-07 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9192e-07 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9729e-07 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8119e-07 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8358e-07 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8716e-07 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8596e-07 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7941e-07 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8060e-07 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8179e-07 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8000e-07 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7821e-07 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7941e-07 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8119e-07 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7583e-07 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7821e-07 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7702e-07 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7583e-07 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7643e-07 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7941e-07 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7523e-07 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8179e-07 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "800/800 [==============================] - 0s 350us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7225e-07 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7166e-07 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7285e-07 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7523e-07 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7285e-07 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7225e-07 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6987e-07 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6927e-07 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6987e-07 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6987e-07 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6868e-07 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6987e-07 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6689e-07 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6927e-07 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6868e-07 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6749e-07 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6987e-07 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6808e-07 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7047e-07 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7047e-07 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6808e-07 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6629e-07 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6749e-07 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6570e-07 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6212e-07 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6510e-07 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6331e-07 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6331e-07 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6272e-07 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "800/800 [==============================] - 0s 341us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6212e-07 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6093e-07 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6033e-07 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6153e-07 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6212e-07 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5855e-07 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5855e-07 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6153e-07 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5855e-07 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5914e-07 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5497e-07 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6033e-07 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5855e-07 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5616e-07 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5318e-07 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5557e-07 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5497e-07 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5616e-07 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5437e-07 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5378e-07 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5437e-07 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5318e-07 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5437e-07 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5139e-07 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5497e-07 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5259e-07 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5259e-07 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5080e-07 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5437e-07 - val_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5378e-07 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5080e-07 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5259e-07 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5139e-07 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5080e-07 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5318e-07 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4961e-07 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4841e-07 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4841e-07 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4782e-07 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "800/800 [==============================] - 0s 368us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4663e-07 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4663e-07 - val_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4603e-07 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "800/800 [==============================] - 0s 356us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4603e-07 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4841e-07 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4484e-07 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4484e-07 - val_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4782e-07 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4603e-07 - val_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4365e-07 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4305e-07 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4484e-07 - val_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4365e-07 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4305e-07 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4543e-07 - val_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4365e-07 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4424e-07 - val_accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4245e-07 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4186e-07 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4066e-07 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4126e-07 - val_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4126e-07 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4066e-07 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4066e-07 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3888e-07 - val_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3947e-07 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4126e-07 - val_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3888e-07 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3947e-07 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3888e-07 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4126e-07 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3709e-07 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3768e-07 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3709e-07 - val_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3768e-07 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3768e-07 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3768e-07 - val_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3709e-07 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3530e-07 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3709e-07 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3709e-07 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3530e-07 - val_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3530e-07 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3530e-07 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3530e-07 - val_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3292e-07 - val_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3292e-07 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3351e-07 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3232e-07 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3113e-07 - val_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3351e-07 - val_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3172e-07 - val_accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3113e-07 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3172e-07 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2994e-07 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3292e-07 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2994e-07 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3292e-07 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2815e-07 - val_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2934e-07 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3113e-07 - val_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2874e-07 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3113e-07 - val_accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2755e-07 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2755e-07 - val_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "800/800 [==============================] - 0s 357us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2755e-07 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2815e-07 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2755e-07 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2934e-07 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2815e-07 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2696e-07 - val_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2815e-07 - val_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2576e-07 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2576e-07 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2576e-07 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2755e-07 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2219e-07 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2278e-07 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2219e-07 - val_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2159e-07 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2219e-07 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2159e-07 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2159e-07 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2338e-07 - val_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2100e-07 - val_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2159e-07 - val_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "800/800 [==============================] - 0s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1682e-07 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1861e-07 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1682e-07 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1504e-07 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1504e-07 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1325e-07 - val_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1265e-07 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1325e-07 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1265e-07 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1265e-07 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1027e-07 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086e-07 - val_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "800/800 [==============================] - 0s 441us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1027e-07 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0848e-07 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1027e-07 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "800/800 [==============================] - 0s 351us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0848e-07 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0610e-07 - val_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0610e-07 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0788e-07 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0669e-07 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "800/800 [==============================] - 0s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0610e-07 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "800/800 [==============================] - 0s 260us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0490e-07 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "800/800 [==============================] - 0s 521us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "800/800 [==============================] - 0s 441us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0073e-07 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0133e-07 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "800/800 [==============================] - 0s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0013e-07 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.9539e-08 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7751e-08 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7751e-08 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7751e-08 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7751e-08 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8943e-08 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.7751e-08 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "800/800 [==============================] - 0s 374us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4770e-08 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4770e-08 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4770e-08 - val_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4770e-08 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4174e-08 - val_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2982e-08 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.4770e-08 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2982e-08 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2982e-08 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2982e-08 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.3578e-08 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "800/800 [==============================] - 0s 346us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.2386e-08 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "800/800 [==============================] - 0s 346us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "DS = 20\n",
    "Network20_2hl = create_network(delay_size = 20, nh_layers=2)\n",
    "results_20delays_2hiddenlayers = train_TDNN(Network20_2hl , delaysize=DS, nhlayers = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 40us/step\n",
      "0.9620000123977661\n"
     ]
    }
   ],
   "source": [
    "loss20_2hl, acc20_2hl  = Network20_2hl.evaluate(X_Test, Y_Test_OneHot)\n",
    "print(acc20_2hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lower accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 80, 30)            630       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 80, 30)            18030     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 4802      \n",
      "=================================================================\n",
      "Total params: 23,462\n",
      "Trainable params: 23,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DS = 20\n",
    "Network20_2hl_internalmemory  = create_network(delay_size = 20, nh_layers=2, internal_memory= True)\n",
    "Network20_2hl_internalmemory.summary()\n",
    "# results_20delays_2hiddenlayers = train_TDNN(Network20_2hl , delaysize=DS, nhlayers = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 482us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0002e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0002e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0002e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0002e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1194e-08 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0598e-08 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0002e-08 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8810e-08 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.8214e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7022e-08 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.6426e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.00 - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.00000s - loss: 0.0000e+00 - accuracy: \n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 321us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 345us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2850e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-08 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.00 - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.1062e-08 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.8081e-08 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7485e-08 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6889e-08 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 329us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5697e-08 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4505e-08 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3909e-08 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.3313e-08 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2717e-08 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 44us/step\n",
      "0.9620000123977661\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20delays_2hiddenlayers = train_TDNN(Network20_2hl_internalmemory , delaysize=DS, nhlayers = 2, verbose = 1)\n",
    "loss20_2hl_int_memory, acc20_2hl_int_memmory  = Network20_2hl.evaluate(X_Test, Y_Test_OneHot)\n",
    "print(acc20_2hl_int_memmory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 80, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building RNN \n",
    "def create_RNN(units): \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units, input_shape = (80,1), return_sequences = False))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(2, activation = 'softmax'))\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 502\n",
      "Trainable params: 502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = create_RNN(10)\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(network , units, verbose = 1, batchsize = 10, epochs = 1000):\n",
    "    Path1 =  'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\SavedModel'\n",
    "    Path2 = '\\RNN_units_' + str(units) +'.h5'\n",
    "    SavePath = Path1 + Path2\n",
    "    StopCriteria = 'val_loss'\n",
    "    callbacks = [EarlyStopping(monitor=StopCriteria, patience=20),\n",
    "             ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n",
    "    network = network\n",
    "    network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history = network.fit(X_Train,Y_Train_oneHot,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batchsize, # Early stopping,\n",
    "                         verbose = verbose,\n",
    "                     validation_data=(X_Val,Y_Val_oneHot),\n",
    "                     callbacks = callbacks)\n",
    "    return history\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3663 - accuracy: 0.8037 - val_loss: 0.1160 - val_accuracy: 0.9850\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8950 - val_loss: 1.0198 - val_accuracy: 0.5850\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.4485 - accuracy: 0.8425 - val_loss: 0.2252 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1291 - accuracy: 0.9975 - val_loss: 0.0909 - val_accuracy: 0.9950\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.9950 - val_loss: 0.0518 - val_accuracy: 0.9950\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9975 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0182 - accuracy: 0.9987 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.9762 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1060 - accuracy: 0.9800 - val_loss: 0.3301 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.5527 - accuracy: 0.8000 - val_loss: 0.4463 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2777 - accuracy: 0.9075 - val_loss: 0.1677 - val_accuracy: 0.9850\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1068 - accuracy: 0.9900 - val_loss: 0.0920 - val_accuracy: 0.9950\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0592 - accuracy: 0.9987 - val_loss: 0.0619 - val_accuracy: 0.9950\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0398 - accuracy: 0.9975 - val_loss: 0.0435 - val_accuracy: 0.9950\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0279 - accuracy: 0.9975 - val_loss: 0.0347 - val_accuracy: 0.9950\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0188 - accuracy: 0.9987 - val_loss: 0.0251 - val_accuracy: 0.9950\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.0500 - val_accuracy: 0.9950\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0227 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9950\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.0270 - accuracy: 0.9962 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.5852 - accuracy: 0.7038 - val_loss: 0.7360 - val_accuracy: 0.5750\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.7519 - accuracy: 0.4812 - val_loss: 0.6897 - val_accuracy: 0.5750\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.7072 - accuracy: 0.4462 - val_loss: 0.6962 - val_accuracy: 0.5750\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.6981 - accuracy: 0.4575 - val_loss: 0.7004 - val_accuracy: 0.4250\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.6945 - accuracy: 0.5025 - val_loss: 0.6977 - val_accuracy: 0.4250\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.6728 - accuracy: 0.5300 - val_loss: 0.6522 - val_accuracy: 0.4250\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2567 - accuracy: 0.9463 - val_loss: 0.1402 - val_accuracy: 0.9950\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.9962 - val_loss: 0.0569 - val_accuracy: 0.9950\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1100 - accuracy: 0.9850 - val_loss: 0.0396 - val_accuracy: 0.9950\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.9862 - val_loss: 0.1281 - val_accuracy: 0.9650\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0461 - accuracy: 0.9900 - val_loss: 0.0304 - val_accuracy: 0.9950\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.9862 - val_loss: 0.1897 - val_accuracy: 0.9650\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1181 - accuracy: 0.9762 - val_loss: 0.1517 - val_accuracy: 0.9650\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0957 - accuracy: 0.9775 - val_loss: 0.1438 - val_accuracy: 0.9650\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0341 - accuracy: 0.9962 - val_loss: 0.0537 - val_accuracy: 0.9900\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.0267 - accuracy: 0.9962 - val_loss: 0.0300 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "u = 30\n",
    "rnn = create_RNN(u)\n",
    "# rnn.summary()\n",
    "RNN_30_history = train_RNN( rnn, units = u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 218us/step\n",
      "0.9179999828338623\n"
     ]
    }
   ],
   "source": [
    "accrnn_30, lossrnn_30  = rnn.evaluate(X_Test, Y_Test_OneHot)\n",
    "print(lossrnn_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = rnn.predict(X_Test)\n",
    "#\n",
    "# Get the max probabilites for each rows\n",
    "probs = np.max(predictions, axis = 1)\n",
    "#\n",
    "# Get the predicted classes for each row  - I have plus 1 because this \n",
    "Y_Predicted_classes = np.argmax(predictions, axis = 1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ConfMat = confusion_matrix(YLabels, Y_Predicted_classes)\n",
    "import seaborn as sn\n",
    "confMat = np.transpose(ConfMat)\n",
    "df_cm = pd.DataFrame(ConfMat, index = [\"Predicted 0\", \"Predicted 1\"],\n",
    "                  columns = [\"True 0\", \"True 1\"])\n",
    "plt.figure(figsize = (7,5))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.title('RNN units 30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### networks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
