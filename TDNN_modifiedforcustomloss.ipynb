{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoda Akl \n",
    "-- Adding the cost function of minimum error entropy to the same example solved in the notebook \"TimeDelayNN_RecurrentNN.ipynb\"\n",
    "<!-- TDNN code -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\skypi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Most general notebook \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "# Form our test and train data\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Form our test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random \n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import models \n",
    "from keras import layers \n",
    "from keras import initializers\n",
    "from keras.models import load_model\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "def create_string(grammar = True):\n",
    "    \"\"\" Returns one array of length 60 that either belongs to the grammar or doesn't \"\"\"\n",
    "    n = 60 \n",
    "    string_arr = np.ones(n)*n\n",
    "    if grammar ==True: \n",
    "\n",
    "        s = 0\n",
    "        while s<n:\n",
    "            n_zero = random.randint(1,11)\n",
    "            if s+n_zero < (n-1):\n",
    "                string_arr[s:s+n_zero] = np.zeros(n_zero)\n",
    "                string_arr[s+n_zero] = 1\n",
    "                s = s+n_zero+1\n",
    "            else:\n",
    "                string_arr[s:] = np.zeros(n-s)\n",
    "                s = n\n",
    "        \n",
    "    \n",
    "    if grammar == False: \n",
    "        curr_idx = 0\n",
    "        while curr_idx<n:\n",
    "        #     curr_idx  = s\n",
    "            last_zero_idx = random.randint(curr_idx+1,curr_idx+11)\n",
    "            if (last_zero_idx <= n):\n",
    "                string_arr[curr_idx:last_zero_idx] = np.zeros(last_zero_idx -curr_idx)\n",
    "                curr_idx = last_zero_idx\n",
    "            else:\n",
    "                string_arr[curr_idx:] = np.zeros(n -curr_idx)\n",
    "                curr_idx = n\n",
    "            ####\n",
    "        #     for the ones string\n",
    "            last_ones_idx = random.randint(curr_idx+1,curr_idx+11)\n",
    "            if (last_ones_idx <= n):\n",
    "                string_arr[curr_idx:last_ones_idx] = np.ones(last_ones_idx -curr_idx)\n",
    "                curr_idx = last_ones_idx\n",
    "            else:\n",
    "                string_arr[curr_idx:] = np.ones(n -curr_idx)\n",
    "                curr_idx = n\n",
    "                \n",
    "    return string_arr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating data : \n",
    "# Last column is the labels \n",
    "# first 500 samples are grammar \n",
    "# last / second 500 samples are grammar \n",
    "DataBase = np.ones((1000,61))*200\n",
    "for i in range(500):\n",
    "    DataBase[i,:-1] = create_string(grammar = True)\n",
    "    DataBase[i,-1] = 1\n",
    "    DataBase[i+500,:-1] = create_string(grammar = False)\n",
    "    DataBase[i+500,-1] = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape  (800, 80)\n",
      "X_Val shape  (200, 80)\n",
      "Y_Train_oneHot shape  (800, 2)\n",
      "Y_Val_oneHot shape  (200, 2)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing the data \n",
    "## data preprocessing \n",
    "# seperate label from sequence\n",
    "Data = DataBase[:,:-1]\n",
    "Label = DataBase[:,-1]\n",
    "\n",
    "PaddedData = np.zeros((Data.shape[0], 81))\n",
    "\n",
    "PaddedData[:,:60] = Data\n",
    "PaddedData[:,-1] = Label\n",
    "np.random.shuffle(PaddedData)\n",
    "Data_Shuffled_WLabel = PaddedData\n",
    "Labels = Data_Shuffled_WLabel[:,-1]\n",
    "Data_processed = Data_Shuffled_WLabel[:,:-1]\n",
    "scl = MinMaxScaler()\n",
    "scl.fit(Data_processed)\n",
    "Data_processed = scl.transform(Data_processed)\n",
    "from keras.utils import to_categorical\n",
    "YTrain_oneHot = to_categorical(Labels)\n",
    "XTrain = Data_processed\n",
    "# \n",
    "X_Train,X_Val,Y_Train_oneHot,Y_Val_oneHot = train_test_split(XTrain,YTrain_oneHot, test_size=0.2, random_state=42)\n",
    "print('X_Train shape ', X_Train.shape)\n",
    "print('X_Val shape ', X_Val.shape)\n",
    "print('Y_Train_oneHot shape ', Y_Train_oneHot.shape)\n",
    "print('Y_Val_oneHot shape ', Y_Val_oneHot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Test shape  (500, 80)\n",
      "Y_Test_OneHot shape  (500, 2)\n"
     ]
    }
   ],
   "source": [
    "### preprocessing the testing data \n",
    "path = 'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\hmw4test.csv'\n",
    "TestData=pd.read_csv(path,header=None)\n",
    "TestData = shuffle(TestData,random_state=42)    # by setting the random state we will get reproducible results\n",
    "# Split the data into training and testing \n",
    "# Scale the input \n",
    "#\n",
    "XTest = TestData.iloc[:,:-1].values\n",
    "# scl = MinMaxScaler() # for scaling the data\n",
    "# XDataSc = scl.fit_transfo.rm(XData)\n",
    "X_Test = scl.transform(XTest)\n",
    "# XTest = XTest.reshape((XTest.shape[0], XTest.shape[1],1))\n",
    "YLabels = TestData.iloc[:,-1].values\n",
    "Y_Test_OneHot = to_categorical(YLabels)\n",
    "# X_Test = XTest.reshape(XTest.shape[0], XTest.shape[1],1)\n",
    "print('X_Test shape ', X_Test.shape)\n",
    "print('Y_Test_OneHot shape ', Y_Test_OneHot.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape inputs \n",
    "X_Test  = X_Test.reshape(X_Test.shape[0], X_Test.shape[1],1)\n",
    "X_Val   = X_Val.reshape(X_Val.shape[0], X_Val.shape[1],1)\n",
    "X_Train = X_Train.reshape(X_Train.shape[0], X_Train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "## I want to define a model that has input of delay size \n",
    "def create_network(delay_size = 7, filters = 30, train_size = 800, batchsize = 10, nh_layers = 1, internal_memory = False):\n",
    "    net =models.Sequential()\n",
    "    filters = filters \n",
    "    delay_size = delay_size\n",
    "    input_shape = (train_size,80)\n",
    "    net.add(layers.Conv1D(filters ,  delay_size,activation='relu', input_shape = (80,1) ,padding=\"same\"))\n",
    "    \n",
    "    if nh_layers ==1 : \n",
    "        net.add(layers.Flatten())\n",
    "        net.add(layers.Dense(2,activation='softmax'))\n",
    "        \n",
    "        \n",
    "    if nh_layers > 1:\n",
    "        for i in range(nh_layers - 1):\n",
    "            if internal_memory == True:\n",
    "#                 net.add(layers.Flatten())\n",
    "                net.add(layers.Conv1D(filters ,  delay_size ,activation='relu',padding=\"same\"))\n",
    "                net.add(layers.Flatten())\n",
    "                net.add(layers.Dense(2,activation='softmax'))\n",
    "            else:\n",
    "                net.add(layers.Flatten())\n",
    "                net.add(layers.Dense(50, activation = 'relu'))\n",
    "                net.add(layers.Dense(2,activation='softmax'))\n",
    "    \n",
    "#     net.add(layers.Dense(2,activation='softmax'))\n",
    "    \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path( nhidden = 1, delay = 20, internal_memory = False):\n",
    "    if internal_memory == False: \n",
    "        internal_memory = 'wo'\n",
    "    else: \n",
    "        internal_memory = 'w'\n",
    "    path1 = 'C:\\everything\\Courses\\EEL6814 - Neural Networks and Deep Learning\\HW\\HW4\\SavedModel\\TDNN' + '_layers_' + str(nhidden) + '_delay_' + str(delay)+ '_'+ internal_memory  +'_memory.h5'\n",
    "    return path1\n",
    "    \n",
    "    \n",
    "def train_TDNN(network , SavePath, delaysize,  verbose = 1, batchsize = 10, epochs = 1000):\n",
    "    StopCriteria = 'val_loss'\n",
    "    callbacks = [EarlyStopping(monitor=StopCriteria, patience=20),\n",
    "             ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n",
    "    network = network\n",
    "    network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history = network.fit(X_Train,Y_Train_oneHot,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batchsize, # Early stopping,\n",
    "                         verbose = verbose,\n",
    "                     validation_data=(X_Val,Y_Val_oneHot),\n",
    "                     callbacks = callbacks)\n",
    "    return history\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 80, 30)            240       \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 50)                120050    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 120,392\n",
      "Trainable params: 120,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nettt = create_network(nh_layers = 2, internal_memory = False)\n",
    "nettt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 647us/step - loss: 0.1045 - accuracy: 0.9513 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 8.5415e-04 - accuracy: 1.0000 - val_loss: 6.0434e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 331us/step - loss: 4.9601e-04 - accuracy: 1.0000 - val_loss: 2.4111e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 337us/step - loss: 2.8671e-04 - accuracy: 1.0000 - val_loss: 1.6149e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 352us/step - loss: 1.8615e-04 - accuracy: 1.0000 - val_loss: 8.7410e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 341us/step - loss: 1.4566e-04 - accuracy: 1.0000 - val_loss: 9.7313e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 1.0995e-04 - accuracy: 1.0000 - val_loss: 8.2350e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 347us/step - loss: 8.6149e-05 - accuracy: 1.0000 - val_loss: 4.4125e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 7.2549e-05 - accuracy: 1.0000 - val_loss: 4.2691e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 348us/step - loss: 5.8458e-05 - accuracy: 1.0000 - val_loss: 3.9279e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 343us/step - loss: 4.7985e-05 - accuracy: 1.0000 - val_loss: 2.9599e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "350/800 [============>.................] - ETA: 0s - loss: 4.3764e-05 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-c36be668591f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_TDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnettt\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelaysize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-2876788139f3>\u001b[0m in \u001b[0;36mtrain_TDNN\u001b[1;34m(network, SavePath, delaysize, verbose, batchsize, epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m                          \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_Val_oneHot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                      callbacks = callbacks)\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = 'test.h5'\n",
    "train_TDNN(nettt ,path, delaysize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the condition table each row corresponds to set of conditions \n",
    "# first column is delay line , 2nd column is number of hidden layers, third column represents internal memory\n",
    "Cond_Table = [[7,1,False],[20,1,False], [7,2,False], [20,2,False], [7,2,True], [20,2,True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_7_nh_1_mem_False', 'd_20_nh_1_mem_False', 'd_7_nh_2_mem_False', 'd_20_nh_2_mem_False', 'd_7_nh_2_mem_True', 'd_20_nh_2_mem_True']\n"
     ]
    }
   ],
   "source": [
    "key_list = []\n",
    "for i in range(len(Cond_Table)):\n",
    "    new_key = \"d_\" + str(Cond_Table[i][0]) + \"_nh_\" +  str(Cond_Table[i][1]) + '_mem_' + str(Cond_Table[i][2])\n",
    "    key_list.append(new_key)\n",
    "print(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tdnn on d_7_nh_1_mem_False\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 487us/step - loss: 0.3181 - accuracy: 0.8425 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0261 - accuracy: 0.9962 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.8174e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.1804e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.3964e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 8.2367e-04 - accuracy: 1.0000 - val_loss: 4.0072e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 7.4362e-04 - accuracy: 1.0000 - val_loss: 4.3200e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 5.9590e-04 - accuracy: 1.0000 - val_loss: 2.8685e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 5.2490e-04 - accuracy: 1.0000 - val_loss: 3.5123e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.5479e-04 - accuracy: 1.0000 - val_loss: 2.4643e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.0562e-04 - accuracy: 1.0000 - val_loss: 2.0235e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 3.5412e-04 - accuracy: 1.0000 - val_loss: 1.8060e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 3.1756e-04 - accuracy: 1.0000 - val_loss: 1.7409e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 2.8283e-04 - accuracy: 1.0000 - val_loss: 1.4629e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 2.5531e-04 - accuracy: 1.0000 - val_loss: 1.7065e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 2.2141e-04 - accuracy: 1.0000 - val_loss: 1.2409e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 2.0547e-04 - accuracy: 1.0000 - val_loss: 1.3467e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.8914e-04 - accuracy: 1.0000 - val_loss: 1.3322e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 1.2311e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.5284e-04 - accuracy: 1.0000 - val_loss: 9.3732e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 1.4366e-04 - accuracy: 1.0000 - val_loss: 9.9098e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 1.3063e-04 - accuracy: 1.0000 - val_loss: 7.4454e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.2117e-04 - accuracy: 1.0000 - val_loss: 8.4471e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.1352e-04 - accuracy: 1.0000 - val_loss: 7.2621e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.0229e-04 - accuracy: 1.0000 - val_loss: 7.0413e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 9.5185e-05 - accuracy: 1.0000 - val_loss: 6.8269e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 8.9705e-05 - accuracy: 1.0000 - val_loss: 6.6058e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 8.1837e-05 - accuracy: 1.0000 - val_loss: 5.6171e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 7.7236e-05 - accuracy: 1.0000 - val_loss: 5.4421e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 7.3075e-05 - accuracy: 1.0000 - val_loss: 4.7585e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 6.7244e-05 - accuracy: 1.0000 - val_loss: 5.3225e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 6.2866e-05 - accuracy: 1.0000 - val_loss: 4.6787e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.9130e-05 - accuracy: 1.0000 - val_loss: 4.7584e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 5.6437e-05 - accuracy: 1.0000 - val_loss: 4.7615e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 5.2629e-05 - accuracy: 1.0000 - val_loss: 3.8186e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 4.9237e-05 - accuracy: 1.0000 - val_loss: 4.1441e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 4.5475e-05 - accuracy: 1.0000 - val_loss: 3.0224e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 4.2613e-05 - accuracy: 1.0000 - val_loss: 3.1669e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 3.7216e-05 - accuracy: 1.00 - 0s 181us/step - loss: 3.9956e-05 - accuracy: 1.0000 - val_loss: 3.0965e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 3.8159e-05 - accuracy: 1.0000 - val_loss: 2.9655e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 3.5875e-05 - accuracy: 1.0000 - val_loss: 2.6862e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 3.3611e-05 - accuracy: 1.0000 - val_loss: 2.5934e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 3.1499e-05 - accuracy: 1.0000 - val_loss: 2.3201e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.0705e-05 - accuracy: 1.0000 - val_loss: 2.4239e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 2.9216e-05 - accuracy: 1.0000 - val_loss: 2.2800e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.7030e-05 - accuracy: 1.0000 - val_loss: 1.9437e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 2.5488e-05 - accuracy: 1.0000 - val_loss: 1.7210e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 2.4592e-05 - accuracy: 1.0000 - val_loss: 2.0021e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 2.3103e-05 - accuracy: 1.0000 - val_loss: 1.5819e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 2.1795e-05 - accuracy: 1.0000 - val_loss: 1.6327e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 2.0389e-05 - accuracy: 1.0000 - val_loss: 1.5361e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 1.9345e-05 - accuracy: 1.0000 - val_loss: 1.6393e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.8242e-05 - accuracy: 1.0000 - val_loss: 1.4812e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.7294e-05 - accuracy: 1.0000 - val_loss: 1.3436e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.6653e-05 - accuracy: 1.0000 - val_loss: 1.3415e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.5836e-05 - accuracy: 1.0000 - val_loss: 1.3151e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.5044e-05 - accuracy: 1.0000 - val_loss: 1.2276e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.4218e-05 - accuracy: 1.0000 - val_loss: 1.0024e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.3573e-05 - accuracy: 1.0000 - val_loss: 1.1209e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 1.2837e-05 - accuracy: 1.0000 - val_loss: 1.0441e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.2187e-05 - accuracy: 1.0000 - val_loss: 9.5411e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.1700e-05 - accuracy: 1.0000 - val_loss: 9.1794e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.1470e-05 - accuracy: 1.0000 - val_loss: 9.4737e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.0533e-05 - accuracy: 1.0000 - val_loss: 9.9442e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 1.0158e-05 - accuracy: 1.0000 - val_loss: 9.8339e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 177us/step - loss: 9.4450e-06 - accuracy: 1.0000 - val_loss: 8.7824e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 9.0701e-06 - accuracy: 1.0000 - val_loss: 8.3415e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 8.8334e-06 - accuracy: 1.0000 - val_loss: 7.5188e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 8.3861e-06 - accuracy: 1.0000 - val_loss: 8.5994e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 8.0336e-06 - accuracy: 1.0000 - val_loss: 8.4683e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 7.4835e-06 - accuracy: 1.0000 - val_loss: 7.2214e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 7.3343e-06 - accuracy: 1.0000 - val_loss: 7.5847e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 6.8331e-06 - accuracy: 1.0000 - val_loss: 6.9377e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 6.4273e-06 - accuracy: 1.0000 - val_loss: 6.1125e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 6.1022e-06 - accuracy: 1.0000 - val_loss: 5.5477e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 5.9861e-06 - accuracy: 1.0000 - val_loss: 6.1041e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 5.5541e-06 - accuracy: 1.0000 - val_loss: 5.6227e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 5.3740e-06 - accuracy: 1.0000 - val_loss: 4.9506e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 5.1395e-06 - accuracy: 1.0000 - val_loss: 5.0912e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 4.8558e-06 - accuracy: 1.0000 - val_loss: 4.3571e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 4.7682e-06 - accuracy: 1.0000 - val_loss: 4.9035e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 4.4888e-06 - accuracy: 1.0000 - val_loss: 4.1902e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 4.2713e-06 - accuracy: 1.0000 - val_loss: 4.2039e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 3.9835e-06 - accuracy: 1.0000 - val_loss: 4.0663e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 3.8457e-06 - accuracy: 1.0000 - val_loss: 3.8094e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 3.6471e-06 - accuracy: 1.0000 - val_loss: 3.8332e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.4845e-06 - accuracy: 1.0000 - val_loss: 3.7218e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 3.3433e-06 - accuracy: 1.0000 - val_loss: 3.4304e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.1980e-06 - accuracy: 1.0000 - val_loss: 3.4316e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 3.0540e-06 - accuracy: 1.0000 - val_loss: 3.2886e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.8860e-06 - accuracy: 1.0000 - val_loss: 3.0252e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.7362e-06 - accuracy: 1.0000 - val_loss: 3.1491e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 2.7257e-06 - accuracy: 1.0000 - val_loss: 3.2540e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 2.5648e-06 - accuracy: 1.0000 - val_loss: 2.5532e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 2.4116e-06 - accuracy: 1.0000 - val_loss: 2.3816e-06 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.2843e-06 - accuracy: 1.0000 - val_loss: 2.6378e-06 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 2.2042e-06 - accuracy: 1.0000 - val_loss: 2.1694e-06 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.1221e-06 - accuracy: 1.0000 - val_loss: 2.2731e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 2.0300e-06 - accuracy: 1.0000 - val_loss: 2.3017e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.9444e-06 - accuracy: 1.0000 - val_loss: 2.2457e-06 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.8252e-06 - accuracy: 1.0000 - val_loss: 2.2588e-06 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.7368e-06 - accuracy: 1.0000 - val_loss: 2.1229e-06 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 1.6756e-06 - accuracy: 1.0000 - val_loss: 1.9644e-06 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.6145e-06 - accuracy: 1.0000 - val_loss: 1.8214e-06 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 1.5440e-06 - accuracy: 1.0000 - val_loss: 1.8637e-06 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 1.4747e-06 - accuracy: 1.0000 - val_loss: 1.9137e-06 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.3905e-06 - accuracy: 1.0000 - val_loss: 1.7272e-06 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.3463e-06 - accuracy: 1.0000 - val_loss: 1.6950e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.2800e-06 - accuracy: 1.0000 - val_loss: 1.6205e-06 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.2201e-06 - accuracy: 1.0000 - val_loss: 1.5663e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 1.1655e-06 - accuracy: 1.0000 - val_loss: 1.5949e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 1.1292e-06 - accuracy: 1.0000 - val_loss: 1.4030e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 1.0720e-06 - accuracy: 1.0000 - val_loss: 1.4042e-06 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.0201e-06 - accuracy: 1.0000 - val_loss: 1.3523e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 9.7467e-07 - accuracy: 1.0000 - val_loss: 1.2111e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 9.3324e-07 - accuracy: 1.0000 - val_loss: 1.2230e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 8.9227e-07 - accuracy: 1.0000 - val_loss: 1.2147e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 8.5010e-07 - accuracy: 1.0000 - val_loss: 1.1372e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 8.0942e-07 - accuracy: 1.0000 - val_loss: 1.1217e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 7.9020e-07 - accuracy: 1.0000 - val_loss: 1.2099e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 7.5146e-07 - accuracy: 1.0000 - val_loss: 9.6376e-07 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 7.1078e-07 - accuracy: 1.0000 - val_loss: 1.0132e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 6.8947e-07 - accuracy: 1.0000 - val_loss: 9.3158e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 6.6116e-07 - accuracy: 1.0000 - val_loss: 9.7389e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 6.2077e-07 - accuracy: 1.0000 - val_loss: 9.6018e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 5.9917e-07 - accuracy: 1.0000 - val_loss: 8.1595e-07 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 5.7592e-07 - accuracy: 1.0000 - val_loss: 7.8794e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 5.5178e-07 - accuracy: 1.0000 - val_loss: 7.3549e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 5.2630e-07 - accuracy: 1.0000 - val_loss: 7.4384e-07 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 5.0484e-07 - accuracy: 1.0000 - val_loss: 7.7185e-07 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 4.8413e-07 - accuracy: 1.0000 - val_loss: 8.1059e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 4.6000e-07 - accuracy: 1.0000 - val_loss: 7.5337e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 4.3615e-07 - accuracy: 1.0000 - val_loss: 6.9675e-07 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 4.1902e-07 - accuracy: 1.0000 - val_loss: 6.5980e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 4.0486e-07 - accuracy: 1.0000 - val_loss: 6.0139e-07 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.8668e-07 - accuracy: 1.0000 - val_loss: 6.3119e-07 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.6970e-07 - accuracy: 1.0000 - val_loss: 6.0139e-07 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 3.5167e-07 - accuracy: 1.0000 - val_loss: 5.6563e-07 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.4302e-07 - accuracy: 1.0000 - val_loss: 5.8589e-07 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 3.2425e-07 - accuracy: 1.0000 - val_loss: 5.3881e-07 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 3.0875e-07 - accuracy: 1.0000 - val_loss: 4.7742e-07 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 3.0041e-07 - accuracy: 1.0000 - val_loss: 5.2391e-07 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 2.8580e-07 - accuracy: 1.0000 - val_loss: 4.8100e-07 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.6688e-07 - accuracy: 1.0000 - val_loss: 4.9709e-07 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.5749e-07 - accuracy: 1.0000 - val_loss: 4.4106e-07 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.4721e-07 - accuracy: 1.0000 - val_loss: 4.6371e-07 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 2.3812e-07 - accuracy: 1.0000 - val_loss: 4.4285e-07 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 2.2679e-07 - accuracy: 1.0000 - val_loss: 4.2735e-07 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.2679e-07 - accuracy: 1.0000 - val_loss: 4.5060e-07 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.0623e-07 - accuracy: 1.0000 - val_loss: 4.0113e-07 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.9893e-07 - accuracy: 1.0000 - val_loss: 3.9338e-07 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 1.9029e-07 - accuracy: 1.0000 - val_loss: 3.4212e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 1.8775e-07 - accuracy: 1.0000 - val_loss: 3.3855e-07 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.8030e-07 - accuracy: 1.0000 - val_loss: 2.8848e-07 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.6347e-07 - accuracy: 1.0000 - val_loss: 3.6716e-07 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.6004e-07 - accuracy: 1.0000 - val_loss: 3.4928e-07 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 314us/step - loss: 1.5363e-07 - accuracy: 1.0000 - val_loss: 3.2782e-07 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.4758e-07 - accuracy: 1.00 - 0s 235us/step - loss: 1.4603e-07 - accuracy: 1.0000 - val_loss: 3.0636e-07 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 1.3918e-07 - accuracy: 1.0000 - val_loss: 2.8967e-07 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 1.3605e-07 - accuracy: 1.0000 - val_loss: 2.5868e-07 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.3053e-07 - accuracy: 1.0000 - val_loss: 2.5570e-07 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.2219e-07 - accuracy: 1.0000 - val_loss: 2.7179e-07 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.1772e-07 - accuracy: 1.0000 - val_loss: 2.5272e-07 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.1280e-07 - accuracy: 1.0000 - val_loss: 2.5093e-07 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.0744e-07 - accuracy: 1.0000 - val_loss: 2.2590e-07 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.0505e-07 - accuracy: 1.0000 - val_loss: 2.1815e-07 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 9.9242e-08 - accuracy: 1.0000 - val_loss: 2.4259e-07 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 9.5814e-08 - accuracy: 1.0000 - val_loss: 2.1517e-07 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 9.0450e-08 - accuracy: 1.0000 - val_loss: 2.3186e-07 - val_accuracy: 1.00000s - loss: 1.0814e-07 - accuracy: 1.00\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 8.6427e-08 - accuracy: 1.0000 - val_loss: 1.8298e-07 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 8.2552e-08 - accuracy: 1.0000 - val_loss: 1.8775e-07 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 7.8380e-08 - accuracy: 1.0000 - val_loss: 1.8298e-07 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 7.4208e-08 - accuracy: 1.0000 - val_loss: 1.8596e-07 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 7.1823e-08 - accuracy: 1.0000 - val_loss: 1.8656e-07 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 6.9886e-08 - accuracy: 1.0000 - val_loss: 1.6629e-07 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 6.7502e-08 - accuracy: 1.0000 - val_loss: 1.8000e-07 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 6.3181e-08 - accuracy: 1.0000 - val_loss: 1.5437e-07 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 6.1691e-08 - accuracy: 1.0000 - val_loss: 1.7106e-07 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 5.6028e-08 - accuracy: 1.0000 - val_loss: 1.6629e-07 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 5.3942e-08 - accuracy: 1.0000 - val_loss: 1.5795e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 5.1707e-08 - accuracy: 1.0000 - val_loss: 1.5020e-07 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 4.8578e-08 - accuracy: 1.0000 - val_loss: 1.2994e-07 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 4.6194e-08 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 4.5598e-08 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 4.3660e-08 - accuracy: 1.0000 - val_loss: 1.3172e-07 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 4.2915e-08 - accuracy: 1.0000 - val_loss: 1.2994e-07 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 3.9339e-08 - accuracy: 1.0000 - val_loss: 1.1563e-07 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 3.8594e-08 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 3.7104e-08 - accuracy: 1.0000 - val_loss: 1.0848e-07 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 3.5316e-08 - accuracy: 1.0000 - val_loss: 1.1384e-07 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 3.3826e-08 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.2932e-08 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 3.0994e-08 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 2.9504e-08 - accuracy: 1.0000 - val_loss: 1.0014e-07 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 2.8163e-08 - accuracy: 1.0000 - val_loss: 9.2387e-08 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.7567e-08 - accuracy: 1.0000 - val_loss: 8.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 2.5928e-08 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 2.3991e-08 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.2650e-08 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 2.2352e-08 - accuracy: 1.0000 - val_loss: 7.8082e-08 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.1607e-08 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 2.0415e-08 - accuracy: 1.0000 - val_loss: 8.0466e-08 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.8775e-08 - accuracy: 1.0000 - val_loss: 6.8545e-08 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 1.8626e-08 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.7434e-08 - accuracy: 1.0000 - val_loss: 6.6161e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 1.6987e-08 - accuracy: 1.0000 - val_loss: 6.4373e-08 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 1.6540e-08 - accuracy: 1.0000 - val_loss: 6.2585e-08 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.5795e-08 - accuracy: 1.0000 - val_loss: 5.9604e-08 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.5646e-08 - accuracy: 1.0000 - val_loss: 6.0796e-08 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4901e-08 - accuracy: 1.0000 - val_loss: 5.9604e-08 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.4156e-08 - accuracy: 1.0000 - val_loss: 5.8412e-08 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 1.3560e-08 - accuracy: 1.0000 - val_loss: 5.7220e-08 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.3113e-08 - accuracy: 1.0000 - val_loss: 5.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 5.0068e-08 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.1474e-08 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 1.1474e-08 - accuracy: 1.0000 - val_loss: 4.6491e-08 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 1.1027e-08 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.0580e-08 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 8.9407e-09 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 8.0466e-09 - accuracy: 1.0000 - val_loss: 3.9339e-08 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 7.5996e-09 - accuracy: 1.0000 - val_loss: 3.8147e-08 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 7.1526e-09 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 6.7055e-09 - accuracy: 1.0000 - val_loss: 3.3975e-08 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 6.2585e-09 - accuracy: 1.0000 - val_loss: 3.0994e-08 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 3.5763e-08 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 5.8115e-09 - accuracy: 1.0000 - val_loss: 3.2186e-08 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 3.2782e-08 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 3.3379e-08 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 2.8014e-08 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 2.7418e-08 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 2.6822e-08 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 2.6822e-08 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 2.6226e-08 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 4.0233e-09 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 2.6822e-08 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 2.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 2.5034e-08 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.2054e-08 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 1.9669e-08 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 2.0266e-08 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 2.0266e-08 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 2.0266e-08 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 277us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.00000s - loss: 3.6680e-10 - accuracy: 1.00\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.3374e-10 - accuracy: 1.00 - 0s 218us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 255us/step\n",
      "tdnn on d_20_nh_1_mem_False\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 565us/step - loss: 0.2583 - accuracy: 0.8888 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.4920e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.0744e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.0854e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.6396e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 7.2403e-04 - accuracy: 1.0000 - val_loss: 2.3936e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 6.8525e-04 - accuracy: 1.0000 - val_loss: 2.5855e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 5.2839e-04 - accuracy: 1.0000 - val_loss: 1.8485e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 5.5335e-04 - accuracy: 1.0000 - val_loss: 3.1355e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 3.9839e-04 - accuracy: 1.0000 - val_loss: 1.6639e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 3.7799e-04 - accuracy: 1.0000 - val_loss: 1.6912e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 3.3122e-04 - accuracy: 1.0000 - val_loss: 2.2084e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 2.5652e-04 - accuracy: 1.0000 - val_loss: 1.1617e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 2.6004e-04 - accuracy: 1.0000 - val_loss: 1.0719e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 2.1596e-04 - accuracy: 1.0000 - val_loss: 1.1141e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 1.9336e-04 - accuracy: 1.0000 - val_loss: 8.9064e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 1.7741e-04 - accuracy: 1.0000 - val_loss: 6.3248e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 1.7264e-04 - accuracy: 1.0000 - val_loss: 7.0652e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 1.4858e-04 - accuracy: 1.0000 - val_loss: 7.5037e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 1.4225e-04 - accuracy: 1.0000 - val_loss: 6.1187e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 1.2738e-04 - accuracy: 1.0000 - val_loss: 6.4799e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.1184e-04 - accuracy: 1.0000 - val_loss: 5.1060e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 1.1266e-04 - accuracy: 1.0000 - val_loss: 5.9068e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 9.9621e-05 - accuracy: 1.0000 - val_loss: 4.1146e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 9.1467e-05 - accuracy: 1.0000 - val_loss: 4.4093e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 8.3775e-05 - accuracy: 1.0000 - val_loss: 4.3431e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 5.6381e-05 - accuracy: 1.0000 ETA: 0s - loss: 5.6824e-05 - accuracy: 1. - 0s 244us/step - loss: 7.8534e-05 - accuracy: 1.0000 - val_loss: 3.5152e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 7.5283e-05 - accuracy: 1.0000 - val_loss: 4.1443e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 7.1480e-05 - accuracy: 1.0000 - val_loss: 3.8603e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 6.8017e-05 - accuracy: 1.0000 - val_loss: 4.7329e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 5.8405e-05 - accuracy: 1.0000 - val_loss: 3.0159e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 5.4826e-05 - accuracy: 1.0000 - val_loss: 2.6337e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 5.1967e-05 - accuracy: 1.0000 - val_loss: 2.9724e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 4.8853e-05 - accuracy: 1.0000 - val_loss: 2.5076e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 4.6561e-05 - accuracy: 1.0000 - val_loss: 1.8218e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 4.0953e-05 - accuracy: 1.0000 - val_loss: 2.4724e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 3.9871e-05 - accuracy: 1.0000 - val_loss: 2.3774e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 3.8807e-05 - accuracy: 1.0000 - val_loss: 2.7365e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 3.6513e-05 - accuracy: 1.0000 - val_loss: 1.9289e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 3.3084e-05 - accuracy: 1.0000 - val_loss: 2.1966e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 3.1210e-05 - accuracy: 1.0000 - val_loss: 1.8841e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 2.8908e-05 - accuracy: 1.0000 - val_loss: 1.4120e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 2.7540e-05 - accuracy: 1.0000 - val_loss: 1.6544e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 2.6179e-05 - accuracy: 1.0000 - val_loss: 1.5075e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 2.4635e-05 - accuracy: 1.0000 - val_loss: 1.3390e-05 - val_accuracy: 1.00000s - loss: 2.5697e-05 - accuracy: 1.\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 2.3989e-05 - accuracy: 1.0000 - val_loss: 1.1127e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 2.2247e-05 - accuracy: 1.0000 - val_loss: 1.2916e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 2.1055e-05 - accuracy: 1.0000 - val_loss: 1.0981e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 1.9648e-05 - accuracy: 1.0000 - val_loss: 1.1328e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9292e-05 - accuracy: 1.00 - 0s 230us/step - loss: 1.8721e-05 - accuracy: 1.0000 - val_loss: 8.8195e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6989e-05 - accuracy: 1.00 - 0s 225us/step - loss: 1.8144e-05 - accuracy: 1.0000 - val_loss: 9.4625e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 1.6747e-05 - accuracy: 1.0000 - val_loss: 9.3635e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 1.6213e-05 - accuracy: 1.0000 - val_loss: 9.8384e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.5459e-05 - accuracy: 1.0000 - val_loss: 9.4260e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 1.4562e-05 - accuracy: 1.0000 - val_loss: 8.4094e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 1.3937e-05 - accuracy: 1.0000 - val_loss: 7.0143e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.3485e-05 - accuracy: 1.00 - 0s 226us/step - loss: 1.3383e-05 - accuracy: 1.0000 - val_loss: 8.3098e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 1.2403e-05 - accuracy: 1.0000 - val_loss: 7.0667e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 1.1773e-05 - accuracy: 1.0000 - val_loss: 6.6543e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 1.1416e-05 - accuracy: 1.0000 - val_loss: 6.6776e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 1.0695e-05 - accuracy: 1.0000 - val_loss: 6.0339e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.0380e-05 - accuracy: 1.0000 - val_loss: 5.9481e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 9.6906e-06 - accuracy: 1.0000 - val_loss: 6.0560e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 9.3406e-06 - accuracy: 1.0000 - val_loss: 5.2943e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 8.7614e-06 - accuracy: 1.0000 - val_loss: 5.2002e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 8.4706e-06 - accuracy: 1.0000 - val_loss: 4.7180e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 8.0395e-06 - accuracy: 1.0000 - val_loss: 5.3944e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 7.7634e-06 - accuracy: 1.0000 - val_loss: 4.7991e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 7.2923e-06 - accuracy: 1.0000 - val_loss: 3.8681e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 6.9144e-06 - accuracy: 1.0000 - val_loss: 3.5415e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 6.6526e-06 - accuracy: 1.0000 - val_loss: 3.8056e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 6.3904e-06 - accuracy: 1.0000 - val_loss: 4.2555e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 5.9092e-06 - accuracy: 1.0000 - val_loss: 3.5254e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 5.6759e-06 - accuracy: 1.0000 - val_loss: 3.2066e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 5.5688e-06 - accuracy: 1.0000 - val_loss: 3.2036e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 5.1850e-06 - accuracy: 1.0000 - val_loss: 3.0951e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 4.9978e-06 - accuracy: 1.0000 - val_loss: 2.9396e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 4.7666e-06 - accuracy: 1.0000 - val_loss: 2.5140e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 4.4809e-06 - accuracy: 1.0000 - val_loss: 2.8192e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 4.3532e-06 - accuracy: 1.0000 - val_loss: 2.2577e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 4.1864e-06 - accuracy: 1.0000 - val_loss: 2.5528e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 4.0078e-06 - accuracy: 1.0000 - val_loss: 2.4508e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 3.6938e-06 - accuracy: 1.0000 - val_loss: 2.3465e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 3.6826e-06 - accuracy: 1.0000 - val_loss: 2.5271e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 3.4224e-06 - accuracy: 1.0000 - val_loss: 2.1671e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 3.2505e-06 - accuracy: 1.0000 - val_loss: 1.9836e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 3.0946e-06 - accuracy: 1.0000 - val_loss: 2.0551e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 3.0397e-06 - accuracy: 1.0000 - val_loss: 1.8852e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 2.8883e-06 - accuracy: 1.0000 - val_loss: 1.7744e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 2.7383e-06 - accuracy: 1.0000 - val_loss: 1.7887e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 2.5739e-06 - accuracy: 1.0000 - val_loss: 1.7636e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 2.5030e-06 - accuracy: 1.0000 - val_loss: 1.6319e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 2.3288e-06 - accuracy: 1.0000 - val_loss: 1.4954e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 2.3097e-06 - accuracy: 1.0000 - val_loss: 1.6629e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 2.2167e-06 - accuracy: 1.0000 - val_loss: 1.5074e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 2.0295e-06 - accuracy: 1.0000 - val_loss: 1.2451e-06 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.9824e-06 - accuracy: 1.0000 - val_loss: 1.2886e-06 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 1.8611e-06 - accuracy: 1.0000 - val_loss: 1.2803e-06 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 1.7858e-06 - accuracy: 1.0000 - val_loss: 1.2296e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 1.7332e-06 - accuracy: 1.0000 - val_loss: 1.1271e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.6517e-06 - accuracy: 1.0000 - val_loss: 1.1915e-06 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 1.5577e-06 - accuracy: 1.0000 - val_loss: 9.8763e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.4847e-06 - accuracy: 1.0000 - val_loss: 9.7631e-07 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.4266e-06 - accuracy: 1.0000 - val_loss: 1.0812e-06 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 1.3893e-06 - accuracy: 1.0000 - val_loss: 9.2624e-07 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 1.3013e-06 - accuracy: 1.0000 - val_loss: 9.0240e-07 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 1.2320e-06 - accuracy: 1.0000 - val_loss: 9.0359e-07 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.2119e-06 - accuracy: 1.0000 - val_loss: 8.8392e-07 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 1.1366e-06 - accuracy: 1.0000 - val_loss: 7.4862e-07 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 1.0864e-06 - accuracy: 1.0000 - val_loss: 8.3683e-07 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 260us/step - loss: 1.0401e-06 - accuracy: 1.0000 - val_loss: 7.5995e-07 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 1.0089e-06 - accuracy: 1.0000 - val_loss: 6.8485e-07 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 9.4724e-07 - accuracy: 1.0000 - val_loss: 7.4028e-07 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 9.1104e-07 - accuracy: 1.0000 - val_loss: 7.2597e-07 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 372us/step - loss: 8.8735e-07 - accuracy: 1.0000 - val_loss: 6.6339e-07 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 8.5829e-07 - accuracy: 1.0000 - val_loss: 5.8173e-07 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 438us/step - loss: 8.0942e-07 - accuracy: 1.0000 - val_loss: 6.8962e-07 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 7.6517e-07 - accuracy: 1.0000 - val_loss: 5.4597e-07 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 7.4445e-07 - accuracy: 1.0000 - val_loss: 5.9306e-07 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 7.2552e-07 - accuracy: 1.0000 - val_loss: 5.5432e-07 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 6.6965e-07 - accuracy: 1.0000 - val_loss: 4.5001e-07 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 312us/step - loss: 6.4819e-07 - accuracy: 1.0000 - val_loss: 4.6730e-07 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 6.1273e-07 - accuracy: 1.0000 - val_loss: 4.8696e-07 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 318us/step - loss: 6.0438e-07 - accuracy: 1.0000 - val_loss: 4.0948e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 5.6817e-07 - accuracy: 1.0000 - val_loss: 4.3690e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 5.3867e-07 - accuracy: 1.0000 - val_loss: 4.5895e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 317us/step - loss: 5.1796e-07 - accuracy: 1.0000 - val_loss: 3.8147e-07 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 4.8562e-07 - accuracy: 1.0000 - val_loss: 3.7253e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 344us/step - loss: 4.6581e-07 - accuracy: 1.0000 - val_loss: 3.5345e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 4.5388e-07 - accuracy: 1.0000 - val_loss: 3.3259e-07 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 450us/step - loss: 4.2632e-07 - accuracy: 1.0000 - val_loss: 3.6835e-07 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 367us/step - loss: 4.1365e-07 - accuracy: 1.0000 - val_loss: 3.3259e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 335us/step - loss: 3.9711e-07 - accuracy: 1.0000 - val_loss: 3.7133e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 3.8087e-07 - accuracy: 1.0000 - val_loss: 2.8610e-07 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 3.6016e-07 - accuracy: 1.0000 - val_loss: 3.1233e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 3.5643e-07 - accuracy: 1.0000 - val_loss: 2.9266e-07 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 3.2767e-07 - accuracy: 1.0000 - val_loss: 2.6166e-07 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 342us/step - loss: 3.1903e-07 - accuracy: 1.0000 - val_loss: 2.9862e-07 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 3.0443e-07 - accuracy: 1.0000 - val_loss: 2.6524e-07 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 2.8521e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 2.7880e-07 - accuracy: 1.0000 - val_loss: 2.4795e-07 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 2.6241e-07 - accuracy: 1.0000 - val_loss: 1.9848e-07 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 2.5689e-07 - accuracy: 1.0000 - val_loss: 1.9967e-07 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 2.4661e-07 - accuracy: 1.0000 - val_loss: 1.7524e-07 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 2.3723e-07 - accuracy: 1.0000 - val_loss: 1.8775e-07 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 2.2307e-07 - accuracy: 1.0000 - val_loss: 1.9729e-07 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 2.1443e-07 - accuracy: 1.0000 - val_loss: 1.8358e-07 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 2.0280e-07 - accuracy: 1.0000 - val_loss: 1.5676e-07 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 1.9684e-07 - accuracy: 1.0000 - val_loss: 1.5616e-07 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 1.8567e-07 - accuracy: 1.0000 - val_loss: 1.4782e-07 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 1s 832us/step - loss: 1.7941e-07 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 1.7166e-07 - accuracy: 1.0000 - val_loss: 1.4245e-07 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 1.6272e-07 - accuracy: 1.0000 - val_loss: 1.5378e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 1.6123e-07 - accuracy: 1.0000 - val_loss: 1.4305e-07 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 1.5348e-07 - accuracy: 1.0000 - val_loss: 1.4782e-07 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 362us/step - loss: 1.4573e-07 - accuracy: 1.0000 - val_loss: 1.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 1.3724e-07 - accuracy: 1.0000 - val_loss: 1.2338e-07 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.3082e-07 - accuracy: 1.00 - 0s 312us/step - loss: 1.3113e-07 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 1.2979e-07 - accuracy: 1.0000 - val_loss: 1.2875e-07 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 1.1936e-07 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.1861e-07 - accuracy: 1.0000 - val_loss: 1.0729e-07 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 1.1101e-07 - accuracy: 1.0000 - val_loss: 1.1325e-07 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0639e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.0103e-07 - accuracy: 1.0000 - val_loss: 9.2387e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 9.7304e-08 - accuracy: 1.0000 - val_loss: 8.4042e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 333us/step - loss: 9.4324e-08 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 8.8513e-08 - accuracy: 1.0000 - val_loss: 8.8215e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 8.4489e-08 - accuracy: 1.0000 - val_loss: 8.6427e-08 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 8.2999e-08 - accuracy: 1.0000 - val_loss: 7.8082e-08 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 7.8082e-08 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 7.7933e-08 - accuracy: 1.0000 - val_loss: 8.5830e-08 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 7.2122e-08 - accuracy: 1.0000 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 6.8545e-08 - accuracy: 1.0000 - val_loss: 6.9141e-08 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 6.6012e-08 - accuracy: 1.0000 - val_loss: 5.8412e-08 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 6.2734e-08 - accuracy: 1.0000 - val_loss: 6.7353e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 6.3181e-08 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 5.8412e-08 - accuracy: 1.0000 - val_loss: 5.6028e-08 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 5.5730e-08 - accuracy: 1.0000 - val_loss: 6.2585e-08 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 275us/step - loss: 5.2899e-08 - accuracy: 1.0000 - val_loss: 5.6624e-08 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 5.1558e-08 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 5.0068e-08 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 4.5896e-08 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 4.4405e-08 - accuracy: 1.0000 - val_loss: 4.6492e-08 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 4.2766e-08 - accuracy: 1.0000 - val_loss: 5.1260e-08 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 4.1127e-08 - accuracy: 1.0000 - val_loss: 3.9935e-08 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 3.9935e-08 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 3.7104e-08 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 3.5912e-08 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 373us/step - loss: 3.7253e-08 - accuracy: 1.0000 - val_loss: 3.8743e-08 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 3.3528e-08 - accuracy: 1.0000 - val_loss: 3.9339e-08 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 3.0845e-08 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 2.9951e-08 - accuracy: 1.0000 - val_loss: 3.3379e-08 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 2.9355e-08 - accuracy: 1.0000 - val_loss: 3.5763e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 502us/step - loss: 2.8461e-08 - accuracy: 1.0000 - val_loss: 3.1590e-08 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 439us/step - loss: 2.5928e-08 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 2.4289e-08 - accuracy: 1.0000 - val_loss: 3.3975e-08 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 2.3395e-08 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 2.2352e-08 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 281us/step - loss: 2.1756e-08 - accuracy: 1.0000 - val_loss: 2.3246e-08 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 2.0862e-08 - accuracy: 1.0000 - val_loss: 2.5034e-08 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.9968e-08 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 2.0266e-08 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.8030e-08 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 1.7732e-08 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 1.6987e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 1.6391e-08 - accuracy: 1.0000 - val_loss: 2.0266e-08 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 1.5646e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 1.5050e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 1.4603e-08 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 322us/step - loss: 1.3560e-08 - accuracy: 1.0000 - val_loss: 1.9670e-08 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 1.3858e-08 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 1.2517e-08 - accuracy: 1.0000 - val_loss: 1.5497e-08 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 1.1921e-08 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.1176e-08 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 320us/step - loss: 1.1027e-08 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 1.0431e-08 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 1.0729e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 1.0133e-08 - accuracy: 1.0000 - val_loss: 1.5497e-08 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 9.5367e-09 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 9.0897e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 1s 721us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 1s 711us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 618us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 571us/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 7.7486e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 7.0035e-09 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 6.8545e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 449us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 5.8115e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 5.5020e-09 - accuracy: 1.00 - 0s 368us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 339us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 349us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 340us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 4.0233e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 262us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 268us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 269us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 332us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 515us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 334us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 299us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 353us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 272us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 324us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 249us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 267us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 267us/step\n",
      "tdnn on d_7_nh_2_mem_False\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 764us/step - loss: 0.1823 - accuracy: 0.9237 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 6.9477e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 6.5004e-04 - accuracy: 1.0000 - val_loss: 3.7603e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 3.1778e-04 - accuracy: 1.0000 - val_loss: 1.8440e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 2.3679e-04 - accuracy: 1.0000 - val_loss: 1.7554e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.7092e-04 - accuracy: 1.0000 - val_loss: 9.7373e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.2995e-04 - accuracy: 1.0000 - val_loss: 9.1318e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 1.0323e-04 - accuracy: 1.0000 - val_loss: 8.2417e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 8.1848e-05 - accuracy: 1.0000 - val_loss: 5.8386e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 6.9008e-05 - accuracy: 1.0000 - val_loss: 5.2018e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 5.6913e-05 - accuracy: 1.0000 - val_loss: 4.6681e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 4.8409e-05 - accuracy: 1.0000 - val_loss: 3.6367e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 4.1495e-05 - accuracy: 1.0000 - val_loss: 3.4606e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 3.6093e-05 - accuracy: 1.0000 - val_loss: 2.8088e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 3.1346e-05 - accuracy: 1.0000 - val_loss: 2.6615e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 2.7493e-05 - accuracy: 1.0000 - val_loss: 2.4150e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 2.4597e-05 - accuracy: 1.0000 - val_loss: 2.2207e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.1767e-05 - accuracy: 1.0000 - val_loss: 1.9067e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 1.9393e-05 - accuracy: 1.0000 - val_loss: 1.7817e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 1.7527e-05 - accuracy: 1.0000 - val_loss: 1.5747e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 1.5818e-05 - accuracy: 1.0000 - val_loss: 1.4678e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 1.4410e-05 - accuracy: 1.0000 - val_loss: 1.4426e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 1.2901e-05 - accuracy: 1.0000 - val_loss: 1.2719e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 445us/step - loss: 1.1747e-05 - accuracy: 1.0000 - val_loss: 1.2174e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.0709e-05 - accuracy: 1.0000 - val_loss: 1.0919e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 9.8332e-06 - accuracy: 1.0000 - val_loss: 1.0443e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 9.0745e-06 - accuracy: 1.0000 - val_loss: 9.9520e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 8.3399e-06 - accuracy: 1.0000 - val_loss: 8.4376e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 7.7510e-06 - accuracy: 1.0000 - val_loss: 8.5489e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 7.1186e-06 - accuracy: 1.0000 - val_loss: 8.0532e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 6.4926e-06 - accuracy: 1.0000 - val_loss: 7.4240e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 6.0410e-06 - accuracy: 1.0000 - val_loss: 7.1928e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 464us/step - loss: 5.6322e-06 - accuracy: 1.0000 - val_loss: 6.7119e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 5.2329e-06 - accuracy: 1.0000 - val_loss: 6.1524e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 4.8285e-06 - accuracy: 1.0000 - val_loss: 6.0213e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 476us/step - loss: 4.5448e-06 - accuracy: 1.0000 - val_loss: 5.6692e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 4.1907e-06 - accuracy: 1.0000 - val_loss: 5.4231e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 3.9247e-06 - accuracy: 1.0000 - val_loss: 4.8499e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 459us/step - loss: 3.6945e-06 - accuracy: 1.0000 - val_loss: 4.5763e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 466us/step - loss: 3.4262e-06 - accuracy: 1.0000 - val_loss: 4.3469e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 3.2173e-06 - accuracy: 1.0000 - val_loss: 4.0585e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 3.0471e-06 - accuracy: 1.0000 - val_loss: 3.9524e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 496us/step - loss: 2.8198e-06 - accuracy: 1.0000 - val_loss: 3.7564e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 471us/step - loss: 2.6399e-06 - accuracy: 1.0000 - val_loss: 3.4936e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 438us/step - loss: 2.4763e-06 - accuracy: 1.0000 - val_loss: 3.5400e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 2.3333e-06 - accuracy: 1.0000 - val_loss: 3.2892e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 1s 645us/step - loss: 2.1932e-06 - accuracy: 1.0000 - val_loss: 3.1861e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 511us/step - loss: 2.0873e-06 - accuracy: 1.0000 - val_loss: 3.1366e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 608us/step - loss: 1.9431e-06 - accuracy: 1.0000 - val_loss: 2.8947e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 587us/step - loss: 1.8356e-06 - accuracy: 1.0000 - val_loss: 2.7993e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 451us/step - loss: 1.7409e-06 - accuracy: 1.0000 - val_loss: 2.6599e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 1.6385e-06 - accuracy: 1.0000 - val_loss: 2.5949e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 532us/step - loss: 1.5494e-06 - accuracy: 1.0000 - val_loss: 2.3595e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 452us/step - loss: 1.4597e-06 - accuracy: 1.0000 - val_loss: 2.3833e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 439us/step - loss: 1.3792e-06 - accuracy: 1.0000 - val_loss: 2.2040e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.2971e-06 - accuracy: 1.0000 - val_loss: 2.1211e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 532us/step - loss: 1.2421e-06 - accuracy: 1.0000 - val_loss: 2.1176e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 435us/step - loss: 1.1693e-06 - accuracy: 1.0000 - val_loss: 1.9954e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 451us/step - loss: 1.1037e-06 - accuracy: 1.0000 - val_loss: 1.8488e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 474us/step - loss: 1.0563e-06 - accuracy: 1.0000 - val_loss: 1.8184e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 9.8704e-07 - accuracy: 1.0000 - val_loss: 1.7046e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 9.4844e-07 - accuracy: 1.0000 - val_loss: 1.5776e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 608us/step - loss: 8.9748e-07 - accuracy: 1.0000 - val_loss: 1.6289e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 544us/step - loss: 8.4101e-07 - accuracy: 1.0000 - val_loss: 1.5633e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 1s 675us/step - loss: 8.0674e-07 - accuracy: 1.0000 - val_loss: 1.4894e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 549us/step - loss: 7.5786e-07 - accuracy: 1.0000 - val_loss: 1.4054e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 7.2985e-07 - accuracy: 1.0000 - val_loss: 1.3774e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 6.8440e-07 - accuracy: 1.0000 - val_loss: 1.3106e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 6.5028e-07 - accuracy: 1.0000 - val_loss: 1.2618e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 6.2167e-07 - accuracy: 1.0000 - val_loss: 1.1277e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 454us/step - loss: 5.8427e-07 - accuracy: 1.0000 - val_loss: 1.1807e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 472us/step - loss: 5.5849e-07 - accuracy: 1.0000 - val_loss: 1.1062e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 484us/step - loss: 5.3361e-07 - accuracy: 1.0000 - val_loss: 1.0538e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 505us/step - loss: 5.0559e-07 - accuracy: 1.0000 - val_loss: 1.0234e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 522us/step - loss: 4.7952e-07 - accuracy: 1.0000 - val_loss: 9.6674e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 469us/step - loss: 4.5731e-07 - accuracy: 1.0000 - val_loss: 9.0714e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 560us/step - loss: 4.3437e-07 - accuracy: 1.0000 - val_loss: 9.0118e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 470us/step - loss: 4.1291e-07 - accuracy: 1.0000 - val_loss: 8.7257e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 3.9443e-07 - accuracy: 1.0000 - val_loss: 8.5946e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 445us/step - loss: 3.7402e-07 - accuracy: 1.0000 - val_loss: 8.4098e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 443us/step - loss: 3.5599e-07 - accuracy: 1.0000 - val_loss: 8.0761e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 459us/step - loss: 3.3855e-07 - accuracy: 1.0000 - val_loss: 7.5099e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 491us/step - loss: 3.2112e-07 - accuracy: 1.0000 - val_loss: 7.2417e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 490us/step - loss: 3.0860e-07 - accuracy: 1.0000 - val_loss: 7.1761e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 450us/step - loss: 2.9161e-07 - accuracy: 1.0000 - val_loss: 6.7053e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 484us/step - loss: 2.7954e-07 - accuracy: 1.0000 - val_loss: 6.4788e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 495us/step - loss: 2.6941e-07 - accuracy: 1.0000 - val_loss: 6.2583e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 474us/step - loss: 2.5168e-07 - accuracy: 1.0000 - val_loss: 6.0854e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 499us/step - loss: 2.4050e-07 - accuracy: 1.0000 - val_loss: 5.9781e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 2.2903e-07 - accuracy: 1.0000 - val_loss: 5.4775e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 547us/step - loss: 2.1726e-07 - accuracy: 1.0000 - val_loss: 5.4477e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 485us/step - loss: 2.0727e-07 - accuracy: 1.0000 - val_loss: 5.2033e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 454us/step - loss: 1.9759e-07 - accuracy: 1.0000 - val_loss: 5.1616e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 1.8954e-07 - accuracy: 1.0000 - val_loss: 5.0007e-07 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 438us/step - loss: 1.7911e-07 - accuracy: 1.0000 - val_loss: 4.7682e-07 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 458us/step - loss: 1.7121e-07 - accuracy: 1.0000 - val_loss: 4.5000e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 464us/step - loss: 1.6317e-07 - accuracy: 1.0000 - val_loss: 4.4821e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.5676e-07 - accuracy: 1.0000 - val_loss: 4.2735e-07 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 1.4827e-07 - accuracy: 1.0000 - val_loss: 4.1365e-07 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 371us/step - loss: 1.4141e-07 - accuracy: 1.0000 - val_loss: 3.9457e-07 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 363us/step - loss: 1.3500e-07 - accuracy: 1.0000 - val_loss: 3.8802e-07 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 377us/step - loss: 1.3009e-07 - accuracy: 1.0000 - val_loss: 3.6894e-07 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 1.2428e-07 - accuracy: 1.0000 - val_loss: 3.6000e-07 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 364us/step - loss: 1.1876e-07 - accuracy: 1.0000 - val_loss: 3.3735e-07 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 380us/step - loss: 1.1280e-07 - accuracy: 1.0000 - val_loss: 3.3855e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 371us/step - loss: 1.0744e-07 - accuracy: 1.0000 - val_loss: 3.1411e-07 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 1.0177e-07 - accuracy: 1.0000 - val_loss: 3.2007e-07 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 9.8049e-08 - accuracy: 1.0000 - val_loss: 3.0517e-07 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 9.2089e-08 - accuracy: 1.0000 - val_loss: 2.9504e-07 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 8.8811e-08 - accuracy: 1.0000 - val_loss: 2.8073e-07 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 8.5384e-08 - accuracy: 1.0000 - val_loss: 2.7358e-07 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 8.0168e-08 - accuracy: 1.0000 - val_loss: 2.6762e-07 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 7.6145e-08 - accuracy: 1.0000 - val_loss: 2.5510e-07 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 485us/step - loss: 7.1227e-08 - accuracy: 1.0000 - val_loss: 2.5332e-07 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 6.8247e-08 - accuracy: 1.0000 - val_loss: 2.4199e-07 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 6.5267e-08 - accuracy: 1.0000 - val_loss: 2.3245e-07 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 468us/step - loss: 6.2436e-08 - accuracy: 1.0000 - val_loss: 2.3007e-07 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 480us/step - loss: 5.9307e-08 - accuracy: 1.0000 - val_loss: 2.2173e-07 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 450us/step - loss: 5.7220e-08 - accuracy: 1.0000 - val_loss: 2.1040e-07 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 507us/step - loss: 5.3942e-08 - accuracy: 1.0000 - val_loss: 2.1159e-07 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 504us/step - loss: 5.2154e-08 - accuracy: 1.0000 - val_loss: 2.0384e-07 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 443us/step - loss: 5.0217e-08 - accuracy: 1.0000 - val_loss: 1.9073e-07 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 501us/step - loss: 4.8429e-08 - accuracy: 1.0000 - val_loss: 1.9073e-07 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 4.5896e-08 - accuracy: 1.0000 - val_loss: 1.8179e-07 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 531us/step - loss: 4.3809e-08 - accuracy: 1.0000 - val_loss: 1.7702e-07 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 515us/step - loss: 4.2021e-08 - accuracy: 1.0000 - val_loss: 1.7524e-07 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 510us/step - loss: 3.9786e-08 - accuracy: 1.0000 - val_loss: 1.6689e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 3.7402e-08 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 3.6359e-08 - accuracy: 1.0000 - val_loss: 1.5497e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 3.5018e-08 - accuracy: 1.0000 - val_loss: 1.5378e-07 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 3.3379e-08 - accuracy: 1.0000 - val_loss: 1.5080e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 3.2186e-08 - accuracy: 1.0000 - val_loss: 1.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 3.0696e-08 - accuracy: 1.0000 - val_loss: 1.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 2.9504e-08 - accuracy: 1.0000 - val_loss: 1.3947e-07 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.8312e-08 - accuracy: 1.0000 - val_loss: 1.3471e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 2.6077e-08 - accuracy: 1.0000 - val_loss: 1.2934e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 457us/step - loss: 2.4289e-08 - accuracy: 1.0000 - val_loss: 1.2457e-07 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 439us/step - loss: 2.4140e-08 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 2.3097e-08 - accuracy: 1.0000 - val_loss: 1.1623e-07 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 2.2054e-08 - accuracy: 1.0000 - val_loss: 1.1444e-07 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 2.1309e-08 - accuracy: 1.0000 - val_loss: 1.0967e-07 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 470us/step - loss: 2.0564e-08 - accuracy: 1.0000 - val_loss: 1.0908e-07 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 1.9670e-08 - accuracy: 1.0000 - val_loss: 1.0610e-07 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 472us/step - loss: 1.8179e-08 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 476us/step - loss: 1.7136e-08 - accuracy: 1.0000 - val_loss: 1.0014e-07 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 605us/step - loss: 1.6689e-08 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 1s 721us/step - loss: 1.5944e-08 - accuracy: 1.0000 - val_loss: 9.3579e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 1s 657us/step - loss: 1.5050e-08 - accuracy: 1.0000 - val_loss: 9.3579e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 568us/step - loss: 1.4752e-08 - accuracy: 1.0000 - val_loss: 9.1790e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 1.4305e-08 - accuracy: 1.0000 - val_loss: 8.7618e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 1.3262e-08 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 1.2964e-08 - accuracy: 1.0000 - val_loss: 8.2254e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 1.2666e-08 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 1.1474e-08 - accuracy: 1.0000 - val_loss: 7.6293e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 1.0878e-08 - accuracy: 1.0000 - val_loss: 7.5101e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 1.0580e-08 - accuracy: 1.0000 - val_loss: 6.9737e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 7.0333e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 9.6858e-09 - accuracy: 1.0000 - val_loss: 6.8545e-08 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 8.7917e-09 - accuracy: 1.0000 - val_loss: 6.6757e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 6.6161e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 6.1989e-08 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 7.5996e-09 - accuracy: 1.0000 - val_loss: 6.1989e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 7.5996e-09 - accuracy: 1.0000 - val_loss: 6.0200e-08 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 5.9604e-08 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 6.7055e-09 - accuracy: 1.0000 - val_loss: 5.5432e-08 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 5.6028e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 6.1095e-09 - accuracy: 1.0000 - val_loss: 5.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 5.8115e-09 - accuracy: 1.0000 - val_loss: 5.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 5.1260e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 5.0664e-08 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 4.7087e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 4.5895e-08 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 4.3213e-09 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 4.3511e-08 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 4.0233e-09 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 4.0531e-08 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 3.9935e-08 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 3.9339e-08 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 3.6955e-08 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 3.5763e-08 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 3.5763e-08 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 3.3975e-08 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 3.1590e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 3.0994e-08 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.8014e-08 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.6226e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 2.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.5034e-08 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.3246e-08 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 464us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 500us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 440us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.2054e-08 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.0266e-08 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.9669e-08 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 554us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 539us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 429us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 475us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 505us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 471us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 443us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 462us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 381us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 369us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 372us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 443us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 551us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 482us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 514us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "800/800 [==============================] - 0s 433us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 440us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 518us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 525us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 465us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 512us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 529us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 490us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 494us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 334us/step\n",
      "tdnn on d_20_nh_2_mem_False\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 945us/step - loss: 0.1057 - accuracy: 0.9588 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 441us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 429us/step - loss: 7.8997e-04 - accuracy: 1.0000 - val_loss: 4.2074e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 470us/step - loss: 3.9804e-04 - accuracy: 1.0000 - val_loss: 2.5800e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 472us/step - loss: 2.5484e-04 - accuracy: 1.0000 - val_loss: 1.5812e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 445us/step - loss: 1.8476e-04 - accuracy: 1.0000 - val_loss: 1.0181e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 454us/step - loss: 1.4122e-04 - accuracy: 1.0000 - val_loss: 7.9774e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 460us/step - loss: 1.0674e-04 - accuracy: 1.0000 - val_loss: 8.7906e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 467us/step - loss: 8.3354e-05 - accuracy: 1.0000 - val_loss: 5.1654e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 451us/step - loss: 6.9307e-05 - accuracy: 1.0000 - val_loss: 4.2367e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 448us/step - loss: 5.7553e-05 - accuracy: 1.0000 - val_loss: 4.6480e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 475us/step - loss: 4.9480e-05 - accuracy: 1.0000 - val_loss: 3.2235e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 476us/step - loss: 4.0861e-05 - accuracy: 1.0000 - val_loss: 2.1714e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 3.4706e-05 - accuracy: 1.0000 - val_loss: 2.4943e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 470us/step - loss: 3.0825e-05 - accuracy: 1.0000 - val_loss: 2.4705e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 464us/step - loss: 2.5639e-05 - accuracy: 1.0000 - val_loss: 1.6979e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 2.3824e-05 - accuracy: 1.0000 - val_loss: 1.7315e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 2.0149e-05 - accuracy: 1.0000 - val_loss: 1.5164e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 1.8404e-05 - accuracy: 1.0000 - val_loss: 1.4644e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 1.6337e-05 - accuracy: 1.0000 - val_loss: 1.1685e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 446us/step - loss: 1.4504e-05 - accuracy: 1.0000 - val_loss: 1.0257e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 476us/step - loss: 1.4043e-05 - accuracy: 1.0000 - val_loss: 1.1930e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 1.1832e-05 - accuracy: 1.0000 - val_loss: 8.9093e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 1.0690e-05 - accuracy: 1.0000 - val_loss: 7.8099e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 9.8527e-06 - accuracy: 1.0000 - val_loss: 6.7366e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 8.8523e-06 - accuracy: 1.0000 - val_loss: 7.2282e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 8.2582e-06 - accuracy: 1.0000 - val_loss: 6.2318e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 439us/step - loss: 7.5652e-06 - accuracy: 1.0000 - val_loss: 5.6114e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 454us/step - loss: 6.8950e-06 - accuracy: 1.0000 - val_loss: 5.7448e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 501us/step - loss: 6.3387e-06 - accuracy: 1.0000 - val_loss: 4.7961e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 5.9253e-06 - accuracy: 1.0000 - val_loss: 4.3235e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 429us/step - loss: 5.4639e-06 - accuracy: 1.0000 - val_loss: 4.3193e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 438us/step - loss: 5.0048e-06 - accuracy: 1.0000 - val_loss: 3.7638e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 491us/step - loss: 4.6513e-06 - accuracy: 1.0000 - val_loss: 3.5987e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 440us/step - loss: 4.4332e-06 - accuracy: 1.0000 - val_loss: 3.3538e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 4.0673e-06 - accuracy: 1.0000 - val_loss: 3.4158e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 463us/step - loss: 3.7864e-06 - accuracy: 1.0000 - val_loss: 3.0975e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 3.5202e-06 - accuracy: 1.0000 - val_loss: 2.9020e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 3.2678e-06 - accuracy: 1.0000 - val_loss: 2.5122e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 477us/step - loss: 3.0817e-06 - accuracy: 1.0000 - val_loss: 2.4550e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 484us/step - loss: 2.8732e-06 - accuracy: 1.0000 - val_loss: 2.3692e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 2.7086e-06 - accuracy: 1.0000 - val_loss: 2.3144e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 2.5548e-06 - accuracy: 1.0000 - val_loss: 2.1213e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 478us/step - loss: 2.3683e-06 - accuracy: 1.0000 - val_loss: 1.9925e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 2.2504e-06 - accuracy: 1.0000 - val_loss: 1.7762e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 2.1069e-06 - accuracy: 1.0000 - val_loss: 1.7076e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 1.9800e-06 - accuracy: 1.0000 - val_loss: 1.6051e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 1.8560e-06 - accuracy: 1.0000 - val_loss: 1.5306e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 1.7411e-06 - accuracy: 1.0000 - val_loss: 1.4370e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 1.6473e-06 - accuracy: 1.0000 - val_loss: 1.4108e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 1.5485e-06 - accuracy: 1.0000 - val_loss: 1.2481e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 1.4656e-06 - accuracy: 1.0000 - val_loss: 1.3101e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 1.3907e-06 - accuracy: 1.0000 - val_loss: 1.2463e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 1.3072e-06 - accuracy: 1.0000 - val_loss: 1.1778e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 1.2271e-06 - accuracy: 1.0000 - val_loss: 1.0872e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 1.1714e-06 - accuracy: 1.0000 - val_loss: 9.8107e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 1.1149e-06 - accuracy: 1.0000 - val_loss: 9.4829e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.0536e-06 - accuracy: 1.0000 - val_loss: 8.7319e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 9.9493e-07 - accuracy: 1.0000 - val_loss: 8.5174e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 9.3175e-07 - accuracy: 1.0000 - val_loss: 8.8750e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 8.8794e-07 - accuracy: 1.0000 - val_loss: 7.7187e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 8.3788e-07 - accuracy: 1.0000 - val_loss: 7.8796e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 7.9109e-07 - accuracy: 1.0000 - val_loss: 6.9200e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 7.5294e-07 - accuracy: 1.0000 - val_loss: 6.4849e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 7.1718e-07 - accuracy: 1.0000 - val_loss: 6.3061e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 382us/step - loss: 6.8172e-07 - accuracy: 1.0000 - val_loss: 6.2882e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 6.4149e-07 - accuracy: 1.0000 - val_loss: 6.0140e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 6.1049e-07 - accuracy: 1.0000 - val_loss: 5.5372e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 5.8322e-07 - accuracy: 1.0000 - val_loss: 5.0365e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 5.5938e-07 - accuracy: 1.0000 - val_loss: 5.1557e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 5.2139e-07 - accuracy: 1.0000 - val_loss: 4.8100e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 4.9799e-07 - accuracy: 1.0000 - val_loss: 4.9173e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 4.7221e-07 - accuracy: 1.0000 - val_loss: 4.2855e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 4.5254e-07 - accuracy: 1.0000 - val_loss: 4.2736e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 4.2513e-07 - accuracy: 1.0000 - val_loss: 4.2200e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 4.0069e-07 - accuracy: 1.0000 - val_loss: 3.6776e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 3.8936e-07 - accuracy: 1.0000 - val_loss: 3.6537e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 3.6627e-07 - accuracy: 1.0000 - val_loss: 3.4451e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 504us/step - loss: 3.4749e-07 - accuracy: 1.0000 - val_loss: 3.3974e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 486us/step - loss: 3.3468e-07 - accuracy: 1.0000 - val_loss: 3.2842e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 455us/step - loss: 3.1665e-07 - accuracy: 1.0000 - val_loss: 3.2365e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 514us/step - loss: 3.0041e-07 - accuracy: 1.0000 - val_loss: 2.9862e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 545us/step - loss: 2.8595e-07 - accuracy: 1.0000 - val_loss: 2.8968e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 2.7299e-07 - accuracy: 1.0000 - val_loss: 2.7478e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.5853e-07 - accuracy: 1.0000 - val_loss: 2.5391e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 2.4631e-07 - accuracy: 1.0000 - val_loss: 2.5034e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 1s 652us/step - loss: 2.3529e-07 - accuracy: 1.0000 - val_loss: 2.3723e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 475us/step - loss: 2.2605e-07 - accuracy: 1.0000 - val_loss: 2.4199e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 571us/step - loss: 2.1398e-07 - accuracy: 1.0000 - val_loss: 2.2113e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 1s 628us/step - loss: 2.0489e-07 - accuracy: 1.0000 - val_loss: 2.1279e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 525us/step - loss: 1.9342e-07 - accuracy: 1.0000 - val_loss: 1.9908e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 466us/step - loss: 1.8641e-07 - accuracy: 1.0000 - val_loss: 1.9193e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 475us/step - loss: 1.7762e-07 - accuracy: 1.0000 - val_loss: 1.8537e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 1.6898e-07 - accuracy: 1.0000 - val_loss: 1.8895e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.6212e-07 - accuracy: 1.0000 - val_loss: 1.7345e-07 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 487us/step - loss: 1.5378e-07 - accuracy: 1.0000 - val_loss: 1.5736e-07 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 532us/step - loss: 1.4797e-07 - accuracy: 1.0000 - val_loss: 1.5438e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 469us/step - loss: 1.4082e-07 - accuracy: 1.0000 - val_loss: 1.5438e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 467us/step - loss: 1.3307e-07 - accuracy: 1.0000 - val_loss: 1.4245e-07 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 1.2711e-07 - accuracy: 1.0000 - val_loss: 1.4067e-07 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 1.2323e-07 - accuracy: 1.0000 - val_loss: 1.4365e-07 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 1.1727e-07 - accuracy: 1.0000 - val_loss: 1.3053e-07 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.1131e-07 - accuracy: 1.0000 - val_loss: 1.2398e-07 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 1.0580e-07 - accuracy: 1.0000 - val_loss: 1.2517e-07 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.1325e-07 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 9.9391e-08 - accuracy: 1.0000 - val_loss: 1.1206e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 9.2536e-08 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 8.9109e-08 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 8.4340e-08 - accuracy: 1.0000 - val_loss: 9.6559e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 442us/step - loss: 8.1211e-08 - accuracy: 1.0000 - val_loss: 9.5963e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 7.7188e-08 - accuracy: 1.0000 - val_loss: 9.2387e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 384us/step - loss: 7.5251e-08 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 7.2419e-08 - accuracy: 1.0000 - val_loss: 8.5234e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 6.8247e-08 - accuracy: 1.0000 - val_loss: 7.5102e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 459us/step - loss: 6.6161e-08 - accuracy: 1.0000 - val_loss: 7.3910e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 6.2436e-08 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 474us/step - loss: 5.9456e-08 - accuracy: 1.0000 - val_loss: 7.1525e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 496us/step - loss: 5.7220e-08 - accuracy: 1.0000 - val_loss: 6.6161e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 5.4091e-08 - accuracy: 1.0000 - val_loss: 6.6161e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 5.2601e-08 - accuracy: 1.0000 - val_loss: 6.7949e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 4.9919e-08 - accuracy: 1.0000 - val_loss: 6.1989e-08 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 4.7088e-08 - accuracy: 1.0000 - val_loss: 5.9008e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 4.5448e-08 - accuracy: 1.0000 - val_loss: 5.4240e-08 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 4.4554e-08 - accuracy: 1.0000 - val_loss: 5.4240e-08 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 4.2319e-08 - accuracy: 1.0000 - val_loss: 5.3644e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 4.0084e-08 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 3.8743e-08 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 3.7253e-08 - accuracy: 1.0000 - val_loss: 4.7088e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 3.5614e-08 - accuracy: 1.0000 - val_loss: 4.5299e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 3.3826e-08 - accuracy: 1.0000 - val_loss: 4.2319e-08 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 3.2335e-08 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 3.0249e-08 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 2.9206e-08 - accuracy: 1.0000 - val_loss: 4.0531e-08 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 2.7120e-08 - accuracy: 1.0000 - val_loss: 3.8147e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 2.6375e-08 - accuracy: 1.0000 - val_loss: 3.8147e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 454us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 3.8743e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 518us/step - loss: 2.4289e-08 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 474us/step - loss: 2.3693e-08 - accuracy: 1.0000 - val_loss: 3.4571e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 490us/step - loss: 2.2948e-08 - accuracy: 1.0000 - val_loss: 3.2783e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 506us/step - loss: 2.2054e-08 - accuracy: 1.0000 - val_loss: 3.0398e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 513us/step - loss: 2.1309e-08 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 502us/step - loss: 1.9819e-08 - accuracy: 1.0000 - val_loss: 3.0398e-08 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 1.9073e-08 - accuracy: 1.0000 - val_loss: 2.7418e-08 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 1.8179e-08 - accuracy: 1.0000 - val_loss: 2.6822e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 1.7881e-08 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 1.6689e-08 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 1.6689e-08 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 1.5199e-08 - accuracy: 1.0000 - val_loss: 2.5034e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.4603e-08 - accuracy: 1.0000 - val_loss: 2.3246e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 1.4454e-08 - accuracy: 1.0000 - val_loss: 2.3246e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 1.4007e-08 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 1.3262e-08 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 446us/step - loss: 1.2368e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 1.2815e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 1.1176e-08 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 1.1027e-08 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 1.0133e-08 - accuracy: 1.0000 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 9.9838e-09 - accuracy: 1.0000 - val_loss: 1.6093e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 9.6858e-09 - accuracy: 1.0000 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 8.7917e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 8.7917e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 8.0466e-09 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 7.1526e-09 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 6.8545e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 6.8545e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 6.2585e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 472us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 5.0664e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 397us/step - loss: 4.7684e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 4.0233e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 429us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 2.5332e-09 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 382us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 379us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 465us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 385us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 376us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 381us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 381us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 377us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 408us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 388us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 399us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 372us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 383us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 378us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 334us/step\n",
      "tdnn on d_7_nh_2_mem_True\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 816us/step - loss: 0.1991 - accuracy: 0.8712 - val_loss: 6.6997e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 6.1405e-04 - accuracy: 1.0000 - val_loss: 6.2478e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 371us/step - loss: 2.9993e-04 - accuracy: 1.0000 - val_loss: 1.4056e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 370us/step - loss: 1.1042e-04 - accuracy: 1.0000 - val_loss: 4.8104e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 355us/step - loss: 8.9151e-05 - accuracy: 1.0000 - val_loss: 4.1066e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 6.9085e-05 - accuracy: 1.0000 - val_loss: 3.8454e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 5.0422e-05 - accuracy: 1.0000 - val_loss: 3.0714e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 371us/step - loss: 3.9849e-05 - accuracy: 1.0000 - val_loss: 1.9805e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 382us/step - loss: 3.2921e-05 - accuracy: 1.0000 - val_loss: 2.0084e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 377us/step - loss: 2.8662e-05 - accuracy: 1.0000 - val_loss: 2.0278e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 2.3986e-05 - accuracy: 1.0000 - val_loss: 1.5202e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 397us/step - loss: 2.0604e-05 - accuracy: 1.0000 - val_loss: 1.2726e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.6878e-05 - accuracy: 1.0000 - val_loss: 8.9583e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.5810e-05 - accuracy: 1.0000 - val_loss: 7.6101e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 1.4648e-05 - accuracy: 1.0000 - val_loss: 9.2586e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 1.1835e-05 - accuracy: 1.0000 - val_loss: 7.6810e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.0512e-05 - accuracy: 1.0000 - val_loss: 6.8477e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 9.3635e-06 - accuracy: 1.0000 - val_loss: 6.0109e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 381us/step - loss: 8.7988e-06 - accuracy: 1.0000 - val_loss: 4.3522e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 7.6177e-06 - accuracy: 1.0000 - val_loss: 5.5240e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 7.0953e-06 - accuracy: 1.0000 - val_loss: 3.6966e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 6.1863e-06 - accuracy: 1.0000 - val_loss: 4.2133e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 5.6670e-06 - accuracy: 1.0000 - val_loss: 3.6024e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 5.3552e-06 - accuracy: 1.0000 - val_loss: 3.2967e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 377us/step - loss: 4.7952e-06 - accuracy: 1.0000 - val_loss: 2.6530e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 382us/step - loss: 4.3635e-06 - accuracy: 1.0000 - val_loss: 2.8824e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 473us/step - loss: 4.0163e-06 - accuracy: 1.0000 - val_loss: 2.6428e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 3.7252e-06 - accuracy: 1.0000 - val_loss: 2.4134e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 448us/step - loss: 3.4730e-06 - accuracy: 1.0000 - val_loss: 2.1332e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 529us/step - loss: 3.2991e-06 - accuracy: 1.0000 - val_loss: 2.2083e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 471us/step - loss: 2.9910e-06 - accuracy: 1.0000 - val_loss: 2.1004e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 2.7705e-06 - accuracy: 1.0000 - val_loss: 1.8775e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 562us/step - loss: 2.6012e-06 - accuracy: 1.0000 - val_loss: 1.8537e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 507us/step - loss: 2.3952e-06 - accuracy: 1.0000 - val_loss: 1.6522e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 2.2319e-06 - accuracy: 1.0000 - val_loss: 1.4126e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 507us/step - loss: 2.0994e-06 - accuracy: 1.0000 - val_loss: 1.4382e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 504us/step - loss: 1.9592e-06 - accuracy: 1.0000 - val_loss: 1.3774e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 1.8488e-06 - accuracy: 1.0000 - val_loss: 1.2177e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 563us/step - loss: 1.7134e-06 - accuracy: 1.0000 - val_loss: 1.1968e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 478us/step - loss: 1.6161e-06 - accuracy: 1.0000 - val_loss: 1.1659e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.4938e-06 - accuracy: 1.0000 - val_loss: 1.0240e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.4148e-06 - accuracy: 1.0000 - val_loss: 9.4592e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 1.3284e-06 - accuracy: 1.0000 - val_loss: 9.0121e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 432us/step - loss: 1.2567e-06 - accuracy: 1.0000 - val_loss: 8.5890e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 1.1868e-06 - accuracy: 1.0000 - val_loss: 8.5890e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 1.1062e-06 - accuracy: 1.0000 - val_loss: 7.8975e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.0600e-06 - accuracy: 1.0000 - val_loss: 7.1406e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 1.0059e-06 - accuracy: 1.0000 - val_loss: 6.0916e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 9.3324e-07 - accuracy: 1.0000 - val_loss: 6.8128e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 8.9539e-07 - accuracy: 1.0000 - val_loss: 6.3478e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 458us/step - loss: 8.3191e-07 - accuracy: 1.0000 - val_loss: 6.1273e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 474us/step - loss: 7.8110e-07 - accuracy: 1.0000 - val_loss: 5.7935e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 464us/step - loss: 7.5398e-07 - accuracy: 1.0000 - val_loss: 5.2511e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 470us/step - loss: 6.9855e-07 - accuracy: 1.0000 - val_loss: 5.3227e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 6.6711e-07 - accuracy: 1.0000 - val_loss: 4.7207e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 6.3865e-07 - accuracy: 1.0000 - val_loss: 4.8339e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 5.9440e-07 - accuracy: 1.0000 - val_loss: 4.5478e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 5.6832e-07 - accuracy: 1.0000 - val_loss: 4.2975e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 525us/step - loss: 5.3345e-07 - accuracy: 1.0000 - val_loss: 3.9577e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 423us/step - loss: 5.1989e-07 - accuracy: 1.0000 - val_loss: 3.9577e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 593us/step - loss: 4.8607e-07 - accuracy: 1.0000 - val_loss: 3.7312e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 508us/step - loss: 4.6014e-07 - accuracy: 1.0000 - val_loss: 3.7074e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 512us/step - loss: 4.3645e-07 - accuracy: 1.0000 - val_loss: 3.3378e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 517us/step - loss: 4.1097e-07 - accuracy: 1.0000 - val_loss: 3.3676e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 577us/step - loss: 3.9368e-07 - accuracy: 1.0000 - val_loss: 3.1948e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 562us/step - loss: 3.7312e-07 - accuracy: 1.0000 - val_loss: 2.7895e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 541us/step - loss: 3.5464e-07 - accuracy: 1.0000 - val_loss: 2.8908e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 605us/step - loss: 3.3736e-07 - accuracy: 1.0000 - val_loss: 2.7537e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 1s 775us/step - loss: 3.2276e-07 - accuracy: 1.0000 - val_loss: 2.5451e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 612us/step - loss: 3.0800e-07 - accuracy: 1.0000 - val_loss: 2.5809e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 1s 657us/step - loss: 2.9325e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 467us/step - loss: 2.7686e-07 - accuracy: 1.0000 - val_loss: 2.3007e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 437us/step - loss: 2.6241e-07 - accuracy: 1.0000 - val_loss: 2.1458e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 2.5153e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 2.4617e-07 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 2.2456e-07 - accuracy: 1.0000 - val_loss: 1.8954e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 2.1502e-07 - accuracy: 1.0000 - val_loss: 1.9491e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 429us/step - loss: 2.0087e-07 - accuracy: 1.0000 - val_loss: 1.7762e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 1.9207e-07 - accuracy: 1.0000 - val_loss: 1.6808e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 1.8254e-07 - accuracy: 1.0000 - val_loss: 1.5676e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.7509e-07 - accuracy: 1.0000 - val_loss: 1.4663e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 1.6406e-07 - accuracy: 1.0000 - val_loss: 1.3292e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 1.5661e-07 - accuracy: 1.0000 - val_loss: 1.4305e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 446us/step - loss: 1.4871e-07 - accuracy: 1.0000 - val_loss: 1.2577e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 397us/step - loss: 1.3992e-07 - accuracy: 1.0000 - val_loss: 1.2338e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.3471e-07 - accuracy: 1.0000 - val_loss: 1.1742e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 1.2770e-07 - accuracy: 1.0000 - val_loss: 1.0848e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 1.2100e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 410us/step - loss: 1.1742e-07 - accuracy: 1.0000 - val_loss: 1.0550e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 1.1057e-07 - accuracy: 1.0000 - val_loss: 1.0192e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 1.0565e-07 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 1.0103e-07 - accuracy: 1.0000 - val_loss: 8.7619e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 442us/step - loss: 9.5516e-08 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 9.0748e-08 - accuracy: 1.0000 - val_loss: 8.5831e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 8.5383e-08 - accuracy: 1.0000 - val_loss: 8.4638e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 8.1360e-08 - accuracy: 1.0000 - val_loss: 7.9870e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 7.8082e-08 - accuracy: 1.0000 - val_loss: 7.5698e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 7.4506e-08 - accuracy: 1.0000 - val_loss: 7.2121e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 6.9737e-08 - accuracy: 1.0000 - val_loss: 6.6757e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 6.7055e-08 - accuracy: 1.0000 - val_loss: 6.8545e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 6.4075e-08 - accuracy: 1.0000 - val_loss: 6.3777e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 6.0350e-08 - accuracy: 1.0000 - val_loss: 6.2585e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 387us/step - loss: 5.6773e-08 - accuracy: 1.0000 - val_loss: 6.2585e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 5.4836e-08 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 5.2303e-08 - accuracy: 1.0000 - val_loss: 5.7220e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 5.0068e-08 - accuracy: 1.0000 - val_loss: 5.5432e-08 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 4.6939e-08 - accuracy: 1.0000 - val_loss: 5.1260e-08 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 4.4852e-08 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 4.2319e-08 - accuracy: 1.0000 - val_loss: 4.8280e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 455us/step - loss: 4.0382e-08 - accuracy: 1.0000 - val_loss: 4.4107e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 424us/step - loss: 3.7849e-08 - accuracy: 1.0000 - val_loss: 4.4107e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 3.6508e-08 - accuracy: 1.0000 - val_loss: 4.3511e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 404us/step - loss: 3.4720e-08 - accuracy: 1.0000 - val_loss: 4.2915e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 3.3081e-08 - accuracy: 1.0000 - val_loss: 4.1723e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 3.0994e-08 - accuracy: 1.0000 - val_loss: 3.6359e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 2.9653e-08 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 2.9206e-08 - accuracy: 1.0000 - val_loss: 3.5167e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 2.7716e-08 - accuracy: 1.0000 - val_loss: 3.1590e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 2.6673e-08 - accuracy: 1.0000 - val_loss: 3.0398e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 2.5034e-08 - accuracy: 1.0000 - val_loss: 3.0398e-08 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 398us/step - loss: 2.5034e-08 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 2.3693e-08 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 391us/step - loss: 2.2203e-08 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 2.1607e-08 - accuracy: 1.0000 - val_loss: 2.9206e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 1.9968e-08 - accuracy: 1.0000 - val_loss: 2.6822e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 1.9670e-08 - accuracy: 1.0000 - val_loss: 2.5630e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 1.8626e-08 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.7434e-08 - accuracy: 1.0000 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.6838e-08 - accuracy: 1.0000 - val_loss: 2.2054e-08 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 448us/step - loss: 1.6093e-08 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 405us/step - loss: 1.4901e-08 - accuracy: 1.0000 - val_loss: 1.9670e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 392us/step - loss: 1.4454e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 1.4007e-08 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 402us/step - loss: 1.2964e-08 - accuracy: 1.0000 - val_loss: 1.6689e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.2666e-08 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 1.1325e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 1.0580e-08 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 386us/step - loss: 1.0282e-08 - accuracy: 1.0000 - val_loss: 1.5497e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 390us/step - loss: 1.0133e-08 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 425us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 8.7917e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 8.9407e-09 - accuracy: 1.0000 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 8.1956e-09 - accuracy: 1.0000 - val_loss: 1.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 8.0466e-09 - accuracy: 1.0000 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 393us/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 403us/step - loss: 7.1526e-09 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 401us/step - loss: 6.5565e-09 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 6.2585e-09 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 406us/step - loss: 6.4075e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 432us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 619us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 500us/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 560us/step - loss: 5.2154e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 485us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 557us/step - loss: 4.6194e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 586us/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 560us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 502us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 496us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 582us/step - loss: 3.2783e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 1s 650us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 0s 495us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 415us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 407us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 461us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 412us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 436us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 444us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 451us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 434us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 473us/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 435us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 433us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 445us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 431us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 457us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 435us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 420us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 419us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 428us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 435us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 418us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 409us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 417us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 413us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 422us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 426us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 456us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 414us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 427us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 416us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 411us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 421us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 451us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 529us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "800/800 [==============================] - 0s 517us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 1s 632us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 490us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 541us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 395us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 396us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 512us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 501us/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 373us/step\n",
      "tdnn on d_20_nh_2_mem_True\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9525 - val_loss: 4.0581e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 1s 979us/step - loss: 4.2362e-04 - accuracy: 1.0000 - val_loss: 4.0872e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 1s 695us/step - loss: 1.6521e-04 - accuracy: 1.0000 - val_loss: 3.9417e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 1s 660us/step - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 3.1326e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 1s 650us/step - loss: 8.2070e-05 - accuracy: 1.0000 - val_loss: 2.1831e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 1s 647us/step - loss: 6.5773e-05 - accuracy: 1.0000 - val_loss: 1.5898e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 1s 657us/step - loss: 5.4114e-05 - accuracy: 1.0000 - val_loss: 2.2076e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 1s 657us/step - loss: 4.4252e-05 - accuracy: 1.0000 - val_loss: 1.3091e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 1s 728us/step - loss: 3.8408e-05 - accuracy: 1.0000 - val_loss: 1.5412e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 1s 654us/step - loss: 3.4453e-05 - accuracy: 1.0000 - val_loss: 1.8351e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 1s 669us/step - loss: 3.0118e-05 - accuracy: 1.0000 - val_loss: 1.3604e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 1s 693us/step - loss: 2.3250e-05 - accuracy: 1.0000 - val_loss: 1.0506e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 1s 670us/step - loss: 1.9928e-05 - accuracy: 1.0000 - val_loss: 6.7181e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 1s 696us/step - loss: 1.8897e-05 - accuracy: 1.0000 - val_loss: 7.3271e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 1s 643us/step - loss: 1.6560e-05 - accuracy: 1.0000 - val_loss: 8.1185e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 1s 652us/step - loss: 1.4183e-05 - accuracy: 1.0000 - val_loss: 5.0250e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 1s 728us/step - loss: 1.3680e-05 - accuracy: 1.0000 - val_loss: 5.8932e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 1s 705us/step - loss: 1.1960e-05 - accuracy: 1.0000 - val_loss: 4.6322e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 1s 682us/step - loss: 1.0625e-05 - accuracy: 1.0000 - val_loss: 4.0934e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 1s 731us/step - loss: 9.3782e-06 - accuracy: 1.0000 - val_loss: 3.3770e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 1s 689us/step - loss: 8.8326e-06 - accuracy: 1.0000 - val_loss: 2.9479e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 1s 705us/step - loss: 8.2253e-06 - accuracy: 1.0000 - val_loss: 2.7828e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 1s 752us/step - loss: 7.3235e-06 - accuracy: 1.0000 - val_loss: 3.5874e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 1s 789us/step - loss: 6.9494e-06 - accuracy: 1.0000 - val_loss: 3.2519e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 1s 937us/step - loss: 6.0424e-06 - accuracy: 1.0000 - val_loss: 2.7363e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 1s 770us/step - loss: 5.6301e-06 - accuracy: 1.0000 - val_loss: 2.3448e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 1s 944us/step - loss: 5.2355e-06 - accuracy: 1.0000 - val_loss: 2.3811e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 1s 830us/step - loss: 5.0262e-06 - accuracy: 1.0000 - val_loss: 2.2136e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 1s 966us/step - loss: 4.5277e-06 - accuracy: 1.0000 - val_loss: 2.2100e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 1s 868us/step - loss: 4.2193e-06 - accuracy: 1.0000 - val_loss: 1.6874e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 1s 781us/step - loss: 4.0153e-06 - accuracy: 1.0000 - val_loss: 1.6409e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 1s 717us/step - loss: 3.5662e-06 - accuracy: 1.0000 - val_loss: 1.6355e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 1s 857us/step - loss: 3.3695e-06 - accuracy: 1.0000 - val_loss: 1.3905e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 1s 772us/step - loss: 3.1860e-06 - accuracy: 1.0000 - val_loss: 1.4102e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 1s 687us/step - loss: 3.0039e-06 - accuracy: 1.0000 - val_loss: 1.1301e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 1s 661us/step - loss: 2.7698e-06 - accuracy: 1.0000 - val_loss: 1.0639e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 1s 664us/step - loss: 2.6009e-06 - accuracy: 1.0000 - val_loss: 1.0299e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 1s 637us/step - loss: 2.4366e-06 - accuracy: 1.0000 - val_loss: 1.0592e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 1s 652us/step - loss: 2.3227e-06 - accuracy: 1.0000 - val_loss: 8.5114e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 1s 919us/step - loss: 2.1767e-06 - accuracy: 1.0000 - val_loss: 9.2505e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.0341e-06 - accuracy: 1.0000 - val_loss: 8.9822e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 1s 864us/step - loss: 1.9409e-06 - accuracy: 1.0000 - val_loss: 9.6259e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 1s 671us/step - loss: 1.7794e-06 - accuracy: 1.0000 - val_loss: 8.3624e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 1s 772us/step - loss: 1.6962e-06 - accuracy: 1.0000 - val_loss: 8.1478e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5601e-06 - accuracy: 1.0000 - val_loss: 7.3968e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5232e-06 - accuracy: 1.0000 - val_loss: 6.5087e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 1s 828us/step - loss: 1.3954e-06 - accuracy: 1.0000 - val_loss: 6.6458e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 1s 734us/step - loss: 1.3117e-06 - accuracy: 1.0000 - val_loss: 6.3299e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 1s 908us/step - loss: 1.2378e-06 - accuracy: 1.0000 - val_loss: 6.0081e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 1s 842us/step - loss: 1.1757e-06 - accuracy: 1.0000 - val_loss: 5.4955e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 1s 813us/step - loss: 1.1447e-06 - accuracy: 1.0000 - val_loss: 5.1915e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 1s 869us/step - loss: 1.0088e-06 - accuracy: 1.0000 - val_loss: 4.1246e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 1s 969us/step - loss: 9.9520e-07 - accuracy: 1.0000 - val_loss: 3.9339e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 1s 979us/step - loss: 9.6555e-07 - accuracy: 1.0000 - val_loss: 4.4643e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "800/800 [==============================] - 1s 742us/step - loss: 8.7854e-07 - accuracy: 1.0000 - val_loss: 4.1186e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 1s 709us/step - loss: 8.3667e-07 - accuracy: 1.0000 - val_loss: 3.9815e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 1s 714us/step - loss: 7.8750e-07 - accuracy: 1.0000 - val_loss: 3.6895e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 1s 717us/step - loss: 7.5651e-07 - accuracy: 1.0000 - val_loss: 3.5524e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 1s 794us/step - loss: 7.1181e-07 - accuracy: 1.0000 - val_loss: 3.3080e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 1s 800us/step - loss: 7.1732e-07 - accuracy: 1.0000 - val_loss: 3.4809e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 1s 905us/step - loss: 6.3715e-07 - accuracy: 1.0000 - val_loss: 2.9325e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 1s 880us/step - loss: 6.1779e-07 - accuracy: 1.0000 - val_loss: 3.0279e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 1s 862us/step - loss: 5.7800e-07 - accuracy: 1.0000 - val_loss: 2.8014e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 1s 694us/step - loss: 5.4522e-07 - accuracy: 1.0000 - val_loss: 2.5749e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 1s 672us/step - loss: 5.3792e-07 - accuracy: 1.0000 - val_loss: 2.2948e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 1s 640us/step - loss: 5.0007e-07 - accuracy: 1.0000 - val_loss: 2.3603e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 1s 667us/step - loss: 4.7668e-07 - accuracy: 1.0000 - val_loss: 2.1756e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 1s 651us/step - loss: 4.5224e-07 - accuracy: 1.0000 - val_loss: 2.1219e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 1s 686us/step - loss: 4.3362e-07 - accuracy: 1.0000 - val_loss: 2.3782e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 1s 849us/step - loss: 4.1648e-07 - accuracy: 1.0000 - val_loss: 2.2828e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 1s 894us/step - loss: 3.9488e-07 - accuracy: 1.0000 - val_loss: 1.9550e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 1s 745us/step - loss: 3.7655e-07 - accuracy: 1.0000 - val_loss: 1.9014e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 1s 850us/step - loss: 3.5539e-07 - accuracy: 1.0000 - val_loss: 1.5974e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 1s 923us/step - loss: 3.3453e-07 - accuracy: 1.0000 - val_loss: 1.7047e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 1s 898us/step - loss: 3.1992e-07 - accuracy: 1.0000 - val_loss: 1.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 1s 654us/step - loss: 2.9847e-07 - accuracy: 1.0000 - val_loss: 1.4424e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 1s 642us/step - loss: 2.8565e-07 - accuracy: 1.0000 - val_loss: 1.3649e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 1s 664us/step - loss: 2.7224e-07 - accuracy: 1.0000 - val_loss: 1.3888e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 1s 645us/step - loss: 2.5704e-07 - accuracy: 1.0000 - val_loss: 1.3113e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 1s 638us/step - loss: 2.4557e-07 - accuracy: 1.0000 - val_loss: 1.2100e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 1s 732us/step - loss: 2.3261e-07 - accuracy: 1.0000 - val_loss: 1.1980e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 1s 666us/step - loss: 2.2471e-07 - accuracy: 1.0000 - val_loss: 9.8347e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 1s 658us/step - loss: 2.0876e-07 - accuracy: 1.0000 - val_loss: 1.1146e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 1s 640us/step - loss: 2.0325e-07 - accuracy: 1.0000 - val_loss: 1.0371e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 1s 737us/step - loss: 1.9103e-07 - accuracy: 1.0000 - val_loss: 9.5367e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 1s 695us/step - loss: 1.8641e-07 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 1s 871us/step - loss: 1.7509e-07 - accuracy: 1.0000 - val_loss: 9.7155e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 1s 788us/step - loss: 1.7360e-07 - accuracy: 1.0000 - val_loss: 7.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 1s 668us/step - loss: 1.5944e-07 - accuracy: 1.0000 - val_loss: 8.1658e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 1s 704us/step - loss: 1.5214e-07 - accuracy: 1.0000 - val_loss: 7.8082e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 1s 694us/step - loss: 1.4439e-07 - accuracy: 1.0000 - val_loss: 7.6890e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 1s 750us/step - loss: 1.3649e-07 - accuracy: 1.0000 - val_loss: 6.8545e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.3445e-07 - accuracy: 1.00 - 1s 764us/step - loss: 1.3277e-07 - accuracy: 1.0000 - val_loss: 6.9141e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 1s 878us/step - loss: 1.3277e-07 - accuracy: 1.0000 - val_loss: 7.3910e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 1s 713us/step - loss: 1.2055e-07 - accuracy: 1.0000 - val_loss: 6.1989e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 1s 667us/step - loss: 1.1668e-07 - accuracy: 1.0000 - val_loss: 5.3644e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 1s 760us/step - loss: 1.1057e-07 - accuracy: 1.0000 - val_loss: 5.4836e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 1s 970us/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 4.8876e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 1s 719us/step - loss: 9.9837e-08 - accuracy: 1.0000 - val_loss: 5.1856e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 1s 731us/step - loss: 9.4324e-08 - accuracy: 1.0000 - val_loss: 5.3644e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 1s 864us/step - loss: 9.2089e-08 - accuracy: 1.0000 - val_loss: 4.8280e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 1s 751us/step - loss: 8.4936e-08 - accuracy: 1.0000 - val_loss: 4.8280e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 1s 815us/step - loss: 8.1062e-08 - accuracy: 1.0000 - val_loss: 4.6492e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 1s 767us/step - loss: 8.1807e-08 - accuracy: 1.0000 - val_loss: 3.9935e-08 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 1s 734us/step - loss: 7.6145e-08 - accuracy: 1.0000 - val_loss: 4.2319e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 1s 798us/step - loss: 7.0333e-08 - accuracy: 1.0000 - val_loss: 4.0531e-08 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 1s 705us/step - loss: 6.7949e-08 - accuracy: 1.0000 - val_loss: 3.8743e-08 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 1s 687us/step - loss: 6.4820e-08 - accuracy: 1.0000 - val_loss: 3.3379e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 1s 914us/step - loss: 6.1542e-08 - accuracy: 1.0000 - val_loss: 3.3975e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 1s 758us/step - loss: 5.9604e-08 - accuracy: 1.0000 - val_loss: 3.0994e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "800/800 [==============================] - 1s 759us/step - loss: 5.6177e-08 - accuracy: 1.0000 - val_loss: 3.2186e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 1s 744us/step - loss: 5.3346e-08 - accuracy: 1.0000 - val_loss: 3.0994e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 1s 775us/step - loss: 5.1856e-08 - accuracy: 1.0000 - val_loss: 3.1590e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 1s 770us/step - loss: 5.0515e-08 - accuracy: 1.0000 - val_loss: 2.8610e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 1s 796us/step - loss: 4.7088e-08 - accuracy: 1.0000 - val_loss: 2.7418e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 1s 768us/step - loss: 4.4405e-08 - accuracy: 1.0000 - val_loss: 2.7418e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 1s 740us/step - loss: 4.2170e-08 - accuracy: 1.0000 - val_loss: 2.3246e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 1s 752us/step - loss: 4.0531e-08 - accuracy: 1.0000 - val_loss: 2.4438e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 1s 951us/step - loss: 4.0084e-08 - accuracy: 1.0000 - val_loss: 2.5034e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 1s 820us/step - loss: 3.7104e-08 - accuracy: 1.0000 - val_loss: 2.2650e-08 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 1s 721us/step - loss: 3.5614e-08 - accuracy: 1.0000 - val_loss: 2.0862e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 1s 756us/step - loss: 3.3379e-08 - accuracy: 1.0000 - val_loss: 1.9670e-08 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 1s 726us/step - loss: 3.2484e-08 - accuracy: 1.0000 - val_loss: 1.9670e-08 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 1s 796us/step - loss: 3.0696e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 1s 797us/step - loss: 2.8759e-08 - accuracy: 1.0000 - val_loss: 1.7285e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 1s 789us/step - loss: 2.8312e-08 - accuracy: 1.0000 - val_loss: 1.8477e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 1s 761us/step - loss: 2.6971e-08 - accuracy: 1.0000 - val_loss: 1.5497e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 1s 796us/step - loss: 2.5481e-08 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 1s 799us/step - loss: 2.4587e-08 - accuracy: 1.0000 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 1s 727us/step - loss: 2.3097e-08 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 1s 701us/step - loss: 2.3097e-08 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 1s 726us/step - loss: 2.1011e-08 - accuracy: 1.0000 - val_loss: 1.3709e-08 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 1s 711us/step - loss: 1.9371e-08 - accuracy: 1.0000 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 1s 729us/step - loss: 1.8626e-08 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 1s 762us/step - loss: 1.8477e-08 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 1s 765us/step - loss: 1.7583e-08 - accuracy: 1.0000 - val_loss: 1.0729e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 1s 733us/step - loss: 1.7881e-08 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 1s 735us/step - loss: 1.6242e-08 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 1s 803us/step - loss: 1.5050e-08 - accuracy: 1.0000 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6915e-08 - accuracy: 1.00 - 1s 717us/step - loss: 1.5646e-08 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 1s 707us/step - loss: 1.4454e-08 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 1s 731us/step - loss: 1.3709e-08 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 1s 719us/step - loss: 1.3113e-08 - accuracy: 1.0000 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 1s 780us/step - loss: 1.2070e-08 - accuracy: 1.0000 - val_loss: 8.3446e-09 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 1s 727us/step - loss: 1.2368e-08 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 1s 740us/step - loss: 1.1474e-08 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 1s 776us/step - loss: 1.0729e-08 - accuracy: 1.0000 - val_loss: 7.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 1s 736us/step - loss: 1.0878e-08 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 1s 793us/step - loss: 9.8348e-09 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 1s 739us/step - loss: 9.3877e-09 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 1s 756us/step - loss: 9.2387e-09 - accuracy: 1.0000 - val_loss: 6.5565e-09 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 1s 743us/step - loss: 8.6427e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 1s 746us/step - loss: 8.4937e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 1s 773us/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 5.9605e-09 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 1s 722us/step - loss: 7.5996e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 1s 712us/step - loss: 7.0035e-09 - accuracy: 1.0000 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 1s 754us/step - loss: 7.0035e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 1s 764us/step - loss: 6.5565e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 1s 770us/step - loss: 6.1095e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 1s 728us/step - loss: 6.1095e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 1s 748us/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 1s 736us/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 1s 733us/step - loss: 5.5134e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 1s 719us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 4.1723e-09 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 1s 778us/step - loss: 4.4703e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "800/800 [==============================] - 1s 728us/step - loss: 4.9174e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 1s 709us/step - loss: 4.4703e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 1s 722us/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 3.5763e-09 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 1s 759us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 1s 777us/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 1s 741us/step - loss: 3.4273e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 1s 752us/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 1s 758us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 1s 747us/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 1s 733us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 1s 712us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 1s 726us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 1s 729us/step - loss: 2.6822e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 1s 727us/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 1s 785us/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 1s 761us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 1s 752us/step - loss: 2.2352e-09 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 1s 854us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 1s 734us/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 1s 686us/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 1s 758us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 1s 746us/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 1s 695us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 1s 725us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 1s 696us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 1s 685us/step - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 1s 720us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 1s 726us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 1s 737us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 1s 707us/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 1s 775us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 1s 814us/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 1s 785us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 1s 842us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 1s 900us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 1s 911us/step - loss: 1.0431e-09 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 1s 906us/step - loss: 8.9407e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 1s 870us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 1s 783us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 1s 677us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 1s 700us/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 1s 704us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 1s 739us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 1s 920us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 1s 851us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 1s 918us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 1s 961us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 1s 942us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 1s 929us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 1s 879us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 1s 703us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 1s 678us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 1s 824us/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "500/500 [==============================] - 0s 494us/step\n"
     ]
    }
   ],
   "source": [
    "# units_to_test = [30,50,70,100]\n",
    "StopCriteria = 'val_loss'; epochs = 1000; \n",
    "\n",
    "npoints = len(key_list)\n",
    "d_tdnn = defaultdict(lambda: \"Not Present\") \n",
    "d_tdnn[\"train_acc_arr\"] = defaultdict(lambda: \"Not Present\")\n",
    "d_tdnn[\"train_loss_arr\"] = defaultdict(lambda: \"Not Present\")\n",
    "d_tdnn[\"val_acc_arr\"] = defaultdict(lambda: \"Not Present\")\n",
    "d_tdnn[\"val_loss_arr\"] = defaultdict(lambda: \"Not Present\")\n",
    "# make accuracy and loss list \n",
    "test_acc_arr = np.zeros(npoints)\n",
    "test_loss_arr = np.zeros(npoints)\n",
    "# loop over hidden layers \n",
    "for i in range(npoints):\n",
    "#     units = units_to_test[i]\n",
    "    key = key_list[i]\n",
    "    print('tdnn on '+ key)\n",
    "    #create network\n",
    "#     create_network(delay_size = 7, filters = 30, train_size = 800, batchsize = 10, nh_layers = 1, internal_memory = False):\n",
    "    delay_size = Cond_Table[i][0]\n",
    "    nh_layers = Cond_Table[i][1]\n",
    "    internal_memory = Cond_Table[i][2]\n",
    "    \n",
    "    network =create_network(delay_size = delay_size , nh_layers = nh_layers, internal_memory = internal_memory)\n",
    "\n",
    "    #fit\n",
    "    SavePath = create_path( nhidden = nh_layers, delay = delay_size, internal_memory = internal_memory)\n",
    "    History = train_TDNN(network , SavePath, delay_size)\n",
    "    \n",
    "#     key = str(LearningRate)\n",
    "    d_tdnn[\"train_acc_arr\"][key] = History.history['accuracy']\n",
    "    d_tdnn[\"train_loss_arr\"][key]  = History.history['loss']\n",
    "    d_tdnn[\"val_acc_arr\"][key] = History.history['val_accuracy']\n",
    "    d_tdnn[\"val_loss_arr\"][key] = History.history['val_loss']\n",
    "    # test the network on the testing data\n",
    "    trained_network = load_model(SavePath)\n",
    "    test_loss, test_acc = trained_network.evaluate(X_Test,Y_Test_OneHot)\n",
    "    test_acc_arr[i] = test_acc\n",
    "    test_loss_arr[i] = test_loss\n",
    "\n",
    "#Get epochs array\n",
    "epoch_arr = np.zeros(npoints)\n",
    "i=0\n",
    "for key in d_tdnn[\"train_acc_arr\"]:\n",
    "    arr = d_tdnn[\"train_acc_arr\"][key]\n",
    "    epoch_arr[i] = len(arr) - 20\n",
    "    i=i+1\n",
    "\n",
    "    #######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tdnn_TBS =defaultdict(lambda: \"Not Present\") \n",
    "d_tdnn_TBS[\"train_acc_arr\"] = dict(d_tdnn[\"train_acc_arr\"] )\n",
    "d_tdnn_TBS[\"train_loss_arr\"] = dict(d_tdnn[\"train_loss_arr\"])\n",
    "d_tdnn_TBS[\"val_acc_arr\"] = dict(d_tdnn[\"val_acc_arr\"])\n",
    "d_tdnn_TBS[\"val_loss_arr\"] = dict(d_tdnn[\"val_loss_arr\"])\n",
    "d_tdnn_TBS['test_acc'] = test_acc_arr\n",
    "d_tdnn_TBS['test_loss'] = test_loss_arr\n",
    "d_tdnn_TBS['epochs'] = epoch_arr \n",
    "# d_tdnn_TBS['units_vals'] = units_to_test\n",
    "# d_LR_TBS['Description'] = 'Optimization for learning rate_Adam_1layer_ '+ str (nhidden) + '_nodes'\n",
    "d_tdnn_TBS = dict(d_tdnn_TBS)\n",
    "np.save('Dict_TDNN', np.array(d_tdnn_TBS), allow_pickle = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc_arr\n",
      "train_loss_arr\n",
      "val_acc_arr\n",
      "val_loss_arr\n",
      "test_acc\n",
      "test_loss\n",
      "epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94       0.96200001 0.912      0.926      0.93400002 0.96200001]\n"
     ]
    }
   ],
   "source": [
    "## Learning rate\n",
    "P = np.load('Dict_TDNN.npy', allow_pickle = True)\n",
    "for key in P.item():\n",
    "    print(key)\n",
    "dict_OPT_TBS = P.item()\n",
    "fig, axs = plt.subplots(1, 2,figsize=(10,5), constrained_layout = True)\n",
    "epoch_arr = dict_OPT_TBS['epochs']\n",
    "test_arr = dict_OPT_TBS['test_acc'] \n",
    "OPT_Arr = key_list\n",
    "a = np.arange(len(OPT_Arr))\n",
    "\n",
    "\n",
    "axs[0].bar(a, test_arr)\n",
    "axs[0].set_title('Testing Accuracy')\n",
    "# axs[0].scatter(a, test_arr)\n",
    "axs[0].set(ylabel = 'acc')\n",
    "axs[0].xaxis.set_ticks(a) #set the ticks to be a\n",
    "axs[0].xaxis.set_ticklabels(OPT_Arr,rotation=90)\n",
    "# axs[0].rc('font', size=12)# ####\n",
    "# plt.xticks(rotation='vertical')\n",
    "axs[1].bar(a, epoch_arr)\n",
    "axs[1].set_title('Epochs to train')\n",
    "axs[1].set(ylabel = 'epochs')\n",
    "axs[1].xaxis.set_ticks(a) #set the ticks to be a\n",
    "axs[1].xaxis.set_ticklabels(OPT_Arr,rotation=90) # change the ticks' names to x\n",
    "\n",
    "fig.suptitle('TDNN perfomance', fontsize=20)\n",
    "plt.show()\n",
    "print(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## having memory in the middle does not increase the accuracy at all but it trains faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_key = key_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#     d_rnn[\"train_acc_arr\"][key] = History.history['accuracy']\n",
    "#     d_rnn[\"train_loss_arr\"][key]  = History.history['loss']\n",
    "#     d_rnn[\"val_acc_arr\"][key] = History.history['val_accuracy']\n",
    "#     d_rnn[\"val_loss_arr\"][key] = History.history['val_loss']\n",
    "key = key_list[-1]\n",
    "train_acc  = d_tdnn_TBS[\"train_acc_arr\"][key]\n",
    "train_loss = d_tdnn_TBS[\"train_loss_arr\"][key]\n",
    "val_acc    = d_tdnn_TBS[\"val_acc_arr\"][key]\n",
    "val_loss   = d_tdnn_TBS[\"val_loss_arr\"][key]\n",
    "# Train_acc_20delay = results_20delays.history['loss']\n",
    "# training_vals_loss = Delay7_1layer_dict['loss']\n",
    "# Val_acc_20delay = results_20delays.history['val_loss']\n",
    "# valid_vals_loss = Delay7_1layer_dict['val_loss']\n",
    "# x = list(range(len(training_vals_acc)));\n",
    "plt.plot(train_acc, label = 'Train acc')\n",
    "plt.plot( train_loss,label =  'Train loss')\n",
    "plt.plot( val_acc, label =  'Val acc')\n",
    "plt.plot( val_loss, label =  'Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.title(' TDNN 20 delays - 2 hidden layers - with internaal memory = 96.2% ')\n",
    "# plt.xlim([.98, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Confusion matrix \n",
    "BestModelPath = 'TDNN_layers_2_delay_20_w_memory.h5'\n",
    "train_model = load_model(BestModelPath)\n",
    "predictions = train_model.predict(X_Test)\n",
    "#\n",
    "# Get the max probabilites for each rows\n",
    "probs = np.max(predictions, axis = 1)\n",
    "#\n",
    "# Get the predicted classes for each row  - I have plus 1 because this \n",
    "Y_Predicted_classes = np.argmax(predictions, axis = 1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ConfMat = confusion_matrix(YLabels, Y_Predicted_classes)\n",
    "import seaborn as sn\n",
    "confMat = np.transpose(ConfMat)\n",
    "df_cm = pd.DataFrame(ConfMat, index = [\"Predicted 0\", \"Predicted 1\"],\n",
    "                  columns = [\"True 0\", \"True 1\"])\n",
    "plt.figure(figsize = (7,5))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.title(' TDNN - 2 hidden layers - with internaal memory = 96.2% ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_actual, y_predicted, sigma= .1):\n",
    "    N = y_actual.shape[0]\n",
    "    error_vec = y_actual - y_predicted\n",
    "    \n",
    "    Error_V, Error_H = np.meshgrid(error_vec, error_vec)\n",
    "#     print(Error_V)\n",
    "#     print(Error_H)\n",
    "    arg_matrix = Error_V - Error_H\n",
    "#     arg_matrix = np.asarray(arg_matrix, dtype='float64')\n",
    "#     print(arg_matrix)\n",
    "#     print(type(N))\n",
    "#     print(N**2)\n",
    "    N_dim = int(N**2)\n",
    "    args = arg_matrix.reshape(N_dim)\n",
    "#     args_mu = np.mean(args)\n",
    "#     print(args_mu)\n",
    "    print(args)\n",
    "    MEE = np.sum(np.exp(- .5*((args /sigma) **2 )))\n",
    "    print(MEE)\n",
    "    return MEE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "16.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya = np.ones(4, dtype = 'int')**4\n",
    "yp = np.ones(4, dtype = 'int')*3\n",
    "custom_loss(ya,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(16.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  np.array([1,2,3,4])\n",
    "x_mesh, y_mesh = np.meshgrid(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3],\n",
       "       [4, 4, 4, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_mesh - y_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = x_mesh- y_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  2.71828183,  7.3890561 , 20.08553692,  0.36787944,\n",
       "        1.        ,  2.71828183,  7.3890561 ,  0.13533528,  0.36787944,\n",
       "        1.        ,  2.71828183,  0.04978707,  0.13533528,  0.36787944,\n",
       "        1.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = res.reshape(16)\n",
    "np.exp(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.442590564781526"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'Dimension' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-3befdf79a53f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m          ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n\u001b[0;32m     10\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m#                   layer losses.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# Functions for train, test and predict will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[1;34m(self, masks)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                     output_loss = loss_fn(\n\u001b[1;32m--> 692\u001b[1;33m                         y_true, y_pred, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mscope_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lambda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'<lambda>'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             return losses_utils.compute_weighted_loss(\n\u001b[0;32m     73\u001b[0m                 losses, sample_weight, reduction=self.reduction)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-aeb7de543d40>\u001b[0m in \u001b[0;36mcustom_loss\u001b[1;34m(y_actual, y_predicted, sigma)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#     print(type(N))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     print(N**2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mN_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     args_mu = np.mean(args)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'Dimension' and 'int'"
     ]
    }
   ],
   "source": [
    "# create network \n",
    "network = create_network()\n",
    "SavePath = \"Model_New_Loss_HW4.h5\"\n",
    "delaysize = 7\n",
    "\n",
    "\n",
    "StopCriteria = 'val_loss'\n",
    "callbacks = [EarlyStopping(monitor=StopCriteria, patience=20),\n",
    "         ModelCheckpoint(filepath=SavePath, monitor=StopCriteria, save_best_only=True)]\n",
    "network = network\n",
    "network.compile(optimizer='adam',loss=custom_loss,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = network.fit(X_Train,Y_Train_oneHot,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batchsize, # Early stopping,\n",
    "                     verbose = verbose,\n",
    "                 validation_data=(X_Val,Y_Val_oneHot),\n",
    "                 callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-100-cedef53c14c2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-100-cedef53c14c2>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    loss =  K.mean(K.square(y_pred - y_true))\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "def loss(y_true,y_pred):\n",
    "    \n",
    "    loss =  K.mean(K.square(y_pred - y_true))\n",
    "    return loss\n",
    "\n",
    "# Return a function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "def loss_fun(y_true,y_pred):\n",
    "    loss =  K.mean(K.square(y_pred - y_true))\n",
    "    return loss\n",
    "\n",
    "# Return a function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss_fun(ya, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "network.compile(optimizer='adam',\n",
    "              loss=loss_fun, # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_3:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Exp_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(sigma =.1):\n",
    "    def loss_fun(y_actual, y_predicted):\n",
    "        y_actual = tf.convert_to_tensor(y_actual, dtype='float32' )\n",
    "        y_predicted = tf.convert_to_tensor(y_predicted ,dtype='float32' )\n",
    "        N = y_actual.shape[0]\n",
    "        error_vec = y_actual - y_predicted    \n",
    "        Error_V, Error_H = tf.meshgrid(error_vec, error_vec)\n",
    "        arg_matrix = Error_V - Error_H\n",
    "        MEE = K.sum(K.exp(- .5*((arg_matrix /sigma) **2 )))\n",
    "    #     print(MEE)\n",
    "        return MEE\n",
    "    return loss_fun\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = custom_loss(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_76:0' shape=(4,) dtype=int32>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "network.compile(optimizer='adam',\n",
    "              loss=custom_loss(.1), # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 1s 875us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 439us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 1s 890us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 1s 903us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 1s 906us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 1s 931us/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 1s 895us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 1s 926us/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.7881e-09 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.1921e-09 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 3.2219e-10 - accuracy: 1.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-ddf023b436ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_TDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'testing_hw4.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-2876788139f3>\u001b[0m in \u001b[0;36mtrain_TDNN\u001b[1;34m(network, SavePath, delaysize, verbose, batchsize, epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m                          \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_Val_oneHot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                      callbacks = callbacks)\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mbatch_hook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mbatch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \"\"\"\n\u001b[0;32m    365\u001b[0m         \u001b[1;31m# For backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_TDNN(network , 'testing_hw4.h5', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 302us/step\n",
      "0.9440000057220459\n"
     ]
    }
   ],
   "source": [
    "# test the network on the testing data\n",
    "trained_network = load_model('testing_hw4.h5')\n",
    "test_loss, test_acc = trained_network.evaluate(X_Test,Y_Test_OneHot)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
